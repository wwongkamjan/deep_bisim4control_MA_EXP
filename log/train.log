{"episode_reward": 0.0, "episode": 1.0, "duration": 36.682589530944824, "step": 250}
{"episode_reward": 7.747346039045906, "episode": 2.0, "duration": 1.3141367435455322, "step": 500}
{"episode_reward": 4.427573337125385, "episode": 3.0, "duration": 1.3313922882080078, "step": 750}
{"episode_reward": 5.050386443524035, "episode": 4.0, "duration": 1.318122386932373, "step": 1000}
{"episode_reward": 17.85499204884596, "episode": 5.0, "batch_reward": 0.03611039677060681, "critic_loss": 0.007211500959149491, "ae_transition_loss": 0.013301549557612476, "ae_encoder_loss": 0.0010447514513630518, "actor_loss": -0.3468733761820849, "actor_target_entropy": -6.0, "actor_entropy": 6.687190922978085, "alpha_loss": 0.056967570820949255, "alpha_value": 0.0064495320499338565, "duration": 282.5374426841736, "step": 1250}
{"episode_reward": 16.91159999999907, "episode": 6.0, "batch_reward": 0.04328627309203148, "critic_loss": 0.0037609478384256364, "ae_transition_loss": 0.0031468476345762613, "ae_encoder_loss": 0.0014409330524504185, "actor_loss": -0.6708691272735595, "actor_target_entropy": -6.0, "actor_entropy": 5.077912086486816, "alpha_loss": 0.01842293233424425, "alpha_value": 0.004168103765937118, "duration": 54.546051025390625, "step": 1500}
{"episode_reward": 13.862142802669416, "episode": 7.0, "batch_reward": 0.04483501394093037, "critic_loss": 0.004977432190440595, "ae_transition_loss": 0.003218310532160103, "ae_encoder_loss": 0.00144825808564201, "actor_loss": -0.7574711365699768, "actor_target_entropy": -6.0, "actor_entropy": 4.850466154098511, "alpha_loss": 0.009223341930657625, "alpha_value": 0.004033254076063717, "duration": 54.47188973426819, "step": 1750}
{"episode_reward": 14.304691437911757, "episode": 8.0, "batch_reward": 0.04598211954534054, "critic_loss": 0.005000714144669473, "ae_transition_loss": 0.0027353718229569494, "ae_encoder_loss": 0.0015010151651222259, "actor_loss": -0.8306702456474304, "actor_target_entropy": -6.0, "actor_entropy": 4.995223377227783, "alpha_loss": 0.008191119134426116, "alpha_value": 0.0039425413864398315, "duration": 54.53324341773987, "step": 2000}
{"episode_reward": 13.85692463253913, "episode": 9.0, "batch_reward": 0.04713152533769607, "critic_loss": 0.00486700923461467, "ae_transition_loss": 0.0020936633171513676, "ae_encoder_loss": 0.0011829935957212, "actor_loss": -0.9283569540977478, "actor_target_entropy": -6.0, "actor_entropy": 4.848371013641358, "alpha_loss": 0.008080100737512112, "alpha_value": 0.0038480935939078265, "duration": 54.52506947517395, "step": 2250}
{"episode_reward": 10.801823584716633, "episode": 10.0, "batch_reward": 0.04667940582334995, "critic_loss": 0.005929267591796816, "ae_transition_loss": 0.0025311351884156467, "ae_encoder_loss": 0.0009914844390004874, "actor_loss": -0.9942378344535827, "actor_target_entropy": -6.0, "actor_entropy": 4.94051900100708, "alpha_loss": 0.008369193080812692, "alpha_value": 0.0037555179263900427, "duration": 54.674829959869385, "step": 2500}
