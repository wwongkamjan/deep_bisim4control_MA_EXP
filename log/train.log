{"episode_reward": 0.0, "episode": 1.0, "duration": 37.509085178375244, "step": 250}
{"episode_reward": 7.747346039045906, "episode": 2.0, "duration": 1.364792823791504, "step": 500}
{"episode_reward": 4.427573337125385, "episode": 3.0, "duration": 1.3946723937988281, "step": 750}
{"episode_reward": 5.050386443524035, "episode": 4.0, "duration": 1.365649700164795, "step": 1000}
{"episode_reward": 17.85499204884596, "episode": 5.0, "batch_reward": 0.03585564650243239, "critic_loss": 0.006290757440584596, "ae_transition_loss": 0.012708452136592836, "ae_encoder_loss": 0.0011550658027939923, "actor_loss": -0.30935327858362494, "actor_target_entropy": -6.0, "actor_entropy": 6.6953295060960425, "alpha_loss": 0.05781296267939791, "alpha_value": 0.0064261787412239766, "duration": 281.3871784210205, "step": 1250}
{"episode_reward": 13.360520066407457, "episode": 6.0, "batch_reward": 0.03854048778116703, "critic_loss": 0.0034614128288812935, "ae_transition_loss": 0.0032133228690363466, "ae_encoder_loss": 0.0012610475758556277, "actor_loss": -0.6164593696594238, "actor_target_entropy": -6.0, "actor_entropy": 5.561108669281006, "alpha_loss": 0.019988198697566986, "alpha_value": 0.004159691168887429, "duration": 54.348036766052246, "step": 1500}
{"episode_reward": 8.160907112448587, "episode": 7.0, "batch_reward": 0.03790704244375229, "critic_loss": 0.003531500373035669, "ae_transition_loss": 0.00242338429717347, "ae_encoder_loss": 0.000991485041566193, "actor_loss": -0.6818044185638428, "actor_target_entropy": -6.0, "actor_entropy": 5.462580539703369, "alpha_loss": 0.015853359572589397, "alpha_value": 0.003975692188478594, "duration": 54.415186643600464, "step": 1750}
{"episode_reward": 9.175534805873335, "episode": 8.0, "batch_reward": 0.03643808737397194, "critic_loss": 0.003643009324558079, "ae_transition_loss": 0.002425112378783524, "ae_encoder_loss": 0.001048706365050748, "actor_loss": -0.7431496443748474, "actor_target_entropy": -6.0, "actor_entropy": 5.380734531402588, "alpha_loss": 0.010524751495569945, "alpha_value": 0.0038358329980689118, "duration": 54.60985827445984, "step": 2000}
{"episode_reward": 5.631197074653419, "episode": 9.0, "batch_reward": 0.035404588416218755, "critic_loss": 0.003821534306742251, "ae_transition_loss": 0.0019180801357142627, "ae_encoder_loss": 0.0008320762575604021, "actor_loss": -0.8184905571937561, "actor_target_entropy": -6.0, "actor_entropy": 5.219644889831543, "alpha_loss": 0.006992781302891672, "alpha_value": 0.003742197794680858, "duration": 54.660778522491455, "step": 2250}
{"episode_reward": 7.323138711551199, "episode": 10.0, "batch_reward": 0.03596413693577051, "critic_loss": 0.0031075275195762515, "ae_transition_loss": 0.00171623638831079, "ae_encoder_loss": 0.0006601521116681397, "actor_loss": -0.8638388867378235, "actor_target_entropy": -6.0, "actor_entropy": 4.763799095153809, "alpha_loss": 0.00671739710867405, "alpha_value": 0.0036696883752328612, "duration": 54.62713265419006, "step": 2500}
