{"episode_reward": 0.0, "episode": 1.0, "duration": 15.462413311004639, "step": 250}
{"episode_reward": 8.03772363506006, "episode": 2.0, "duration": 0.3480565547943115, "step": 500}
{"episode_reward": 17.16626315104322, "episode": 3.0, "duration": 0.33976316452026367, "step": 750}
{"episode_reward": 12.073072643141685, "episode": 4.0, "duration": 0.33876776695251465, "step": 1000}
{"episode_reward": 11.095187414981499, "episode": 5.0, "batch_reward": 0.048329339242630526, "critic_loss": 0.01286827915014805, "ae_transition_loss": 0.013014070274878702, "ae_encoder_loss": 0.0006045476011153153, "actor_loss": -0.1829861261845327, "actor_target_entropy": -6.0, "actor_entropy": 5.601305680130724, "alpha_loss": 0.04005745586854641, "alpha_value": 0.006785318533930732, "duration": 281.5773069858551, "step": 1250}
{"episode_reward": 12.67761641861349, "episode": 6.0, "batch_reward": 0.051796249389648434, "critic_loss": 0.022521886333823203, "ae_transition_loss": 0.0008874340175534599, "ae_encoder_loss": 0.0002959945356706157, "actor_loss": -0.5028239424228669, "actor_target_entropy": -6.0, "actor_entropy": 6.484705406188965, "alpha_loss": 0.028760864660143853, "alpha_value": 0.004712084412807306, "duration": 54.13903784751892, "step": 1500}
{"episode_reward": 15.867696554816906, "episode": 7.0, "batch_reward": 0.049686159953475, "critic_loss": 0.01136140357889235, "ae_transition_loss": 0.001534312889969442, "ae_encoder_loss": 0.00042640181467868386, "actor_loss": -0.5357562928199768, "actor_target_entropy": -6.0, "actor_entropy": 6.321079284667968, "alpha_loss": 0.02896616480499506, "alpha_value": 0.0042702389543687255, "duration": 54.09212517738342, "step": 1750}
{"episode_reward": 9.783099733621135, "episode": 8.0, "batch_reward": 0.050166874065995216, "critic_loss": 0.006560573035851121, "ae_transition_loss": 0.004200415642932057, "ae_encoder_loss": 0.0008910441448679194, "actor_loss": -0.6465329737663269, "actor_target_entropy": -6.0, "actor_entropy": 5.200140789031982, "alpha_loss": 0.01717331610620022, "alpha_value": 0.003942813197962451, "duration": 54.069947957992554, "step": 2000}
{"episode_reward": 11.264666903104581, "episode": 9.0, "batch_reward": 0.04889132872223854, "critic_loss": 0.00378858335968107, "ae_transition_loss": 0.003166760191321373, "ae_encoder_loss": 0.0007634804333793, "actor_loss": -0.7279030518531799, "actor_target_entropy": -6.0, "actor_entropy": 4.689892332077027, "alpha_loss": 0.012561064340174198, "alpha_value": 0.0037349663893833478, "duration": 54.03706622123718, "step": 2250}
{"episode_reward": 10.56995823199057, "episode": 10.0, "batch_reward": 0.04930639573931694, "critic_loss": 0.005539956615306437, "ae_transition_loss": 0.0036466197511181237, "ae_encoder_loss": 0.0006960036160307936, "actor_loss": -0.7377221298217773, "actor_target_entropy": -6.0, "actor_entropy": 4.75238391494751, "alpha_loss": 0.013215297102928162, "alpha_value": 0.0035641063351933367, "duration": 54.03286600112915, "step": 2500}
{"episode_reward": 13.404255640948183, "episode": 11.0, "batch_reward": 0.04817428959906101, "critic_loss": 0.008552369229495526, "ae_transition_loss": 0.004620362694375217, "ae_encoder_loss": 0.0007183603704907, "actor_loss": -0.6959233522415161, "actor_target_entropy": -6.0, "actor_entropy": 6.099836460113526, "alpha_loss": 0.016058036256581545, "alpha_value": 0.0033351040666474013, "duration": 67.85494947433472, "step": 2750}
{"episode_reward": 12.775274490802014, "episode": 12.0, "batch_reward": 0.05232993040978909, "critic_loss": 0.014363276643678546, "ae_transition_loss": 0.0055593045200221245, "ae_encoder_loss": 0.0012838934671599417, "actor_loss": -0.7854105706214904, "actor_target_entropy": -6.0, "actor_entropy": 4.856767766475677, "alpha_loss": -0.0020155770184937865, "alpha_value": 0.0031909683978211595, "duration": 53.949997901916504, "step": 3000}
{"episode_reward": 51.95497762769602, "episode": 13.0, "batch_reward": 0.06421235880255699, "critic_loss": 0.019441019957885147, "ae_transition_loss": 0.00360331422672607, "ae_encoder_loss": 0.004684816752560436, "actor_loss": -0.8079086537361145, "actor_target_entropy": -6.0, "actor_entropy": 4.5706807861328125, "alpha_loss": -0.02275252086110413, "alpha_value": 0.0034398633940137895, "duration": 54.0290949344635, "step": 3250}
{"episode_reward": 64.97040349978505, "episode": 14.0, "batch_reward": 0.08313481982052326, "critic_loss": 0.009367911530658603, "ae_transition_loss": 0.009694983622059226, "ae_encoder_loss": 0.009662750797346234, "actor_loss": -0.7981114282608032, "actor_target_entropy": -6.0, "actor_entropy": 5.555707782745361, "alpha_loss": 0.001234383258386515, "alpha_value": 0.00361234465567032, "duration": 54.044374227523804, "step": 3500}
{"episode_reward": 42.802605695615114, "episode": 15.0, "batch_reward": 0.08474975430965423, "critic_loss": 0.026828834583982827, "ae_transition_loss": 0.018225801058113576, "ae_encoder_loss": 0.01079206964559853, "actor_loss": -0.873880136013031, "actor_target_entropy": -6.0, "actor_entropy": 5.7243015022277834, "alpha_loss": 0.000684920224128291, "alpha_value": 0.0035571764229600663, "duration": 54.07458472251892, "step": 3750}
{"episode_reward": 24.42665941220227, "episode": 16.0, "batch_reward": 0.0967032408118248, "critic_loss": 0.028641899712383748, "ae_transition_loss": 0.013423379747197033, "ae_encoder_loss": 0.01385157479532063, "actor_loss": -1.0249212412834168, "actor_target_entropy": -6.0, "actor_entropy": 5.20775884437561, "alpha_loss": -0.01071081312559545, "alpha_value": 0.0036880060929564557, "duration": 54.018104553222656, "step": 4000}
{"episode_reward": 119.13528445021062, "episode": 17.0, "batch_reward": 0.11254634103178977, "critic_loss": 0.029591020457446576, "ae_transition_loss": 0.019147793870419264, "ae_encoder_loss": 0.02191733879595995, "actor_loss": -1.1426931977272035, "actor_target_entropy": -6.0, "actor_entropy": 5.263999206542969, "alpha_loss": -0.010589812947204336, "alpha_value": 0.00389290701378899, "duration": 54.02569055557251, "step": 4250}
{"episode_reward": 33.59782578591603, "episode": 18.0, "batch_reward": 0.1152433158159256, "critic_loss": 0.028418353974819184, "ae_transition_loss": 0.016884197831153868, "ae_encoder_loss": 0.024138289723545314, "actor_loss": -1.2367900667190552, "actor_target_entropy": -6.0, "actor_entropy": 5.448597248077393, "alpha_loss": -0.006458043840480968, "alpha_value": 0.004085302562515052, "duration": 53.931294441223145, "step": 4500}
{"episode_reward": 59.222096637911235, "episode": 19.0, "batch_reward": 0.12092092829942704, "critic_loss": 0.032522306419909, "ae_transition_loss": 0.018760333165526392, "ae_encoder_loss": 0.030442319869995117, "actor_loss": -1.338650583267212, "actor_target_entropy": -6.0, "actor_entropy": 5.632140884399414, "alpha_loss": -0.0036370720365084706, "alpha_value": 0.004212921694057929, "duration": 53.95437955856323, "step": 4750}
{"episode_reward": 37.65511158591187, "episode": 20.0, "batch_reward": 0.12330221262574195, "critic_loss": 0.03768465757369995, "ae_transition_loss": 0.02065199825167656, "ae_encoder_loss": 0.032680676892399785, "actor_loss": -1.4378551893234253, "actor_target_entropy": -6.0, "actor_entropy": 5.674305629730225, "alpha_loss": -0.0013293981121387333, "alpha_value": 0.004279286110087298, "duration": 53.97076988220215, "step": 5000}
{"episode_reward": 56.58508584029497, "episode": 21.0, "batch_reward": 0.12921331235766412, "critic_loss": 0.04394349736720324, "ae_transition_loss": 0.022465242225676776, "ae_encoder_loss": 0.035220338553190234, "actor_loss": -1.5414108715057373, "actor_target_entropy": -6.0, "actor_entropy": 5.724436073303223, "alpha_loss": -0.0007522578086936846, "alpha_value": 0.00431344365063944, "duration": 67.9484474658966, "step": 5250}
{"episode_reward": 92.98654579243103, "episode": 22.0, "batch_reward": 0.1394895597398281, "critic_loss": 0.03928912241756916, "ae_transition_loss": 0.023515937320888042, "ae_encoder_loss": 0.04009592179954052, "actor_loss": -1.7139161281585693, "actor_target_entropy": -6.0, "actor_entropy": 5.421415637969971, "alpha_loss": -0.004110404051141814, "alpha_value": 0.004382766384845286, "duration": 54.00319147109985, "step": 5500}
{"episode_reward": 43.582770354314896, "episode": 23.0, "batch_reward": 0.14184768861532213, "critic_loss": 0.034010934121906755, "ae_transition_loss": 0.02243868223950267, "ae_encoder_loss": 0.043690867215394974, "actor_loss": -1.8318640842437743, "actor_target_entropy": -6.0, "actor_entropy": 5.2824070854187015, "alpha_loss": -0.0038646564080845563, "alpha_value": 0.00451019683388519, "duration": 54.063910484313965, "step": 5750}
{"episode_reward": 52.76680117968031, "episode": 24.0, "batch_reward": 0.14410842305421828, "critic_loss": 0.035277747713029384, "ae_transition_loss": 0.02299382198601961, "ae_encoder_loss": 0.04571346612274647, "actor_loss": -1.960997127532959, "actor_target_entropy": -6.0, "actor_entropy": 5.111891777038574, "alpha_loss": -0.005670215925201774, "alpha_value": 0.004680997425619613, "duration": 54.07781481742859, "step": 6000}
{"episode_reward": 55.30127392696836, "episode": 25.0, "batch_reward": 0.1465347016453743, "critic_loss": 0.038273951902985576, "ae_transition_loss": 0.022813835732638836, "ae_encoder_loss": 0.04966858273744583, "actor_loss": -2.073472762107849, "actor_target_entropy": -6.0, "actor_entropy": 5.081819988250732, "alpha_loss": -0.006470333907753229, "alpha_value": 0.004957722824665394, "duration": 54.03770732879639, "step": 6250}
{"episode_reward": 57.87364441381226, "episode": 26.0, "batch_reward": 0.15095194041728974, "critic_loss": 0.03884306720644236, "ae_transition_loss": 0.023105638287961482, "ae_encoder_loss": 0.0495821575820446, "actor_loss": -2.1949345188140867, "actor_target_entropy": -6.0, "actor_entropy": 5.228132461547852, "alpha_loss": -0.001949011229677126, "alpha_value": 0.0051847369445726784, "duration": 54.018840074539185, "step": 6500}
{"episode_reward": 63.09741263137588, "episode": 27.0, "batch_reward": 0.15509635335206987, "critic_loss": 0.039753245182335376, "ae_transition_loss": 0.02212414813786745, "ae_encoder_loss": 0.05115182739496231, "actor_loss": -2.307427345275879, "actor_target_entropy": -6.0, "actor_entropy": 5.33747241973877, "alpha_loss": -0.0015791760188294574, "alpha_value": 0.005234508887011476, "duration": 54.00032091140747, "step": 6750}
{"episode_reward": 63.27266834121121, "episode": 28.0, "batch_reward": 0.15660373747348785, "critic_loss": 0.040547839723527435, "ae_transition_loss": 0.02221063006669283, "ae_encoder_loss": 0.051074279755353925, "actor_loss": -2.3987902927398683, "actor_target_entropy": -6.0, "actor_entropy": 5.375915561676026, "alpha_loss": -0.002454611565452069, "alpha_value": 0.005367748710340677, "duration": 54.03079009056091, "step": 7000}
{"episode_reward": 39.20942525124192, "episode": 29.0, "batch_reward": 0.15739809411764144, "critic_loss": 0.04815188979357481, "ae_transition_loss": 0.024756599925458433, "ae_encoder_loss": 0.053379254013299945, "actor_loss": -2.496832830429077, "actor_target_entropy": -6.0, "actor_entropy": 5.194108085632324, "alpha_loss": -0.0038697806220734494, "alpha_value": 0.005523048582826932, "duration": 54.009313344955444, "step": 7250}
{"episode_reward": 52.8682493204402, "episode": 30.0, "batch_reward": 0.1607025775909424, "critic_loss": 0.048708965644240376, "ae_transition_loss": 0.02279591714590788, "ae_encoder_loss": 0.05556384998559952, "actor_loss": -2.6321547660827638, "actor_target_entropy": -6.0, "actor_entropy": 5.247349285125733, "alpha_loss": -0.006736847571330145, "alpha_value": 0.005868569495337392, "duration": 54.025575399398804, "step": 7500}
{"episode_reward": 71.22697832233203, "episode": 31.0, "batch_reward": 0.1646338954567909, "critic_loss": 0.05179639655351639, "ae_transition_loss": 0.0235596946105361, "ae_encoder_loss": 0.05592801289260387, "actor_loss": -2.765966537475586, "actor_target_entropy": -6.0, "actor_entropy": 5.240020259857178, "alpha_loss": -0.006367349657812156, "alpha_value": 0.006397559203249084, "duration": 68.76747536659241, "step": 7750}
{"episode_reward": 54.64941536971771, "episode": 32.0, "batch_reward": 0.16553546512126924, "critic_loss": 0.05480311745405197, "ae_transition_loss": 0.023017202191054822, "ae_encoder_loss": 0.059293340921401975, "actor_loss": -2.8858789329528807, "actor_target_entropy": -6.0, "actor_entropy": 5.3472524147033695, "alpha_loss": -0.003818002351676114, "alpha_value": 0.006808918218857617, "duration": 54.10791540145874, "step": 8000}
{"episode_reward": 64.5430281879644, "episode": 33.0, "batch_reward": 0.16695302200317383, "critic_loss": 0.05771226467192173, "ae_transition_loss": 0.02246002120524645, "ae_encoder_loss": 0.059023835331201556, "actor_loss": -3.036215328216553, "actor_target_entropy": -6.0, "actor_entropy": 5.3258398818969725, "alpha_loss": -0.004397014380665496, "alpha_value": 0.007153614742079721, "duration": 53.99845290184021, "step": 8250}
{"episode_reward": 33.29171812920424, "episode": 34.0, "batch_reward": 0.1671793556213379, "critic_loss": 0.05646084555983543, "ae_transition_loss": 0.02050276619195938, "ae_encoder_loss": 0.060980388775467874, "actor_loss": -3.1859504985809326, "actor_target_entropy": -6.0, "actor_entropy": 5.300597213745117, "alpha_loss": -0.0043998739244416355, "alpha_value": 0.007574673123796716, "duration": 53.99818682670593, "step": 8500}
{"episode_reward": 58.11010759005202, "episode": 35.0, "batch_reward": 0.1672622492313385, "critic_loss": 0.05686323446035385, "ae_transition_loss": 0.019888729199767113, "ae_encoder_loss": 0.05907824450731278, "actor_loss": -3.306298673629761, "actor_target_entropy": -6.0, "actor_entropy": 5.231948162078857, "alpha_loss": -0.003030542440712452, "alpha_value": 0.00799539271035535, "duration": 54.15102028846741, "step": 8750}
{"episode_reward": 53.803429298632885, "episode": 36.0, "batch_reward": 0.171136028110981, "critic_loss": 0.05160261230915785, "ae_transition_loss": 0.017986170802265406, "ae_encoder_loss": 0.054227367281913755, "actor_loss": -3.4354586753845213, "actor_target_entropy": -6.0, "actor_entropy": 5.217381427764892, "alpha_loss": -0.002593263466143981, "alpha_value": 0.008286348911983533, "duration": 54.17660999298096, "step": 9000}
{"episode_reward": 77.60282963389776, "episode": 37.0, "batch_reward": 0.17374925142526626, "critic_loss": 0.05134032475948334, "ae_transition_loss": 0.017491939269006253, "ae_encoder_loss": 0.051766271084547046, "actor_loss": -3.558539068222046, "actor_target_entropy": -6.0, "actor_entropy": 5.234017299652099, "alpha_loss": -0.00014321059070061893, "alpha_value": 0.008541801578872285, "duration": 54.38126301765442, "step": 9250}
{"episode_reward": 72.69060180246916, "episode": 38.0, "batch_reward": 0.1784177971482277, "critic_loss": 0.08416887736320496, "ae_transition_loss": 0.022006082348525524, "ae_encoder_loss": 0.055859622433781626, "actor_loss": -3.7243925437927246, "actor_target_entropy": -6.0, "actor_entropy": 5.1868193359375, "alpha_loss": -0.001444628294557333, "alpha_value": 0.008632618160921618, "duration": 54.128132343292236, "step": 9500}
{"episode_reward": 87.93857384183883, "episode": 39.0, "batch_reward": 0.18117957216501235, "critic_loss": 0.06948878253996373, "ae_transition_loss": 0.01967660068720579, "ae_encoder_loss": 0.05741666722297668, "actor_loss": -3.863080976486206, "actor_target_entropy": -6.0, "actor_entropy": 5.241244186401367, "alpha_loss": -0.0028516486580483615, "alpha_value": 0.008888380548886864, "duration": 54.12794828414917, "step": 9750}
{"episode_reward": 59.76235159398444, "episode": 40.0, "batch_reward": 0.18534969854354857, "critic_loss": 0.07058521826565266, "ae_transition_loss": 0.0193256753757596, "ae_encoder_loss": 0.05905808264017105, "actor_loss": -4.0219577293396, "actor_target_entropy": -6.0, "actor_entropy": 5.2730769958496095, "alpha_loss": -0.0014051486362004653, "alpha_value": 0.009221283852913147, "duration": 54.18495059013367, "step": 10000}
{"episode_reward": 98.69971600447967, "episode": 41.0, "batch_reward": 0.1885362527370453, "critic_loss": 0.06842397621273995, "ae_transition_loss": 0.018618579123169183, "ae_encoder_loss": 0.05836755216121674, "actor_loss": -4.1593010730743405, "actor_target_entropy": -6.0, "actor_entropy": 5.297935611724854, "alpha_loss": 6.035839882679283e-05, "alpha_value": 0.009411326890608373, "duration": 74.6676504611969, "step": 10250}
{"episode_reward": 70.06850389023442, "episode": 42.0, "batch_reward": 0.19080639272928238, "critic_loss": 0.07490883485972881, "ae_transition_loss": 0.01803689485043287, "ae_encoder_loss": 0.056932935565710066, "actor_loss": -4.306156352996826, "actor_target_entropy": -6.0, "actor_entropy": 5.154099071502686, "alpha_loss": -0.002104835577891208, "alpha_value": 0.0095603468434432, "duration": 54.254481077194214, "step": 10500}
{"episode_reward": 81.22164915109818, "episode": 43.0, "batch_reward": 0.19529923367500304, "critic_loss": 0.08540254391729832, "ae_transition_loss": 0.01951832355558872, "ae_encoder_loss": 0.060157445207238196, "actor_loss": -4.486842273712158, "actor_target_entropy": -6.0, "actor_entropy": 5.1100533599853515, "alpha_loss": -0.001450016028713435, "alpha_value": 0.009991758534024292, "duration": 54.216717004776, "step": 10750}
{"episode_reward": 87.43709487844944, "episode": 44.0, "batch_reward": 0.19727593463659288, "critic_loss": 0.07592498415708542, "ae_transition_loss": 0.018348802134394646, "ae_encoder_loss": 0.0597515986263752, "actor_loss": -4.6148680953979495, "actor_target_entropy": -6.0, "actor_entropy": 5.088063285827637, "alpha_loss": -0.0020147573249414564, "alpha_value": 0.010209392317140553, "duration": 54.249489307403564, "step": 11000}
{"episode_reward": 88.33151431602253, "episode": 45.0, "batch_reward": 0.20298624610900878, "critic_loss": 0.08490686073899269, "ae_transition_loss": 0.019082408778369427, "ae_encoder_loss": 0.0603882961422205, "actor_loss": -4.793445430755615, "actor_target_entropy": -6.0, "actor_entropy": 5.116662216186524, "alpha_loss": -0.0002764442565385252, "alpha_value": 0.010574974580448246, "duration": 54.17976188659668, "step": 11250}
{"episode_reward": 103.70288552438242, "episode": 46.0, "batch_reward": 0.20762490153312682, "critic_loss": 0.11518951952457428, "ae_transition_loss": 0.02117708757519722, "ae_encoder_loss": 0.06327499940991402, "actor_loss": -4.969419273376465, "actor_target_entropy": -6.0, "actor_entropy": 5.140477828979492, "alpha_loss": -0.000794076933641918, "alpha_value": 0.010654936760440398, "duration": 54.18429946899414, "step": 11500}
{"episode_reward": 111.62093235408507, "episode": 47.0, "batch_reward": 0.2102250844836235, "critic_loss": 0.08524727439880371, "ae_transition_loss": 0.019584053777158262, "ae_encoder_loss": 0.0645294925570488, "actor_loss": -5.13584912109375, "actor_target_entropy": -6.0, "actor_entropy": 5.172437602996826, "alpha_loss": -0.0006815548805752769, "alpha_value": 0.010899666809703619, "duration": 54.18333554267883, "step": 11750}
{"episode_reward": 29.53359724559537, "episode": 48.0, "batch_reward": 0.21065949684381485, "critic_loss": 0.1214815115481615, "ae_transition_loss": 0.021034299712628126, "ae_encoder_loss": 0.06608404821157456, "actor_loss": -5.31625993347168, "actor_target_entropy": -6.0, "actor_entropy": 5.231951793670654, "alpha_loss": 0.00022220107796601951, "alpha_value": 0.010877132423308804, "duration": 54.20486092567444, "step": 12000}
{"episode_reward": 89.38408476277255, "episode": 49.0, "batch_reward": 0.21404296225309372, "critic_loss": 0.11623764750361443, "ae_transition_loss": 0.020252653326839207, "ae_encoder_loss": 0.06777775606513023, "actor_loss": -5.508896770477295, "actor_target_entropy": -6.0, "actor_entropy": 5.204766788482666, "alpha_loss": -0.00045812651491723954, "alpha_value": 0.011009926792490675, "duration": 53.80846643447876, "step": 12250}
{"episode_reward": 110.91484126314121, "episode": 50.0, "batch_reward": 0.2173497933745384, "critic_loss": 0.10985739535093307, "ae_transition_loss": 0.020095950074493885, "ae_encoder_loss": 0.06820130267739297, "actor_loss": -5.677535186767578, "actor_target_entropy": -6.0, "actor_entropy": 5.27158959197998, "alpha_loss": -0.0002461415163706988, "alpha_value": 0.011068185527442025, "duration": 53.91861128807068, "step": 12500}
{"episode_reward": 78.92105922351755, "episode": 51.0, "batch_reward": 0.2189108354449272, "critic_loss": 0.11428283184766769, "ae_transition_loss": 0.020040137253701688, "ae_encoder_loss": 0.06935889363288879, "actor_loss": -5.829544612884521, "actor_target_entropy": -6.0, "actor_entropy": 5.287179958343506, "alpha_loss": -0.0003841775266919285, "alpha_value": 0.010991553092984737, "duration": 67.99257946014404, "step": 12750}
{"episode_reward": 48.79365956678617, "episode": 52.0, "batch_reward": 0.21922870075702666, "critic_loss": 0.12002894547581673, "ae_transition_loss": 0.020842877611517905, "ae_encoder_loss": 0.06910674135386943, "actor_loss": -6.021611522674561, "actor_target_entropy": -6.0, "actor_entropy": 5.2558501663208, "alpha_loss": -0.0015227636296767742, "alpha_value": 0.011488988333858616, "duration": 53.93873620033264, "step": 13000}
{"episode_reward": 94.4667305960122, "episode": 53.0, "batch_reward": 0.22259324240684508, "critic_loss": 0.1175952232182026, "ae_transition_loss": 0.019545572862029077, "ae_encoder_loss": 0.06935668469965459, "actor_loss": -6.193622570037842, "actor_target_entropy": -6.0, "actor_entropy": 5.197062522888183, "alpha_loss": -0.0020209414733108133, "alpha_value": 0.011982572926575907, "duration": 54.18002414703369, "step": 13250}
{"episode_reward": 92.81537288710936, "episode": 54.0, "batch_reward": 0.2253523610830307, "critic_loss": 0.10990936702489854, "ae_transition_loss": 0.018625564999878406, "ae_encoder_loss": 0.06919064663350583, "actor_loss": -6.372375080108642, "actor_target_entropy": -6.0, "actor_entropy": 5.2335669212341305, "alpha_loss": -1.833541039377451e-05, "alpha_value": 0.012362074305164648, "duration": 54.2090528011322, "step": 13500}
{"episode_reward": 105.14175831410795, "episode": 55.0, "batch_reward": 0.22899750328063964, "critic_loss": 0.1389640692770481, "ae_transition_loss": 0.02072026327252388, "ae_encoder_loss": 0.06810010127723216, "actor_loss": -6.560807960510254, "actor_target_entropy": -6.0, "actor_entropy": 5.235154163360596, "alpha_loss": -0.000552915994077921, "alpha_value": 0.012374039506012856, "duration": 54.14838981628418, "step": 13750}
{"episode_reward": 87.45073929496229, "episode": 56.0, "batch_reward": 0.2311158613562584, "critic_loss": 0.11096187895536423, "ae_transition_loss": 0.017580894257873295, "ae_encoder_loss": 0.06701274226605893, "actor_loss": -6.714490711212158, "actor_target_entropy": -6.0, "actor_entropy": 5.204804100036621, "alpha_loss": -8.787833759561181e-05, "alpha_value": 0.012575589150225877, "duration": 54.286622524261475, "step": 14000}
{"episode_reward": 102.85168547176808, "episode": 57.0, "batch_reward": 0.23375051969289778, "critic_loss": 0.1451835146546364, "ae_transition_loss": 0.02071186262741685, "ae_encoder_loss": 0.07093573801219463, "actor_loss": -6.858552921295166, "actor_target_entropy": -6.0, "actor_entropy": 5.20854568862915, "alpha_loss": -0.0009211065575946123, "alpha_value": 0.01275615926819218, "duration": 54.19407629966736, "step": 14250}
{"episode_reward": 86.50898163091858, "episode": 58.0, "batch_reward": 0.23674081015586854, "critic_loss": 0.11732626101374626, "ae_transition_loss": 0.01793144564703107, "ae_encoder_loss": 0.06608943736553193, "actor_loss": -7.039439777374268, "actor_target_entropy": -6.0, "actor_entropy": 5.279367671966552, "alpha_loss": 0.0004944330952130258, "alpha_value": 0.012800370908103197, "duration": 54.33768653869629, "step": 14500}
{"episode_reward": 88.59891696658167, "episode": 59.0, "batch_reward": 0.23823665469884872, "critic_loss": 0.14628709253668784, "ae_transition_loss": 0.020316363662481306, "ae_encoder_loss": 0.06962874488532543, "actor_loss": -7.204573665618897, "actor_target_entropy": -6.0, "actor_entropy": 5.276331859588623, "alpha_loss": 0.00025585408415645364, "alpha_value": 0.012743698133546671, "duration": 54.23822355270386, "step": 14750}
{"episode_reward": 106.59422576009139, "episode": 60.0, "batch_reward": 0.24090588849782943, "critic_loss": 0.18698988819122314, "ae_transition_loss": 0.02166372050344944, "ae_encoder_loss": 0.07061058621108532, "actor_loss": -7.413272834777832, "actor_target_entropy": -6.0, "actor_entropy": 5.261043735504151, "alpha_loss": -0.0008638309461530298, "alpha_value": 0.012763053317714391, "duration": 54.43174481391907, "step": 15000}
{"episode_reward": 98.16329115085618, "episode": 61.0, "batch_reward": 0.24381738889217378, "critic_loss": 0.13879196727275847, "ae_transition_loss": 0.01983834193646908, "ae_encoder_loss": 0.07397106185555458, "actor_loss": -7.584061836242676, "actor_target_entropy": -6.0, "actor_entropy": 5.283307987213135, "alpha_loss": -0.000764224289683625, "alpha_value": 0.012984108807651175, "duration": 68.43529725074768, "step": 15250}
{"episode_reward": 119.61840736165767, "episode": 62.0, "batch_reward": 0.2484127469062805, "critic_loss": 0.1546366648375988, "ae_transition_loss": 0.020831254497170448, "ae_encoder_loss": 0.07576772160828113, "actor_loss": -7.798613994598389, "actor_target_entropy": -6.0, "actor_entropy": 5.2756379585266115, "alpha_loss": -0.0006873482037335634, "alpha_value": 0.013299660637478748, "duration": 54.259920835494995, "step": 15500}
{"episode_reward": 110.65805439449504, "episode": 63.0, "batch_reward": 0.24987976312637328, "critic_loss": 0.1504392832517624, "ae_transition_loss": 0.019446929052472115, "ae_encoder_loss": 0.07211478079855442, "actor_loss": -7.964569702148437, "actor_target_entropy": -6.0, "actor_entropy": 5.278151348114013, "alpha_loss": 0.00035662331245839594, "alpha_value": 0.013437556622389227, "duration": 54.38421130180359, "step": 15750}
{"episode_reward": 65.2232369284436, "episode": 64.0, "batch_reward": 0.2489891224503517, "critic_loss": 0.1656508826315403, "ae_transition_loss": 0.021081015713512896, "ae_encoder_loss": 0.07480908203125, "actor_loss": -8.150770301818847, "actor_target_entropy": -6.0, "actor_entropy": 5.252685031890869, "alpha_loss": -0.0006896886622998863, "alpha_value": 0.013540946800817034, "duration": 54.38026833534241, "step": 16000}
{"episode_reward": 73.17133798565382, "episode": 65.0, "batch_reward": 0.2518803533911705, "critic_loss": 0.1482539118528366, "ae_transition_loss": 0.019592878937721252, "ae_encoder_loss": 0.07463546808063984, "actor_loss": -8.346972793579102, "actor_target_entropy": -6.0, "actor_entropy": 5.26556103515625, "alpha_loss": 9.027851128485054e-05, "alpha_value": 0.013570604628286553, "duration": 54.341089487075806, "step": 16250}
{"episode_reward": 103.7031317464304, "episode": 66.0, "batch_reward": 0.25354730117321017, "critic_loss": 0.16800270968675612, "ae_transition_loss": 0.0205742599144578, "ae_encoder_loss": 0.07518250226974488, "actor_loss": -8.505345207214356, "actor_target_entropy": -6.0, "actor_entropy": 5.248627658843994, "alpha_loss": 0.0007811287958174944, "alpha_value": 0.013465903876961234, "duration": 54.29258346557617, "step": 16500}
{"episode_reward": 57.47336895791804, "episode": 67.0, "batch_reward": 0.25334278255701065, "critic_loss": 0.17650580382347106, "ae_transition_loss": 0.02088595436513424, "ae_encoder_loss": 0.07803817051649094, "actor_loss": -8.711830825805665, "actor_target_entropy": -6.0, "actor_entropy": 5.269025531768799, "alpha_loss": -0.000344227620633319, "alpha_value": 0.013327105529474225, "duration": 54.38943123817444, "step": 16750}
{"episode_reward": 92.19016729446894, "episode": 68.0, "batch_reward": 0.2556966028213501, "critic_loss": 0.22769661223888396, "ae_transition_loss": 0.024419675521552563, "ae_encoder_loss": 0.08226980856060982, "actor_loss": -8.938938842773437, "actor_target_entropy": -6.0, "actor_entropy": 5.320073474884033, "alpha_loss": -0.001172403568169102, "alpha_value": 0.013472328220265752, "duration": 54.25828242301941, "step": 17000}
{"episode_reward": 75.0959513496255, "episode": 69.0, "batch_reward": 0.25385847640037534, "critic_loss": 0.18075580045580864, "ae_transition_loss": 0.02054360892251134, "ae_encoder_loss": 0.08023601457476616, "actor_loss": -9.08510767364502, "actor_target_entropy": -6.0, "actor_entropy": 5.293305400848388, "alpha_loss": -0.00033677349030040207, "alpha_value": 0.013906032764026775, "duration": 54.38296175003052, "step": 17250}
{"episode_reward": 76.1720081205979, "episode": 70.0, "batch_reward": 0.25608039045333864, "critic_loss": 0.14304466485977174, "ae_transition_loss": 0.018335605897009374, "ae_encoder_loss": 0.08326199194788933, "actor_loss": -9.313952033996582, "actor_target_entropy": -6.0, "actor_entropy": 5.3316667213439946, "alpha_loss": -0.0006699369600974023, "alpha_value": 0.014286056402641944, "duration": 54.290396213531494, "step": 17500}
{"episode_reward": 113.7273741508272, "episode": 71.0, "batch_reward": 0.259195585668087, "critic_loss": 0.1900630035996437, "ae_transition_loss": 0.01974370166659355, "ae_encoder_loss": 0.08248635081946849, "actor_loss": -9.449879997253419, "actor_target_entropy": -6.0, "actor_entropy": 5.333114643096923, "alpha_loss": 0.0011636707140132785, "alpha_value": 0.014173360065486505, "duration": 68.90713310241699, "step": 17750}
{"episode_reward": 106.42856981591784, "episode": 72.0, "batch_reward": 0.26162461388111113, "critic_loss": 0.17291058298945428, "ae_transition_loss": 0.02016061557084322, "ae_encoder_loss": 0.08500277057290077, "actor_loss": -9.611242012023926, "actor_target_entropy": -6.0, "actor_entropy": 5.291685451507568, "alpha_loss": 0.0009767817510291934, "alpha_value": 0.013778938258164081, "duration": 54.379623889923096, "step": 18000}
{"episode_reward": 81.78608268618987, "episode": 73.0, "batch_reward": 0.26402654260396957, "critic_loss": 0.21794499731063843, "ae_transition_loss": 0.021192718721926213, "ae_encoder_loss": 0.08209543612599372, "actor_loss": -9.810537269592285, "actor_target_entropy": -6.0, "actor_entropy": 5.262776775360107, "alpha_loss": -0.00018083230848424137, "alpha_value": 0.013438319218249855, "duration": 54.26303505897522, "step": 18250}
{"episode_reward": 107.79193392823518, "episode": 74.0, "batch_reward": 0.2654647668004036, "critic_loss": 0.18121528387069702, "ae_transition_loss": 0.019376645229756833, "ae_encoder_loss": 0.08381418228149413, "actor_loss": -10.03470058441162, "actor_target_entropy": -6.0, "actor_entropy": 5.29220979309082, "alpha_loss": 0.00046176061732694507, "alpha_value": 0.013384142829768492, "duration": 54.624125957489014, "step": 18500}
{"episode_reward": 91.23652015747268, "episode": 75.0, "batch_reward": 0.2660239191651344, "critic_loss": 0.17287883830070497, "ae_transition_loss": 0.019197127506136894, "ae_encoder_loss": 0.08426434528827667, "actor_loss": -10.234146507263183, "actor_target_entropy": -6.0, "actor_entropy": 5.210604312896728, "alpha_loss": -0.0007140026257839054, "alpha_value": 0.013458943513366357, "duration": 54.284284830093384, "step": 18750}
{"episode_reward": 91.41964047751587, "episode": 76.0, "batch_reward": 0.26644891357421874, "critic_loss": 0.2102358160018921, "ae_transition_loss": 0.02129950623959303, "ae_encoder_loss": 0.08524206998944282, "actor_loss": -10.380406204223632, "actor_target_entropy": -6.0, "actor_entropy": 5.247684009552002, "alpha_loss": 0.0004227599026635289, "alpha_value": 0.013445819058280352, "duration": 54.49334740638733, "step": 19000}
{"episode_reward": 72.12925810673036, "episode": 77.0, "batch_reward": 0.26825927752256395, "critic_loss": 0.24819308227300643, "ae_transition_loss": 0.02279390076547861, "ae_encoder_loss": 0.08689666068553925, "actor_loss": -10.564263275146484, "actor_target_entropy": -6.0, "actor_entropy": 5.246227577209472, "alpha_loss": 0.00014721981575712561, "alpha_value": 0.013315712760678342, "duration": 54.52433681488037, "step": 19250}
{"episode_reward": 105.14532739931117, "episode": 78.0, "batch_reward": 0.26982463943958285, "critic_loss": 0.20079555433988572, "ae_transition_loss": 0.02057215178012848, "ae_encoder_loss": 0.0897574009001255, "actor_loss": -10.789533592224121, "actor_target_entropy": -6.0, "actor_entropy": 5.239950412750244, "alpha_loss": -0.00030361684784293175, "alpha_value": 0.01340022002398281, "duration": 54.52896022796631, "step": 19500}
{"episode_reward": 62.22350559596745, "episode": 79.0, "batch_reward": 0.2699117395877838, "critic_loss": 0.225328395485878, "ae_transition_loss": 0.020892904296517373, "ae_encoder_loss": 0.0918683605492115, "actor_loss": -10.979045440673827, "actor_target_entropy": -6.0, "actor_entropy": 5.241488754272461, "alpha_loss": 0.00011094808881171048, "alpha_value": 0.013414631114281992, "duration": 54.34151005744934, "step": 19750}
{"episode_reward": 101.47599786473388, "episode": 80.0, "batch_reward": 0.27113226377964017, "critic_loss": 0.24982470351457595, "ae_transition_loss": 0.022275650426745414, "ae_encoder_loss": 0.09450363785028458, "actor_loss": -11.186836128234864, "actor_target_entropy": -6.0, "actor_entropy": 5.277102157592774, "alpha_loss": 0.0002870459614787251, "alpha_value": 0.013389312382185672, "duration": 54.20394015312195, "step": 20000}
{"episode_reward": 116.58054043888903, "episode": 81.0, "batch_reward": 0.27397623950242994, "critic_loss": 0.23927777051925658, "ae_transition_loss": 0.021743461042642593, "ae_encoder_loss": 0.09249397936463356, "actor_loss": -11.405481880187988, "actor_target_entropy": -6.0, "actor_entropy": 5.2548470878601075, "alpha_loss": 0.00015091597544960678, "alpha_value": 0.0132016360449656, "duration": 74.62800669670105, "step": 20250}
{"episode_reward": 88.46686921555833, "episode": 82.0, "batch_reward": 0.27547097092866896, "critic_loss": 0.21857384872436522, "ae_transition_loss": 0.021115374371409416, "ae_encoder_loss": 0.09434317770600319, "actor_loss": -11.60698585510254, "actor_target_entropy": -6.0, "actor_entropy": 5.250291915893555, "alpha_loss": -0.0007754264939576387, "alpha_value": 0.013488577574064874, "duration": 54.2121741771698, "step": 20500}
{"episode_reward": 118.08320087124362, "episode": 83.0, "batch_reward": 0.27747952175140383, "critic_loss": 0.3232727144360542, "ae_transition_loss": 0.025571286514401437, "ae_encoder_loss": 0.09564447411894798, "actor_loss": -11.7840101852417, "actor_target_entropy": -6.0, "actor_entropy": 5.247505992889404, "alpha_loss": 0.000897618463030085, "alpha_value": 0.013374740776788227, "duration": 54.23270583152771, "step": 20750}
{"episode_reward": 126.24073747183978, "episode": 84.0, "batch_reward": 0.2790523560643196, "critic_loss": 0.21165687054395677, "ae_transition_loss": 0.020837154120206834, "ae_encoder_loss": 0.09222756060957908, "actor_loss": -11.984092422485352, "actor_target_entropy": -6.0, "actor_entropy": 5.217706233978271, "alpha_loss": -0.0004593977078329772, "alpha_value": 0.013252223599011863, "duration": 54.32021951675415, "step": 21000}
{"episode_reward": 93.79261450915416, "episode": 85.0, "batch_reward": 0.280892561674118, "critic_loss": 0.27240535938739774, "ae_transition_loss": 0.023662177629768848, "ae_encoder_loss": 0.09664440187811851, "actor_loss": -12.196334060668946, "actor_target_entropy": -6.0, "actor_entropy": 5.236726455688476, "alpha_loss": 0.0008335623592138291, "alpha_value": 0.013294083961679871, "duration": 54.35059690475464, "step": 21250}
{"episode_reward": 35.73584830494316, "episode": 86.0, "batch_reward": 0.2781129622459412, "critic_loss": 0.22178792399168015, "ae_transition_loss": 0.02171128611266613, "ae_encoder_loss": 0.0971785272359848, "actor_loss": -12.327471725463868, "actor_target_entropy": -6.0, "actor_entropy": 5.249260692596436, "alpha_loss": -0.000551689761923626, "alpha_value": 0.013144489540501184, "duration": 54.38764452934265, "step": 21500}
{"episode_reward": 96.00313146060105, "episode": 87.0, "batch_reward": 0.2813439106941223, "critic_loss": 0.24355233192443848, "ae_transition_loss": 0.022303083419799804, "ae_encoder_loss": 0.09818350878357887, "actor_loss": -12.539791007995605, "actor_target_entropy": -6.0, "actor_entropy": 5.236727725982666, "alpha_loss": 0.0009185106318909675, "alpha_value": 0.013185773305048009, "duration": 54.343255043029785, "step": 21750}
{"episode_reward": 116.64747916605016, "episode": 88.0, "batch_reward": 0.28249761974811555, "critic_loss": 0.25839554190635683, "ae_transition_loss": 0.023020685270428658, "ae_encoder_loss": 0.10073944553732872, "actor_loss": -12.70488877105713, "actor_target_entropy": -6.0, "actor_entropy": 5.229996810913086, "alpha_loss": -0.00019062585034407674, "alpha_value": 0.012980070014179881, "duration": 54.307220220565796, "step": 22000}
