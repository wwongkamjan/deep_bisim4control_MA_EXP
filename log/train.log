{"episode_reward": 0.0, "episode": 1.0, "duration": 17.293684482574463, "step": 250}
{"episode_reward": 8.03772363506006, "episode": 2.0, "duration": 0.34541797637939453, "step": 500}
{"episode_reward": 17.16626315104322, "episode": 3.0, "duration": 0.33795928955078125, "step": 750}
{"episode_reward": 12.073072643141685, "episode": 4.0, "duration": 0.33724427223205566, "step": 1000}
{"episode_reward": 11.095187414981499, "episode": 5.0, "batch_reward": 0.04839861202683804, "critic_loss": 0.011883360337655397, "ae_transition_loss": 0.013254109654389919, "ae_encoder_loss": 0.0007122215957017232, "actor_loss": -0.15198809195730795, "actor_target_entropy": -6.0, "actor_entropy": 5.569728654580608, "alpha_loss": 0.03627599403270554, "alpha_value": 0.006864232546225209, "duration": 281.6791024208069, "step": 1250}
{"episode_reward": 10.864442954304312, "episode": 6.0, "batch_reward": 0.04743046753108501, "critic_loss": 0.027245371837168932, "ae_transition_loss": 0.00876283560320735, "ae_encoder_loss": 0.001109519494115375, "actor_loss": -0.638996317744255, "actor_target_entropy": -6.0, "actor_entropy": 4.329238650560379, "alpha_loss": -0.005346756544429809, "alpha_value": 0.005321798394343799, "duration": 53.692025661468506, "step": 1500}
{"episode_reward": 12.4513433528187, "episode": 7.0, "batch_reward": 0.05002240988612175, "critic_loss": 0.0792751184105873, "ae_transition_loss": 0.01454492493532598, "ae_encoder_loss": 0.0009751053401851096, "actor_loss": -0.6829677276611328, "actor_target_entropy": -6.0, "actor_entropy": 5.272702053070068, "alpha_loss": -0.009771143563848455, "alpha_value": 0.005464152624850594, "duration": 53.77462863922119, "step": 1750}
{"episode_reward": 16.56992383146954, "episode": 8.0, "batch_reward": 0.05227662207186222, "critic_loss": 0.019103959165513516, "ae_transition_loss": 0.004251878498122096, "ae_encoder_loss": 0.0010887506387662143, "actor_loss": -0.9809608979225158, "actor_target_entropy": -6.0, "actor_entropy": 5.004967998504639, "alpha_loss": -0.023171587035059928, "alpha_value": 0.005780019492631769, "duration": 53.75379157066345, "step": 2000}
{"episode_reward": 12.869490244263783, "episode": 9.0, "batch_reward": 0.060484590232372286, "critic_loss": 0.02483876380696893, "ae_transition_loss": 0.0047182387951761485, "ae_encoder_loss": 0.001810529712587595, "actor_loss": -1.1209534707069397, "actor_target_entropy": -6.0, "actor_entropy": 4.836917722702027, "alpha_loss": -0.01574446927383542, "alpha_value": 0.006303662327262839, "duration": 53.7823441028595, "step": 2250}
{"episode_reward": 52.4530539685882, "episode": 10.0, "batch_reward": 0.06954790140688419, "critic_loss": 0.04011422389745712, "ae_transition_loss": 0.0060602443851530555, "ae_encoder_loss": 0.0024046751889400184, "actor_loss": -1.21691002702713, "actor_target_entropy": -6.0, "actor_entropy": 5.177324851989746, "alpha_loss": -0.00946716512273997, "alpha_value": 0.00663049217488189, "duration": 53.736467123031616, "step": 2500}
{"episode_reward": 15.961640850443263, "episode": 11.0, "batch_reward": 0.07206903395056724, "critic_loss": 0.08262014189362527, "ae_transition_loss": 0.008590069618076086, "ae_encoder_loss": 0.0031900876415893436, "actor_loss": -1.274964961051941, "actor_target_entropy": -6.0, "actor_entropy": 5.131621088027954, "alpha_loss": -0.0036085601355880497, "alpha_value": 0.00686493452604404, "duration": 67.00386309623718, "step": 2750}
{"episode_reward": 47.478128705170725, "episode": 12.0, "batch_reward": 0.086274119079113, "critic_loss": 0.0877675568908453, "ae_transition_loss": 0.006960118118673563, "ae_encoder_loss": 0.007224108302034437, "actor_loss": -1.5413345670700074, "actor_target_entropy": -6.0, "actor_entropy": 4.427578172683716, "alpha_loss": -0.02042434165207669, "alpha_value": 0.0071767413867404395, "duration": 53.739654302597046, "step": 3000}
{"episode_reward": 48.842579828904015, "episode": 13.0, "batch_reward": 0.0906302949488163, "critic_loss": 0.33358205860853196, "ae_transition_loss": 0.016071993937715887, "ae_encoder_loss": 0.00811547163873911, "actor_loss": -1.3625603380203246, "actor_target_entropy": -6.0, "actor_entropy": 5.957621536254883, "alpha_loss": -0.0019393381781410426, "alpha_value": 0.00758013194835897, "duration": 53.78530287742615, "step": 3250}
{"episode_reward": 39.174875517915844, "episode": 14.0, "batch_reward": 0.10113554519414902, "critic_loss": 0.0670231993496418, "ae_transition_loss": 0.00902794543094933, "ae_encoder_loss": 0.013219402818009257, "actor_loss": -1.7399782962799073, "actor_target_entropy": -6.0, "actor_entropy": 4.968062732696533, "alpha_loss": -0.015339661213569344, "alpha_value": 0.007993335610632257, "duration": 53.70683407783508, "step": 3500}
{"episode_reward": 43.06969472880537, "episode": 15.0, "batch_reward": 0.11155506637692451, "critic_loss": 0.09465553836524486, "ae_transition_loss": 0.011021235685795546, "ae_encoder_loss": 0.018760665163397788, "actor_loss": -1.914662392616272, "actor_target_entropy": -6.0, "actor_entropy": 4.834882242202759, "alpha_loss": -0.008791270341258496, "alpha_value": 0.008521655239065586, "duration": 53.76341724395752, "step": 3750}
{"episode_reward": 85.76101296183492, "episode": 16.0, "batch_reward": 0.12069275733828545, "critic_loss": 0.11400441958010196, "ae_transition_loss": 0.012442577410489321, "ae_encoder_loss": 0.02347976304218173, "actor_loss": -2.050751181602478, "actor_target_entropy": -6.0, "actor_entropy": 4.744679599761963, "alpha_loss": -0.004519293827237561, "alpha_value": 0.008883788656947783, "duration": 53.76481485366821, "step": 4000}
{"episode_reward": 45.62245165302573, "episode": 17.0, "batch_reward": 0.1178030424118042, "critic_loss": 0.38646173974871634, "ae_transition_loss": 0.017182214878499507, "ae_encoder_loss": 0.01833902747556567, "actor_loss": -1.6169653024673463, "actor_target_entropy": -6.0, "actor_entropy": 4.9835422255992885, "alpha_loss": 0.01343410968396347, "alpha_value": 0.008924404472555622, "duration": 53.74849224090576, "step": 4250}
{"episode_reward": 19.24414807773305, "episode": 18.0, "batch_reward": 0.12393331986665726, "critic_loss": 0.08183109855651856, "ae_transition_loss": 0.01443777211010456, "ae_encoder_loss": 0.027166328586637974, "actor_loss": -1.4158796138763428, "actor_target_entropy": -6.0, "actor_entropy": 5.847777862548828, "alpha_loss": 0.032046495512127876, "alpha_value": 0.0077319003930697615, "duration": 53.71981453895569, "step": 4500}
{"episode_reward": 79.78067850037878, "episode": 19.0, "batch_reward": 0.13104641270637513, "critic_loss": 0.09861129893362522, "ae_transition_loss": 0.01778953716903925, "ae_encoder_loss": 0.033797118335962294, "actor_loss": -1.57328919506073, "actor_target_entropy": -6.0, "actor_entropy": 5.258886232376098, "alpha_loss": 0.009397234153700992, "alpha_value": 0.006948896167502959, "duration": 53.73798441886902, "step": 4750}
{"episode_reward": 29.260202198315323, "episode": 20.0, "batch_reward": 0.12663183951377868, "critic_loss": 0.07386959466338158, "ae_transition_loss": 0.016264213413000106, "ae_encoder_loss": 0.034924348436295986, "actor_loss": -1.546776689529419, "actor_target_entropy": -6.0, "actor_entropy": 5.224339710235595, "alpha_loss": 0.009085779725806788, "alpha_value": 0.006612756360080411, "duration": 53.82133626937866, "step": 5000}
{"episode_reward": 17.958062897893186, "episode": 21.0, "batch_reward": 0.12576234298944472, "critic_loss": 0.05780389766395092, "ae_transition_loss": 0.015062260799109935, "ae_encoder_loss": 0.035936166815459726, "actor_loss": -1.5595692529678344, "actor_target_entropy": -6.0, "actor_entropy": 5.557959415435791, "alpha_loss": 0.008746796088293195, "alpha_value": 0.006317642531214992, "duration": 66.99027514457703, "step": 5250}
{"episode_reward": 22.48199444834766, "episode": 22.0, "batch_reward": 0.12433542630076408, "critic_loss": 0.04822045677900314, "ae_transition_loss": 0.014735918577760458, "ae_encoder_loss": 0.03717471054941416, "actor_loss": -1.668997841835022, "actor_target_entropy": -6.0, "actor_entropy": 5.439280403137207, "alpha_loss": 0.005340218306519091, "alpha_value": 0.006033081878865595, "duration": 53.74890398979187, "step": 5500}
{"episode_reward": 27.086288891936274, "episode": 23.0, "batch_reward": 0.12423394763469696, "critic_loss": 0.0878920892328024, "ae_transition_loss": 0.01601389306038618, "ae_encoder_loss": 0.03708176500350237, "actor_loss": -1.811610080718994, "actor_target_entropy": -6.0, "actor_entropy": 4.96292414855957, "alpha_loss": -0.0008568221621681005, "alpha_value": 0.005923234913017831, "duration": 53.87726020812988, "step": 5750}
{"episode_reward": 36.55131637210991, "episode": 24.0, "batch_reward": 0.12647229406237603, "critic_loss": 0.0602719638645649, "ae_transition_loss": 0.014014967296272517, "ae_encoder_loss": 0.03802511645108461, "actor_loss": -2.0540465202331544, "actor_target_entropy": -6.0, "actor_entropy": 4.484620622634887, "alpha_loss": -0.009339772533625364, "alpha_value": 0.006116796703500994, "duration": 53.77157282829285, "step": 6000}
{"episode_reward": 29.791410601178484, "episode": 25.0, "batch_reward": 0.12323606622219085, "critic_loss": 0.0604988879263401, "ae_transition_loss": 0.013443814903497695, "ae_encoder_loss": 0.03873103100061417, "actor_loss": -2.177505868911743, "actor_target_entropy": -6.0, "actor_entropy": 4.619236705780029, "alpha_loss": -0.00990056012943387, "alpha_value": 0.00659092753925526, "duration": 53.72502064704895, "step": 6250}
{"episode_reward": 17.896577146714108, "episode": 26.0, "batch_reward": 0.12059309047460556, "critic_loss": 0.09958713644742966, "ae_transition_loss": 0.01554548766836524, "ae_encoder_loss": 0.03914182772487402, "actor_loss": -2.245034311294556, "actor_target_entropy": -6.0, "actor_entropy": 5.02375080871582, "alpha_loss": 0.0033367875560652463, "alpha_value": 0.006769113567003362, "duration": 53.739588499069214, "step": 6500}
{"episode_reward": 20.332071324139918, "episode": 27.0, "batch_reward": 0.12475545561313629, "critic_loss": 0.05362432178854942, "ae_transition_loss": 0.0127334946654737, "ae_encoder_loss": 0.03966482630372047, "actor_loss": -2.3448458614349366, "actor_target_entropy": -6.0, "actor_entropy": 5.099221523284912, "alpha_loss": 0.005871226676739752, "alpha_value": 0.006514604046114036, "duration": 53.8344144821167, "step": 6750}
{"episode_reward": 58.324884544870805, "episode": 28.0, "batch_reward": 0.12548800119757653, "critic_loss": 0.06007894213497639, "ae_transition_loss": 0.012932706594467163, "ae_encoder_loss": 0.04049086348712444, "actor_loss": -2.469166193008423, "actor_target_entropy": -6.0, "actor_entropy": 5.152397048950196, "alpha_loss": 0.0002974064778536558, "alpha_value": 0.006325985963264145, "duration": 53.70142221450806, "step": 7000}
{"episode_reward": 38.81307504468915, "episode": 29.0, "batch_reward": 0.12802961161732673, "critic_loss": 0.06988590422272682, "ae_transition_loss": 0.013630747571587562, "ae_encoder_loss": 0.041458517648279666, "actor_loss": -2.677606981277466, "actor_target_entropy": -6.0, "actor_entropy": 5.126188957214356, "alpha_loss": -0.0026500443754484877, "alpha_value": 0.006395301773699033, "duration": 53.73144030570984, "step": 7250}
{"episode_reward": 53.39535794049057, "episode": 30.0, "batch_reward": 0.12957853102684022, "critic_loss": 0.07436787712574006, "ae_transition_loss": 0.013476776517927646, "ae_encoder_loss": 0.04031826112419367, "actor_loss": -2.8070606422424316, "actor_target_entropy": -6.0, "actor_entropy": 5.223538372039795, "alpha_loss": -0.0004635938107967377, "alpha_value": 0.006515010999708392, "duration": 53.79736089706421, "step": 7500}
{"episode_reward": 31.730826857571966, "episode": 31.0, "batch_reward": 0.1323645920753479, "critic_loss": 0.06804179775714875, "ae_transition_loss": 0.013480945531278848, "ae_encoder_loss": 0.04210420437902212, "actor_loss": -2.97539448928833, "actor_target_entropy": -6.0, "actor_entropy": 5.152376125335693, "alpha_loss": -0.0007586618714267388, "alpha_value": 0.006516081076577752, "duration": 67.26907896995544, "step": 7750}
{"episode_reward": 76.15656922657736, "episode": 32.0, "batch_reward": 0.13692412090301515, "critic_loss": 0.09447630380094052, "ae_transition_loss": 0.014338653944432735, "ae_encoder_loss": 0.043495952308177946, "actor_loss": -3.1436176013946535, "actor_target_entropy": -6.0, "actor_entropy": 5.218577621459961, "alpha_loss": -0.00643677196954377, "alpha_value": 0.006799332245212211, "duration": 53.70235514640808, "step": 8000}
{"episode_reward": 67.42771217342141, "episode": 33.0, "batch_reward": 0.14008187597990035, "critic_loss": 0.06823773823678493, "ae_transition_loss": 0.013060269866138697, "ae_encoder_loss": 0.044393358640372756, "actor_loss": -3.3292557621002197, "actor_target_entropy": -6.0, "actor_entropy": 5.250129852294922, "alpha_loss": -0.006572700234130025, "alpha_value": 0.007206616907850075, "duration": 53.736507177352905, "step": 8250}
{"episode_reward": 52.37107348359428, "episode": 34.0, "batch_reward": 0.14312368258833885, "critic_loss": 0.07663512583076953, "ae_transition_loss": 0.01320430126413703, "ae_encoder_loss": 0.04544744192808867, "actor_loss": -3.454578779220581, "actor_target_entropy": -6.0, "actor_entropy": 5.146593845367431, "alpha_loss": -0.014094158045947552, "alpha_value": 0.008072975886629427, "duration": 53.90852975845337, "step": 8500}
{"episode_reward": 68.04009943774595, "episode": 35.0, "batch_reward": 0.14747300297021865, "critic_loss": 0.08189380396902561, "ae_transition_loss": 0.01427958057820797, "ae_encoder_loss": 0.045059595063328746, "actor_loss": -3.5871661949157714, "actor_target_entropy": -6.0, "actor_entropy": 5.354283195495605, "alpha_loss": -0.008394124918617308, "alpha_value": 0.009185469920792501, "duration": 53.785913944244385, "step": 8750}
{"episode_reward": 68.5541412306736, "episode": 36.0, "batch_reward": 0.15005989646911622, "critic_loss": 0.10683211179077626, "ae_transition_loss": 0.016186240065842867, "ae_encoder_loss": 0.04906570890545845, "actor_loss": -3.7170142669677735, "actor_target_entropy": -6.0, "actor_entropy": 5.405853694915772, "alpha_loss": -0.003409746100194752, "alpha_value": 0.009910767788211199, "duration": 53.85271334648132, "step": 9000}
{"episode_reward": 53.034990341916675, "episode": 37.0, "batch_reward": 0.15016784739494324, "critic_loss": 0.08803121246397495, "ae_transition_loss": 0.014672969289124012, "ae_encoder_loss": 0.04784351823478937, "actor_loss": -3.859167957305908, "actor_target_entropy": -6.0, "actor_entropy": 5.692279678344726, "alpha_loss": 0.005344654238549992, "alpha_value": 0.009777718345492997, "duration": 53.861247062683105, "step": 9250}
{"episode_reward": 45.79052166961286, "episode": 38.0, "batch_reward": 0.15504092854261398, "critic_loss": 0.08130340668559075, "ae_transition_loss": 0.014850610692054034, "ae_encoder_loss": 0.052048937186598775, "actor_loss": -4.016093629837036, "actor_target_entropy": -6.0, "actor_entropy": 5.639273380279541, "alpha_loss": 0.006734059926355258, "alpha_value": 0.009078063088571809, "duration": 53.801554918289185, "step": 9500}
{"episode_reward": 67.51719117682447, "episode": 39.0, "batch_reward": 0.15480490824580193, "critic_loss": 0.11305758015811443, "ae_transition_loss": 0.01682852567732334, "ae_encoder_loss": 0.05169564118981362, "actor_loss": -4.115481916427612, "actor_target_entropy": -6.0, "actor_entropy": 5.593795059204101, "alpha_loss": 0.004775458746356889, "alpha_value": 0.008468381403081714, "duration": 53.839892625808716, "step": 9750}
{"episode_reward": 46.36855650503253, "episode": 40.0, "batch_reward": 0.15671768534183503, "critic_loss": 0.11521348144114017, "ae_transition_loss": 0.016767601646482944, "ae_encoder_loss": 0.050067883178591725, "actor_loss": -4.260615642547608, "actor_target_entropy": -6.0, "actor_entropy": 5.5590587272644045, "alpha_loss": 0.00026303333055693656, "alpha_value": 0.008173779591681262, "duration": 53.92265033721924, "step": 10000}
{"episode_reward": 75.89446715874048, "episode": 41.0, "batch_reward": 0.15999998730421067, "critic_loss": 0.10136964145302772, "ae_transition_loss": 0.0158701794706285, "ae_encoder_loss": 0.05525057871639728, "actor_loss": -4.47022622680664, "actor_target_entropy": -6.0, "actor_entropy": 5.5052468147277835, "alpha_loss": -0.000842106154654175, "alpha_value": 0.008178731516483462, "duration": 74.16675114631653, "step": 10250}
{"episode_reward": 74.41995912171251, "episode": 42.0, "batch_reward": 0.16364350235462188, "critic_loss": 0.1044066508114338, "ae_transition_loss": 0.016362841565161945, "ae_encoder_loss": 0.059938500344753266, "actor_loss": -4.6433940086364744, "actor_target_entropy": -6.0, "actor_entropy": 5.423074462890625, "alpha_loss": -0.0032343688971595837, "alpha_value": 0.008431834049465552, "duration": 53.796828746795654, "step": 10500}
{"episode_reward": 72.84028099566645, "episode": 43.0, "batch_reward": 0.16903808468580245, "critic_loss": 0.21713240125775338, "ae_transition_loss": 0.02093406568095088, "ae_encoder_loss": 0.060845844134688375, "actor_loss": -4.7592191314697265, "actor_target_entropy": -6.0, "actor_entropy": 5.6955612258911135, "alpha_loss": 0.0002891290932893753, "alpha_value": 0.008692763241402897, "duration": 53.9067645072937, "step": 10750}
{"episode_reward": 100.54262960783592, "episode": 44.0, "batch_reward": 0.16992669117450715, "critic_loss": 0.13189265078306198, "ae_transition_loss": 0.018688950423151253, "ae_encoder_loss": 0.06900849065184593, "actor_loss": -4.973516983032226, "actor_target_entropy": -6.0, "actor_entropy": 5.573714351654052, "alpha_loss": -0.002111846426036209, "alpha_value": 0.008719598916112594, "duration": 53.768330335617065, "step": 11000}
{"episode_reward": 45.525993939070666, "episode": 45.0, "batch_reward": 0.17086715352535248, "critic_loss": 0.11602986243367196, "ae_transition_loss": 0.017841858483850954, "ae_encoder_loss": 0.07093622380495071, "actor_loss": -5.141409481048584, "actor_target_entropy": -6.0, "actor_entropy": 5.526198863983154, "alpha_loss": -0.0017643129755742849, "alpha_value": 0.009000705458173278, "duration": 53.72596883773804, "step": 11250}
{"episode_reward": 60.40403777566521, "episode": 46.0, "batch_reward": 0.17252642178535463, "critic_loss": 0.1632331493794918, "ae_transition_loss": 0.019568390380591154, "ae_encoder_loss": 0.0693610054552555, "actor_loss": -5.268850498199463, "actor_target_entropy": -6.0, "actor_entropy": 5.46540697479248, "alpha_loss": -0.003699299578089267, "alpha_value": 0.0094083421128258, "duration": 53.878259897232056, "step": 11500}
{"episode_reward": 42.33334467836156, "episode": 47.0, "batch_reward": 0.1748336466550827, "critic_loss": 0.11119031867384911, "ae_transition_loss": 0.017227249577641487, "ae_encoder_loss": 0.06960392788052559, "actor_loss": -5.392721408843994, "actor_target_entropy": -6.0, "actor_entropy": 5.550856388092041, "alpha_loss": -0.002279856252949685, "alpha_value": 0.009961879916375867, "duration": 53.77119445800781, "step": 11750}
{"episode_reward": 68.03418318264065, "episode": 48.0, "batch_reward": 0.17548774188756944, "critic_loss": 0.11711608147621155, "ae_transition_loss": 0.017812711603939532, "ae_encoder_loss": 0.06913267076015472, "actor_loss": -5.48778226852417, "actor_target_entropy": -6.0, "actor_entropy": 5.5628869934082035, "alpha_loss": 0.0007367917678784579, "alpha_value": 0.010145389111613697, "duration": 53.91639447212219, "step": 12000}
{"episode_reward": 59.41167820860439, "episode": 49.0, "batch_reward": 0.1780356878042221, "critic_loss": 0.13034436449408532, "ae_transition_loss": 0.018262284703552723, "ae_encoder_loss": 0.0671221078634262, "actor_loss": -5.6030456199645995, "actor_target_entropy": -6.0, "actor_entropy": 5.603571716308593, "alpha_loss": 0.0015760937435552477, "alpha_value": 0.009931997130017111, "duration": 53.83067774772644, "step": 12250}
{"episode_reward": 52.59068412226805, "episode": 50.0, "batch_reward": 0.17801658976078033, "critic_loss": 0.12761477580666541, "ae_transition_loss": 0.018191658314317464, "ae_encoder_loss": 0.06667199771106243, "actor_loss": -5.711888282775879, "actor_target_entropy": -6.0, "actor_entropy": 5.5571916275024416, "alpha_loss": -0.0017112133482005446, "alpha_value": 0.009927009471755604, "duration": 53.767481088638306, "step": 12500}
{"episode_reward": 57.028799443286445, "episode": 51.0, "batch_reward": 0.1774213152527809, "critic_loss": 0.12115088149905205, "ae_transition_loss": 0.0181781634837389, "ae_encoder_loss": 0.06556829744577408, "actor_loss": -5.834081546783447, "actor_target_entropy": -6.0, "actor_entropy": 5.579816394805908, "alpha_loss": 0.0002905503259971738, "alpha_value": 0.010005626649938308, "duration": 67.40718650817871, "step": 12750}
{"episode_reward": 43.74774157079483, "episode": 52.0, "batch_reward": 0.17793314731121063, "critic_loss": 0.17127804234623908, "ae_transition_loss": 0.021567458741366865, "ae_encoder_loss": 0.06781215433776379, "actor_loss": -5.948761432647705, "actor_target_entropy": -6.0, "actor_entropy": 5.585465835571289, "alpha_loss": -0.00043682130938395855, "alpha_value": 0.010101065575089255, "duration": 53.86598873138428, "step": 13000}
{"episode_reward": 56.05190301431215, "episode": 53.0, "batch_reward": 0.1784028571844101, "critic_loss": 0.10205836156010628, "ae_transition_loss": 0.016912460159510374, "ae_encoder_loss": 0.06853953044116497, "actor_loss": -6.088104530334473, "actor_target_entropy": -6.0, "actor_entropy": 5.481572277069092, "alpha_loss": 0.0002227731980383396, "alpha_value": 0.010086135044751055, "duration": 53.71235132217407, "step": 13250}
{"episode_reward": 34.92470651312232, "episode": 54.0, "batch_reward": 0.18112009221315384, "critic_loss": 0.14474629443883896, "ae_transition_loss": 0.01951170324161649, "ae_encoder_loss": 0.07154773807525634, "actor_loss": -6.268118549346924, "actor_target_entropy": -6.0, "actor_entropy": 5.445764263153076, "alpha_loss": 0.0008908303922507912, "alpha_value": 0.010001420669534194, "duration": 53.90349364280701, "step": 13500}
{"episode_reward": 128.99593335974694, "episode": 55.0, "batch_reward": 0.18623629897832872, "critic_loss": 0.1603413669168949, "ae_transition_loss": 0.020701093014329673, "ae_encoder_loss": 0.07547880871593952, "actor_loss": -6.413410621643067, "actor_target_entropy": -6.0, "actor_entropy": 5.4208765335083005, "alpha_loss": 0.0003968745537567884, "alpha_value": 0.00985322140971427, "duration": 53.7491352558136, "step": 13750}
{"episode_reward": 85.96430926129678, "episode": 56.0, "batch_reward": 0.18884459096193312, "critic_loss": 0.11365710482001305, "ae_transition_loss": 0.01815766840800643, "ae_encoder_loss": 0.07410878868401051, "actor_loss": -6.520429626464844, "actor_target_entropy": -6.0, "actor_entropy": 5.320514274597168, "alpha_loss": 0.00043089777557179333, "alpha_value": 0.009690027319867935, "duration": 53.7880597114563, "step": 14000}
{"episode_reward": 60.80114533117293, "episode": 57.0, "batch_reward": 0.1869185962677002, "critic_loss": 0.14415698871016502, "ae_transition_loss": 0.020267468083649872, "ae_encoder_loss": 0.07535557563602924, "actor_loss": -6.595843254089355, "actor_target_entropy": -6.0, "actor_entropy": 5.324132171630859, "alpha_loss": 0.0005083993225125596, "alpha_value": 0.009666889643526175, "duration": 53.9686176776886, "step": 14250}
{"episode_reward": 42.730180998870956, "episode": 58.0, "batch_reward": 0.18998567110300063, "critic_loss": 0.14900955748558045, "ae_transition_loss": 0.021518500711768866, "ae_encoder_loss": 0.07734978145360946, "actor_loss": -6.724318565368653, "actor_target_entropy": -6.0, "actor_entropy": 5.377015804290772, "alpha_loss": 0.0007192965662106872, "alpha_value": 0.009354731229628321, "duration": 53.77300572395325, "step": 14500}
{"episode_reward": 130.09156238669473, "episode": 59.0, "batch_reward": 0.19384001922607422, "critic_loss": 0.12789600750803948, "ae_transition_loss": 0.02034221851825714, "ae_encoder_loss": 0.0800449312478304, "actor_loss": -6.8425983123779295, "actor_target_entropy": -6.0, "actor_entropy": 5.359142871856689, "alpha_loss": -0.0003638008285779506, "alpha_value": 0.009328453574740677, "duration": 53.957213401794434, "step": 14750}
{"episode_reward": 69.50916888237636, "episode": 60.0, "batch_reward": 0.1958998066186905, "critic_loss": 0.16274362590909003, "ae_transition_loss": 0.022941199384629726, "ae_encoder_loss": 0.08511980743706227, "actor_loss": -6.998592784881592, "actor_target_entropy": -6.0, "actor_entropy": 5.4144368019104006, "alpha_loss": 0.0002805966376326978, "alpha_value": 0.009418619018097457, "duration": 53.811400175094604, "step": 15000}
{"episode_reward": 72.35296271710708, "episode": 61.0, "batch_reward": 0.19577267134189605, "critic_loss": 0.14744145607948303, "ae_transition_loss": 0.02176715189218521, "ae_encoder_loss": 0.08568375569581986, "actor_loss": -7.088034893035888, "actor_target_entropy": -6.0, "actor_entropy": 5.342112773895264, "alpha_loss": 0.0006066343078855425, "alpha_value": 0.009246521668145932, "duration": 67.24914145469666, "step": 15250}
{"episode_reward": 39.25159182123525, "episode": 62.0, "batch_reward": 0.19571279907226563, "critic_loss": 0.1416296345591545, "ae_transition_loss": 0.022029451556503772, "ae_encoder_loss": 0.08601644513010978, "actor_loss": -7.190803173065185, "actor_target_entropy": -6.0, "actor_entropy": 5.396816055297852, "alpha_loss": 0.0002112531450111419, "alpha_value": 0.009207141032073367, "duration": 53.906148195266724, "step": 15500}
{"episode_reward": 52.37428053218885, "episode": 63.0, "batch_reward": 0.19703977406024933, "critic_loss": 0.1461219890117645, "ae_transition_loss": 0.021899424925446512, "ae_encoder_loss": 0.08235617896914482, "actor_loss": -7.308296627044678, "actor_target_entropy": -6.0, "actor_entropy": 5.47235884475708, "alpha_loss": 8.377473684959114e-05, "alpha_value": 0.008989473177163877, "duration": 53.78673791885376, "step": 15750}
{"episode_reward": 76.65506638912159, "episode": 64.0, "batch_reward": 0.1979359981417656, "critic_loss": 0.15968293452262877, "ae_transition_loss": 0.02181935678422451, "ae_encoder_loss": 0.08341855409741401, "actor_loss": -7.4003671875, "actor_target_entropy": -6.0, "actor_entropy": 5.438890796661377, "alpha_loss": 0.0008475186701398343, "alpha_value": 0.009029891417057248, "duration": 53.98620367050171, "step": 16000}
{"episode_reward": 69.5224108924192, "episode": 65.0, "batch_reward": 0.19967474377155303, "critic_loss": 0.12452740356326103, "ae_transition_loss": 0.019724985867738725, "ae_encoder_loss": 0.07951702438294887, "actor_loss": -7.533326183319092, "actor_target_entropy": -6.0, "actor_entropy": 5.329073268890381, "alpha_loss": -4.1821275372058155e-05, "alpha_value": 0.008843111146985766, "duration": 53.81049871444702, "step": 16250}
{"episode_reward": 66.5534061377258, "episode": 66.0, "batch_reward": 0.20114150232076644, "critic_loss": 0.1677009628713131, "ae_transition_loss": 0.022085328735411167, "ae_encoder_loss": 0.08074743160605431, "actor_loss": -7.6012895393371585, "actor_target_entropy": -6.0, "actor_entropy": 5.374866458892822, "alpha_loss": -0.0003208307474851608, "alpha_value": 0.008950986955042943, "duration": 53.76995873451233, "step": 16500}
{"episode_reward": 66.24050611582425, "episode": 67.0, "batch_reward": 0.20279284143447876, "critic_loss": 0.1508813484311104, "ae_transition_loss": 0.022945514746010302, "ae_encoder_loss": 0.08224474580585957, "actor_loss": -7.692120723724365, "actor_target_entropy": -6.0, "actor_entropy": 5.4301169471740725, "alpha_loss": 1.3254591031000019e-05, "alpha_value": 0.008898594256777801, "duration": 53.9846875667572, "step": 16750}
{"episode_reward": 81.89284009740473, "episode": 68.0, "batch_reward": 0.20444656455516816, "critic_loss": 0.13685432317852975, "ae_transition_loss": 0.020536272682249546, "ae_encoder_loss": 0.08002571041882038, "actor_loss": -7.793745121002197, "actor_target_entropy": -6.0, "actor_entropy": 5.397285060882568, "alpha_loss": -0.000504792271880433, "alpha_value": 0.009054724846634938, "duration": 53.83954381942749, "step": 17000}
{"episode_reward": 87.40505077939056, "episode": 69.0, "batch_reward": 0.20523469430208205, "critic_loss": 0.15848849809169768, "ae_transition_loss": 0.021702172458171843, "ae_encoder_loss": 0.07894209188222885, "actor_loss": -7.8734383964538575, "actor_target_entropy": -6.0, "actor_entropy": 5.384282115936279, "alpha_loss": 0.0002300031976774335, "alpha_value": 0.009080198219705262, "duration": 53.94120383262634, "step": 17250}
{"episode_reward": 72.22588940132829, "episode": 70.0, "batch_reward": 0.2074260594844818, "critic_loss": 0.14651116394996644, "ae_transition_loss": 0.021376859307289123, "ae_encoder_loss": 0.07935908786952496, "actor_loss": -7.97987675857544, "actor_target_entropy": -6.0, "actor_entropy": 5.437362373352051, "alpha_loss": 0.001100267513655126, "alpha_value": 0.008980368113063627, "duration": 53.87151503562927, "step": 17500}
{"episode_reward": 52.00245373336227, "episode": 71.0, "batch_reward": 0.20771049171686173, "critic_loss": 0.1781966551244259, "ae_transition_loss": 0.023740444898605346, "ae_encoder_loss": 0.08105015578866005, "actor_loss": -8.060747283935546, "actor_target_entropy": -6.0, "actor_entropy": 5.348396549224853, "alpha_loss": -3.080322640016675e-06, "alpha_value": 0.008758504138436523, "duration": 67.32121396064758, "step": 17750}
{"episode_reward": 101.67452415682266, "episode": 72.0, "batch_reward": 0.21090468943119048, "critic_loss": 0.1263860192000866, "ae_transition_loss": 0.020445887662470342, "ae_encoder_loss": 0.08176831640303135, "actor_loss": -8.143889247894288, "actor_target_entropy": -6.0, "actor_entropy": 5.424767677307129, "alpha_loss": -0.00020924571086652577, "alpha_value": 0.008743495731022273, "duration": 53.91975522041321, "step": 18000}
{"episode_reward": 81.26868677385204, "episode": 73.0, "batch_reward": 0.21257819443941117, "critic_loss": 0.1543297148346901, "ae_transition_loss": 0.022465818226337433, "ae_encoder_loss": 0.08068119119107724, "actor_loss": -8.256389881134034, "actor_target_entropy": -6.0, "actor_entropy": 5.421048519134522, "alpha_loss": 3.157516103237868e-05, "alpha_value": 0.008719749627970484, "duration": 53.796263694763184, "step": 18250}
{"episode_reward": 94.39052157730292, "episode": 74.0, "batch_reward": 0.21417803198099136, "critic_loss": 0.16837035167217254, "ae_transition_loss": 0.02344260463863611, "ae_encoder_loss": 0.0853636671602726, "actor_loss": -8.370921230316162, "actor_target_entropy": -6.0, "actor_entropy": 5.4160524787902835, "alpha_loss": -0.000568432264495641, "alpha_value": 0.008855148230769511, "duration": 53.96583652496338, "step": 18500}
{"episode_reward": 68.75639595045868, "episode": 75.0, "batch_reward": 0.2142447499036789, "critic_loss": 0.20648810908198356, "ae_transition_loss": 0.02446443023532629, "ae_encoder_loss": 0.08139568848907948, "actor_loss": -8.499303283691406, "actor_target_entropy": -6.0, "actor_entropy": 5.458131065368653, "alpha_loss": 0.00027824250725097955, "alpha_value": 0.008945047229245832, "duration": 53.841232776641846, "step": 18750}
{"episode_reward": 75.76369425514031, "episode": 76.0, "batch_reward": 0.21485018980503082, "critic_loss": 0.16515340563654898, "ae_transition_loss": 0.022795940592885016, "ae_encoder_loss": 0.08317751757800579, "actor_loss": -8.58030253982544, "actor_target_entropy": -6.0, "actor_entropy": 5.4359544715881345, "alpha_loss": -0.001096606323728338, "alpha_value": 0.009103040290804292, "duration": 53.7568473815918, "step": 19000}
{"episode_reward": 91.11029779002223, "episode": 77.0, "batch_reward": 0.21809897184371949, "critic_loss": 0.17472877055406572, "ae_transition_loss": 0.023784862406551838, "ae_encoder_loss": 0.08470568421483039, "actor_loss": -8.715051109313965, "actor_target_entropy": -6.0, "actor_entropy": 5.441379028320313, "alpha_loss": -0.0002860026778653264, "alpha_value": 0.00935739993653235, "duration": 53.98748278617859, "step": 19250}
{"episode_reward": 82.72811407786529, "episode": 78.0, "batch_reward": 0.21937746143341064, "critic_loss": 0.17915912184119226, "ae_transition_loss": 0.023305000647902488, "ae_encoder_loss": 0.08756088435649872, "actor_loss": -8.883879295349121, "actor_target_entropy": -6.0, "actor_entropy": 5.40986672592163, "alpha_loss": -4.041904932819307e-05, "alpha_value": 0.009381135515959059, "duration": 53.74627447128296, "step": 19500}
{"episode_reward": 90.2910549437972, "episode": 79.0, "batch_reward": 0.22242990738153456, "critic_loss": 0.16706794494390487, "ae_transition_loss": 0.022148365013301374, "ae_encoder_loss": 0.08566271910071373, "actor_loss": -9.042461982727051, "actor_target_entropy": -6.0, "actor_entropy": 5.422382236480713, "alpha_loss": -0.00047338617569766937, "alpha_value": 0.009501351987465436, "duration": 54.02710008621216, "step": 19750}
{"episode_reward": 98.66140067454349, "episode": 80.0, "batch_reward": 0.22318642717599868, "critic_loss": 0.16875377437472344, "ae_transition_loss": 0.022458257727324963, "ae_encoder_loss": 0.08893671353161335, "actor_loss": -9.152385955810546, "actor_target_entropy": -6.0, "actor_entropy": 5.484735057830811, "alpha_loss": -5.356428539380431e-05, "alpha_value": 0.009551367924249132, "duration": 53.79607105255127, "step": 20000}
{"episode_reward": 59.46658094689863, "episode": 81.0, "batch_reward": 0.2245061095356941, "critic_loss": 0.211839232891798, "ae_transition_loss": 0.025597527354955674, "ae_encoder_loss": 0.09284099142253399, "actor_loss": -9.25487126159668, "actor_target_entropy": -6.0, "actor_entropy": 5.454414665222168, "alpha_loss": -7.924279756844043e-05, "alpha_value": 0.009605879527911206, "duration": 74.18213891983032, "step": 20250}
{"episode_reward": 112.10748475247227, "episode": 82.0, "batch_reward": 0.22598296791315078, "critic_loss": 0.23243992805480956, "ae_transition_loss": 0.026165951572358608, "ae_encoder_loss": 0.09786943559348583, "actor_loss": -9.447799827575684, "actor_target_entropy": -6.0, "actor_entropy": 5.432251224517822, "alpha_loss": -0.0009893434378318489, "alpha_value": 0.009750107903824839, "duration": 53.870091915130615, "step": 20500}
{"episode_reward": 91.93783176886417, "episode": 83.0, "batch_reward": 0.22909001410007476, "critic_loss": 0.2321490153372288, "ae_transition_loss": 0.026191166304051876, "ae_encoder_loss": 0.1026790702790022, "actor_loss": -9.655640747070313, "actor_target_entropy": -6.0, "actor_entropy": 5.396741245269776, "alpha_loss": -0.00020465375669300557, "alpha_value": 0.009994899818009346, "duration": 53.9690043926239, "step": 20750}
{"episode_reward": 81.8294866685106, "episode": 84.0, "batch_reward": 0.22761767446994782, "critic_loss": 0.16221038615703584, "ae_transition_loss": 0.0211499729976058, "ae_encoder_loss": 0.09637875637412072, "actor_loss": -9.765663459777832, "actor_target_entropy": -6.0, "actor_entropy": 5.367199440002441, "alpha_loss": -0.00030283833516296, "alpha_value": 0.010043278696449384, "duration": 53.891834020614624, "step": 21000}
{"episode_reward": 71.67257726548816, "episode": 85.0, "batch_reward": 0.23123224872350692, "critic_loss": 0.2768683624863625, "ae_transition_loss": 0.025668812319636344, "ae_encoder_loss": 0.09675405496358871, "actor_loss": -9.902059661865234, "actor_target_entropy": -6.0, "actor_entropy": 5.40909880065918, "alpha_loss": -0.00013598951208405196, "alpha_value": 0.010167991107616146, "duration": 53.79470658302307, "step": 21250}
{"episode_reward": 150.23196227111177, "episode": 86.0, "batch_reward": 0.23443880581855775, "critic_loss": 0.23005690240859986, "ae_transition_loss": 0.024548824213445185, "ae_encoder_loss": 0.10164554160833358, "actor_loss": -10.099328819274902, "actor_target_entropy": -6.0, "actor_entropy": 5.390144985198974, "alpha_loss": -0.0009206849539186805, "alpha_value": 0.010400896614739284, "duration": 54.04760241508484, "step": 21500}
{"episode_reward": 95.17105306763582, "episode": 87.0, "batch_reward": 0.23892409586906432, "critic_loss": 0.24858712637424468, "ae_transition_loss": 0.025812345243990422, "ae_encoder_loss": 0.10513040606677532, "actor_loss": -10.278205749511718, "actor_target_entropy": -6.0, "actor_entropy": 5.356657730102539, "alpha_loss": -0.0009908108138479293, "alpha_value": 0.010709632809044196, "duration": 53.77955222129822, "step": 21750}
{"episode_reward": 163.04479543981893, "episode": 88.0, "batch_reward": 0.24223951596021653, "critic_loss": 0.2891950956583023, "ae_transition_loss": 0.02811577434837818, "ae_encoder_loss": 0.11376317393779754, "actor_loss": -10.500667465209961, "actor_target_entropy": -6.0, "actor_entropy": 5.387122703552246, "alpha_loss": 0.0005133533647749573, "alpha_value": 0.01090900153599695, "duration": 54.0438392162323, "step": 22000}
{"episode_reward": 151.62389262077318, "episode": 89.0, "batch_reward": 0.24548495995998382, "critic_loss": 0.291993486225605, "ae_transition_loss": 0.028309438720345498, "ae_encoder_loss": 0.11962661731243134, "actor_loss": -10.769302070617675, "actor_target_entropy": -6.0, "actor_entropy": 5.4404390411376955, "alpha_loss": -0.0018093586049508304, "alpha_value": 0.010984575141222086, "duration": 53.76627063751221, "step": 22250}
{"episode_reward": 115.51107956933535, "episode": 90.0, "batch_reward": 0.24860866206884386, "critic_loss": 0.2539446380138397, "ae_transition_loss": 0.026807454973459245, "ae_encoder_loss": 0.12016440656781197, "actor_loss": -10.968144256591797, "actor_target_entropy": -6.0, "actor_entropy": 5.4238888473510745, "alpha_loss": -0.0005887164063751697, "alpha_value": 0.011508299367863793, "duration": 53.79038405418396, "step": 22500}
{"episode_reward": 98.21365849665878, "episode": 91.0, "batch_reward": 0.24920106357336044, "critic_loss": 0.28621552091836927, "ae_transition_loss": 0.02786203420907259, "ae_encoder_loss": 0.12057303816080094, "actor_loss": -11.158216339111329, "actor_target_entropy": -6.0, "actor_entropy": 5.429032337188721, "alpha_loss": -0.0005456448781769723, "alpha_value": 0.011775912221565064, "duration": 67.6375527381897, "step": 22750}
{"episode_reward": 191.5717868336263, "episode": 92.0, "batch_reward": 0.2563663492798805, "critic_loss": 0.34643845790624617, "ae_transition_loss": 0.03197740076482296, "ae_encoder_loss": 0.1330539131462574, "actor_loss": -11.390955436706543, "actor_target_entropy": -6.0, "actor_entropy": 5.4531634941101075, "alpha_loss": -0.0005607285238802433, "alpha_value": 0.01179637501213835, "duration": 54.05995726585388, "step": 23000}
{"episode_reward": 138.3108827245583, "episode": 93.0, "batch_reward": 0.2594601221084595, "critic_loss": 0.31448622834682466, "ae_transition_loss": 0.03090655341744423, "ae_encoder_loss": 0.13311498004198075, "actor_loss": -11.586567733764648, "actor_target_entropy": -6.0, "actor_entropy": 5.505805648803711, "alpha_loss": 0.00021963017038069665, "alpha_value": 0.012099914734062274, "duration": 53.84467935562134, "step": 23250}
{"episode_reward": 112.65163957326484, "episode": 94.0, "batch_reward": 0.2600908817052841, "critic_loss": 0.26450348752737046, "ae_transition_loss": 0.029886159427464008, "ae_encoder_loss": 0.13403187343478204, "actor_loss": -11.699051193237304, "actor_target_entropy": -6.0, "actor_entropy": 5.539511867523194, "alpha_loss": -2.0898212678730488e-05, "alpha_value": 0.01195089028041624, "duration": 53.790756702423096, "step": 23500}
{"episode_reward": 71.38435237481563, "episode": 95.0, "batch_reward": 0.2613538897633553, "critic_loss": 0.28747940212488177, "ae_transition_loss": 0.03060008393973112, "ae_encoder_loss": 0.13724085935950278, "actor_loss": -11.868567932128906, "actor_target_entropy": -6.0, "actor_entropy": 5.5384405364990235, "alpha_loss": -0.00021205022232607007, "alpha_value": 0.012103797815239471, "duration": 54.0778067111969, "step": 23750}
{"episode_reward": 85.77761117125951, "episode": 96.0, "batch_reward": 0.26140455818176267, "critic_loss": 0.3295427757501602, "ae_transition_loss": 0.03261833306401968, "ae_encoder_loss": 0.13691263607144355, "actor_loss": -12.047951110839843, "actor_target_entropy": -6.0, "actor_entropy": 5.532538322448731, "alpha_loss": -5.574613530188799e-05, "alpha_value": 0.01190571285834642, "duration": 53.97367787361145, "step": 24000}
{"episode_reward": 155.95705129923113, "episode": 97.0, "batch_reward": 0.2630785991549492, "critic_loss": 0.34206529557704923, "ae_transition_loss": 0.034335229724645616, "ae_encoder_loss": 0.142882312476635, "actor_loss": -12.168211936950684, "actor_target_entropy": -6.0, "actor_entropy": 5.529238201141357, "alpha_loss": 0.0004139665062539279, "alpha_value": 0.01221937510365547, "duration": 53.94356441497803, "step": 24250}
{"episode_reward": 101.27761532430682, "episode": 98.0, "batch_reward": 0.2663144998550415, "critic_loss": 0.3023910106420517, "ae_transition_loss": 0.03260370486974716, "ae_encoder_loss": 0.14228575792908668, "actor_loss": -12.33955298614502, "actor_target_entropy": -6.0, "actor_entropy": 5.549055183410645, "alpha_loss": 0.0004164942866191268, "alpha_value": 0.01178647288746988, "duration": 53.82000756263733, "step": 24500}
{"episode_reward": 75.56211856326003, "episode": 99.0, "batch_reward": 0.26640217697620394, "critic_loss": 0.3068008822798729, "ae_transition_loss": 0.03323793559521437, "ae_encoder_loss": 0.1381160708963871, "actor_loss": -12.490186569213867, "actor_target_entropy": -6.0, "actor_entropy": 5.523685192108155, "alpha_loss": -0.0007617946232203394, "alpha_value": 0.012021172031404305, "duration": 54.11970090866089, "step": 24750}
{"episode_reward": 83.93930399762068, "episode": 100.0, "batch_reward": 0.26579206621646884, "critic_loss": 0.33428524482250216, "ae_transition_loss": 0.033955874860286714, "ae_encoder_loss": 0.14096349650621415, "actor_loss": -12.574381477355956, "actor_target_entropy": -6.0, "actor_entropy": 5.560852695465088, "alpha_loss": 0.0005614515459164977, "alpha_value": 0.011887726001080144, "duration": 53.74956822395325, "step": 25000}
{"episode_reward": 80.58947968959681, "episode": 101.0, "batch_reward": 0.2694788213968277, "critic_loss": 0.4073532040119171, "ae_transition_loss": 0.03876403748989105, "ae_encoder_loss": 0.1487655414044857, "actor_loss": -12.742994178771973, "actor_target_entropy": -6.0, "actor_entropy": 5.538248237609864, "alpha_loss": 0.0001045226096175611, "alpha_value": 0.011795112887281987, "duration": 67.69410109519958, "step": 25250}
{"episode_reward": 160.6665793906057, "episode": 102.0, "batch_reward": 0.2711380062699318, "critic_loss": 0.4146556969881058, "ae_transition_loss": 0.03791995574533939, "ae_encoder_loss": 0.15391089749336243, "actor_loss": -12.93464461517334, "actor_target_entropy": -6.0, "actor_entropy": 5.4686289939880375, "alpha_loss": -0.00020624687150120734, "alpha_value": 0.011803858450674653, "duration": 53.733832359313965, "step": 25500}
{"episode_reward": 111.44007840988253, "episode": 103.0, "batch_reward": 0.27271538990736005, "critic_loss": 0.39185896670818327, "ae_transition_loss": 0.03726984733343124, "ae_encoder_loss": 0.1665407537817955, "actor_loss": -13.158544555664063, "actor_target_entropy": -6.0, "actor_entropy": 5.551841697692871, "alpha_loss": -0.002248347633285448, "alpha_value": 0.012267176121841002, "duration": 54.082480907440186, "step": 25750}
{"episode_reward": 63.68895796043485, "episode": 104.0, "batch_reward": 0.2723346535563469, "critic_loss": 0.41808400881290436, "ae_transition_loss": 0.03835883240401745, "ae_encoder_loss": 0.1587588548362255, "actor_loss": -13.306149513244629, "actor_target_entropy": -6.0, "actor_entropy": 5.553790912628174, "alpha_loss": 0.0012729565231129527, "alpha_value": 0.012569046439944154, "duration": 53.911152839660645, "step": 26000}
{"episode_reward": 117.85312681006295, "episode": 105.0, "batch_reward": 0.27501628786325455, "critic_loss": 0.33776847273111343, "ae_transition_loss": 0.035144585952162744, "ae_encoder_loss": 0.1613765116930008, "actor_loss": -13.474058677673339, "actor_target_entropy": -6.0, "actor_entropy": 5.590489727020263, "alpha_loss": -0.00024153835442848503, "alpha_value": 0.012262533938889361, "duration": 54.079164266586304, "step": 26250}
{"episode_reward": 61.89824531500163, "episode": 106.0, "batch_reward": 0.27491327160596846, "critic_loss": 0.33892955869436264, "ae_transition_loss": 0.033850417539477345, "ae_encoder_loss": 0.1591924223601818, "actor_loss": -13.588293060302734, "actor_target_entropy": -6.0, "actor_entropy": 5.559521606445313, "alpha_loss": 0.0005244738226756454, "alpha_value": 0.012360756797147722, "duration": 53.78559970855713, "step": 26500}
{"episode_reward": 73.5136150995513, "episode": 107.0, "batch_reward": 0.27410832977294924, "critic_loss": 0.36597380304336546, "ae_transition_loss": 0.03491353359073401, "ae_encoder_loss": 0.16048333713412286, "actor_loss": -13.671460678100585, "actor_target_entropy": -6.0, "actor_entropy": 5.594456390380859, "alpha_loss": -0.0003512015449814498, "alpha_value": 0.012291890252020668, "duration": 54.11392140388489, "step": 26750}
{"episode_reward": 93.09505517923577, "episode": 108.0, "batch_reward": 0.27666731375455855, "critic_loss": 0.47637790215015413, "ae_transition_loss": 0.04005367293208838, "ae_encoder_loss": 0.16163340145349503, "actor_loss": -13.868209251403808, "actor_target_entropy": -6.0, "actor_entropy": 5.548918117523193, "alpha_loss": 0.0006306394701823592, "alpha_value": 0.012356275373318402, "duration": 53.87179207801819, "step": 27000}
{"episode_reward": 164.40415846770514, "episode": 109.0, "batch_reward": 0.28093017381429675, "critic_loss": 0.43301841151714326, "ae_transition_loss": 0.03875732886046171, "ae_encoder_loss": 0.16412508115172386, "actor_loss": -14.122609222412109, "actor_target_entropy": -6.0, "actor_entropy": 5.556465034484863, "alpha_loss": -0.000658400067826733, "alpha_value": 0.012168268210726738, "duration": 54.07980251312256, "step": 27250}
{"episode_reward": 185.2565812743678, "episode": 110.0, "batch_reward": 0.28295374238491056, "critic_loss": 0.4720798864364624, "ae_transition_loss": 0.040748906694352625, "ae_encoder_loss": 0.17316955435276032, "actor_loss": -14.213248458862305, "actor_target_entropy": -6.0, "actor_entropy": 5.643576900482178, "alpha_loss": -0.000738738264888525, "alpha_value": 0.012342941427546333, "duration": 53.76011323928833, "step": 27500}
{"episode_reward": 116.13131105774566, "episode": 111.0, "batch_reward": 0.2852600910067558, "critic_loss": 0.5250645642280578, "ae_transition_loss": 0.04545407244563103, "ae_encoder_loss": 0.17864929604530336, "actor_loss": -14.446918373107911, "actor_target_entropy": -6.0, "actor_entropy": 5.67091446685791, "alpha_loss": 0.0007509547187946737, "alpha_value": 0.012364935372457008, "duration": 67.76508927345276, "step": 27750}
{"episode_reward": 128.97471241647824, "episode": 112.0, "batch_reward": 0.28818157529830934, "critic_loss": 0.5966192889213562, "ae_transition_loss": 0.048125234499573705, "ae_encoder_loss": 0.1844092189669609, "actor_loss": -14.732898696899413, "actor_target_entropy": -6.0, "actor_entropy": 5.617055278778076, "alpha_loss": -0.0010715878293849528, "alpha_value": 0.01242776795377902, "duration": 54.036253929138184, "step": 28000}
{"episode_reward": 115.11197547480029, "episode": 113.0, "batch_reward": 0.28988735258579257, "critic_loss": 0.49462532258033753, "ae_transition_loss": 0.04211555433273315, "ae_encoder_loss": 0.18161572688817978, "actor_loss": -14.899121589660645, "actor_target_entropy": -6.0, "actor_entropy": 5.62114436340332, "alpha_loss": -4.2866081930696966e-06, "alpha_value": 0.012558545772302258, "duration": 53.869521141052246, "step": 28250}
{"episode_reward": 92.5636659327078, "episode": 114.0, "batch_reward": 0.28968936574459075, "critic_loss": 0.5280924046039581, "ae_transition_loss": 0.04094659084826708, "ae_encoder_loss": 0.1880310465991497, "actor_loss": -14.975393913269043, "actor_target_entropy": -6.0, "actor_entropy": 5.614693836212158, "alpha_loss": -0.00051068155746907, "alpha_value": 0.012913797682281857, "duration": 53.77327227592468, "step": 28500}
{"episode_reward": 80.60469174176463, "episode": 115.0, "batch_reward": 0.2895985584259033, "critic_loss": 0.435714107632637, "ae_transition_loss": 0.038920234844088554, "ae_encoder_loss": 0.18778442001342774, "actor_loss": -15.180122367858887, "actor_target_entropy": -6.0, "actor_entropy": 5.6395170135498045, "alpha_loss": -0.0007760269928257913, "alpha_value": 0.013004656874657157, "duration": 54.12431812286377, "step": 28750}
{"episode_reward": 97.81612897217505, "episode": 116.0, "batch_reward": 0.29243632245063783, "critic_loss": 0.6302170372009277, "ae_transition_loss": 0.046489233657717705, "ae_encoder_loss": 0.18919682356715203, "actor_loss": -15.270466186523437, "actor_target_entropy": -6.0, "actor_entropy": 5.621545425415039, "alpha_loss": -2.0508245564997198e-05, "alpha_value": 0.013066483418209958, "duration": 54.126868724823, "step": 29000}
{"episode_reward": 173.6549593713303, "episode": 117.0, "batch_reward": 0.2933759124875069, "critic_loss": 0.6237525625228881, "ae_transition_loss": 0.047534238442778584, "ae_encoder_loss": 0.19445223942399026, "actor_loss": -15.527747711181641, "actor_target_entropy": -6.0, "actor_entropy": 5.637940624237061, "alpha_loss": 0.001039517054799944, "alpha_value": 0.012880186752993756, "duration": 53.8521146774292, "step": 29250}
{"episode_reward": 98.77337547463593, "episode": 118.0, "batch_reward": 0.2951524657011032, "critic_loss": 0.6549525055885315, "ae_transition_loss": 0.047910448983311656, "ae_encoder_loss": 0.20367176362872125, "actor_loss": -15.728428215026856, "actor_target_entropy": -6.0, "actor_entropy": 5.665843734741211, "alpha_loss": -0.0010486430302262305, "alpha_value": 0.012915921201069375, "duration": 53.87194585800171, "step": 29500}
{"episode_reward": 107.02096311119526, "episode": 119.0, "batch_reward": 0.2954437325000763, "critic_loss": 0.6375518044233323, "ae_transition_loss": 0.046674844712018965, "ae_encoder_loss": 0.21075430512428284, "actor_loss": -15.911513145446778, "actor_target_entropy": -6.0, "actor_entropy": 5.611297290802002, "alpha_loss": -0.0009940645762253552, "alpha_value": 0.013281371180393284, "duration": 54.02588605880737, "step": 29750}
{"episode_reward": 128.4789647594645, "episode": 120.0, "batch_reward": 0.2981588441133499, "critic_loss": 0.6729986399412156, "ae_transition_loss": 0.04730311660468579, "ae_encoder_loss": 0.2197263720035553, "actor_loss": -16.161290534973144, "actor_target_entropy": -6.0, "actor_entropy": 5.61794393157959, "alpha_loss": 0.0022459989357739686, "alpha_value": 0.013241694719245339, "duration": 54.12888240814209, "step": 30000}
{"episode_reward": 65.58945978937626, "episode": 121.0, "batch_reward": 0.2968138154745102, "critic_loss": 0.719002160191536, "ae_transition_loss": 0.048204676985740665, "ae_encoder_loss": 0.22121671238541604, "actor_loss": -16.204799865722656, "actor_target_entropy": -6.0, "actor_entropy": 5.594361110687256, "alpha_loss": -0.0005725962379947305, "alpha_value": 0.012744229493447466, "duration": 73.94966554641724, "step": 30250}
{"episode_reward": 87.0279664025617, "episode": 122.0, "batch_reward": 0.2982904393672943, "critic_loss": 0.5660351762771606, "ae_transition_loss": 0.04296721056103706, "ae_encoder_loss": 0.21402638754248618, "actor_loss": -16.356495376586913, "actor_target_entropy": -6.0, "actor_entropy": 5.618792644500733, "alpha_loss": -0.0009487039938103407, "alpha_value": 0.01302611005454103, "duration": 54.14558792114258, "step": 30500}
{"episode_reward": 94.426864384683, "episode": 123.0, "batch_reward": 0.2981043499708176, "critic_loss": 0.8252038307189942, "ae_transition_loss": 0.04852365130186081, "ae_encoder_loss": 0.213906917065382, "actor_loss": -16.56689335632324, "actor_target_entropy": -6.0, "actor_entropy": 5.6131136474609375, "alpha_loss": -8.08795178309083e-05, "alpha_value": 0.01332993674999353, "duration": 53.86303496360779, "step": 30750}
{"episode_reward": 140.76519910455804, "episode": 124.0, "batch_reward": 0.3029126704931259, "critic_loss": 1.0312067365646362, "ae_transition_loss": 0.05400082825124264, "ae_encoder_loss": 0.2277991465330124, "actor_loss": -16.759624778747558, "actor_target_entropy": -6.0, "actor_entropy": 5.717403717041016, "alpha_loss": -0.00018098804424516857, "alpha_value": 0.013396487594674291, "duration": 54.10559153556824, "step": 31000}
{"episode_reward": 132.78454764172196, "episode": 125.0, "batch_reward": 0.3025579099655151, "critic_loss": 0.6283442064523697, "ae_transition_loss": 0.04361363433301449, "ae_encoder_loss": 0.21587043073773385, "actor_loss": -16.95112776184082, "actor_target_entropy": -6.0, "actor_entropy": 5.585333896636963, "alpha_loss": -0.001717898650560528, "alpha_value": 0.013776389097044942, "duration": 53.71402621269226, "step": 31250}
{"episode_reward": 86.47808795974639, "episode": 126.0, "batch_reward": 0.30276700389385225, "critic_loss": 0.6597562527656555, "ae_transition_loss": 0.043317862406373024, "ae_encoder_loss": 0.21518989944458009, "actor_loss": -17.100806259155274, "actor_target_entropy": -6.0, "actor_entropy": 5.673485450744629, "alpha_loss": -0.00020412728702649474, "alpha_value": 0.013907754058310543, "duration": 54.162083864212036, "step": 31500}
{"episode_reward": 115.99047511798662, "episode": 127.0, "batch_reward": 0.30377469182014466, "critic_loss": 0.9621143012046814, "ae_transition_loss": 0.05059254878759384, "ae_encoder_loss": 0.2203571603000164, "actor_loss": -17.290016052246095, "actor_target_entropy": -6.0, "actor_entropy": 5.716110527038574, "alpha_loss": -0.0006757017520722002, "alpha_value": 0.014401452980373607, "duration": 54.11426138877869, "step": 31750}
{"episode_reward": 105.7244143641681, "episode": 128.0, "batch_reward": 0.30458005714416503, "critic_loss": 0.7945934077501297, "ae_transition_loss": 0.04609816877543926, "ae_encoder_loss": 0.21785964506864547, "actor_loss": -17.46068812561035, "actor_target_entropy": -6.0, "actor_entropy": 5.733911212921143, "alpha_loss": -0.000626249120105058, "alpha_value": 0.01414354170891138, "duration": 53.907554626464844, "step": 32000}
{"episode_reward": 99.32852354066979, "episode": 129.0, "batch_reward": 0.3055351197719574, "critic_loss": 0.8461777808666229, "ae_transition_loss": 0.04620569613575935, "ae_encoder_loss": 0.2175285992026329, "actor_loss": -17.616486434936522, "actor_target_entropy": -6.0, "actor_entropy": 5.729069305419922, "alpha_loss": -0.00021036702999845146, "alpha_value": 0.014678411185615253, "duration": 53.95448303222656, "step": 32250}
{"episode_reward": 89.63340161356982, "episode": 130.0, "batch_reward": 0.30606477451324465, "critic_loss": 0.9043239314556122, "ae_transition_loss": 0.04907428978383541, "ae_encoder_loss": 0.22479175090789794, "actor_loss": -17.879485122680663, "actor_target_entropy": -6.0, "actor_entropy": 5.729462417602539, "alpha_loss": -0.0018460219488479197, "alpha_value": 0.014890957770268045, "duration": 54.01611328125, "step": 32500}
{"episode_reward": 122.5127401048164, "episode": 131.0, "batch_reward": 0.30750997686386106, "critic_loss": 0.8725749944448471, "ae_transition_loss": 0.047934945806860925, "ae_encoder_loss": 0.2300736033320427, "actor_loss": -18.0557607421875, "actor_target_entropy": -6.0, "actor_entropy": 5.748232704162597, "alpha_loss": -0.0010374853275716305, "alpha_value": 0.015413432511991973, "duration": 67.93477821350098, "step": 32750}
{"episode_reward": 149.10058192480636, "episode": 132.0, "batch_reward": 0.31058438670635224, "critic_loss": 1.0440785082578659, "ae_transition_loss": 0.051272353887557985, "ae_encoder_loss": 0.23312309089303015, "actor_loss": -18.3125368347168, "actor_target_entropy": -6.0, "actor_entropy": 5.76719926071167, "alpha_loss": 0.0008238957645371556, "alpha_value": 0.015483580144257493, "duration": 53.80487585067749, "step": 33000}
{"episode_reward": 93.59426952047367, "episode": 133.0, "batch_reward": 0.30977847146987914, "critic_loss": 1.04450932097435, "ae_transition_loss": 0.04853123617172241, "ae_encoder_loss": 0.22420389968156815, "actor_loss": -18.424293991088867, "actor_target_entropy": -6.0, "actor_entropy": 5.784387702941895, "alpha_loss": 0.0005981913385912776, "alpha_value": 0.015243714067989323, "duration": 54.1884708404541, "step": 33250}
{"episode_reward": 139.1497385175843, "episode": 134.0, "batch_reward": 0.31170447850227356, "critic_loss": 0.8468377184867859, "ae_transition_loss": 0.04547450801730156, "ae_encoder_loss": 0.21574886697530746, "actor_loss": -18.55243229675293, "actor_target_entropy": -6.0, "actor_entropy": 5.711519767761231, "alpha_loss": -0.00034035171614959836, "alpha_value": 0.015192923075743032, "duration": 54.01550531387329, "step": 33500}
{"episode_reward": 97.51721262073434, "episode": 135.0, "batch_reward": 0.3130423471927643, "critic_loss": 1.0469524083137511, "ae_transition_loss": 0.048964625522494316, "ae_encoder_loss": 0.23215073534846306, "actor_loss": -18.801328811645508, "actor_target_entropy": -6.0, "actor_entropy": 5.726714160919189, "alpha_loss": -0.0011969800819642842, "alpha_value": 0.015538191750065041, "duration": 53.982003927230835, "step": 33750}
{"episode_reward": 80.67851343503172, "episode": 136.0, "batch_reward": 0.3122559965848923, "critic_loss": 0.9131991209983825, "ae_transition_loss": 0.04553709553182125, "ae_encoder_loss": 0.2286691476404667, "actor_loss": -19.016712783813478, "actor_target_entropy": -6.0, "actor_entropy": 5.656458839416504, "alpha_loss": 7.266071159392595e-06, "alpha_value": 0.015622305385806392, "duration": 53.854087352752686, "step": 34000}
{"episode_reward": 89.58029885174794, "episode": 137.0, "batch_reward": 0.3119679107666016, "critic_loss": 1.0802856707572936, "ae_transition_loss": 0.050014041781425475, "ae_encoder_loss": 0.2357972799539566, "actor_loss": -19.095997650146483, "actor_target_entropy": -6.0, "actor_entropy": 5.739864200592041, "alpha_loss": -0.00011028950242325663, "alpha_value": 0.01556467622995997, "duration": 54.09298014640808, "step": 34250}
{"episode_reward": 121.59969640366957, "episode": 138.0, "batch_reward": 0.3129769488573074, "critic_loss": 1.2802117817401886, "ae_transition_loss": 0.05357315810024738, "ae_encoder_loss": 0.23157317423820495, "actor_loss": -19.155579513549803, "actor_target_entropy": -6.0, "actor_entropy": 5.772301898956298, "alpha_loss": -0.00022205842402763665, "alpha_value": 0.015692758205374833, "duration": 54.18928623199463, "step": 34500}
{"episode_reward": 75.89182373508025, "episode": 139.0, "batch_reward": 0.314496950507164, "critic_loss": 1.2043038852214814, "ae_transition_loss": 0.04957165858149529, "ae_encoder_loss": 0.21945515358448028, "actor_loss": -19.317968063354492, "actor_target_entropy": -6.0, "actor_entropy": 5.73438740158081, "alpha_loss": 0.0007983915475197137, "alpha_value": 0.015778680680330146, "duration": 53.742698431015015, "step": 34750}
{"episode_reward": 69.70929051603963, "episode": 140.0, "batch_reward": 0.31526467394828794, "critic_loss": 0.848671138048172, "ae_transition_loss": 0.04218057501316071, "ae_encoder_loss": 0.22296194618940354, "actor_loss": -19.495181091308595, "actor_target_entropy": -6.0, "actor_entropy": 5.723185531616211, "alpha_loss": 0.00041642759297974406, "alpha_value": 0.015530128524483933, "duration": 54.15045166015625, "step": 35000}
{"episode_reward": 183.89795585390777, "episode": 141.0, "batch_reward": 0.3167119954824448, "critic_loss": 1.165211266517639, "ae_transition_loss": 0.04892933067679405, "ae_encoder_loss": 0.22012395459413528, "actor_loss": -19.633930145263673, "actor_target_entropy": -6.0, "actor_entropy": 5.754900009155273, "alpha_loss": -0.0020375640015117824, "alpha_value": 0.015615001395538683, "duration": 67.85116863250732, "step": 35250}
{"episode_reward": 117.98298333188833, "episode": 142.0, "batch_reward": 0.31605366015434266, "critic_loss": 1.1555500800609588, "ae_transition_loss": 0.04833750025928021, "ae_encoder_loss": 0.22505966359376908, "actor_loss": -19.72072593688965, "actor_target_entropy": -6.0, "actor_entropy": 5.751959671020508, "alpha_loss": 0.0016026168554089963, "alpha_value": 0.01587835449047754, "duration": 53.89202642440796, "step": 35500}
{"episode_reward": 64.20944295808563, "episode": 143.0, "batch_reward": 0.3181997624635696, "critic_loss": 1.062154224872589, "ae_transition_loss": 0.04686833044886589, "ae_encoder_loss": 0.2197590338587761, "actor_loss": -19.94800001525879, "actor_target_entropy": -6.0, "actor_entropy": 5.72899783706665, "alpha_loss": -0.0007867551189847291, "alpha_value": 0.015627033727134886, "duration": 54.093759298324585, "step": 35750}
{"episode_reward": 142.45043898689116, "episode": 144.0, "batch_reward": 0.32054936480522156, "critic_loss": 1.2252131245136262, "ae_transition_loss": 0.04774022701382637, "ae_encoder_loss": 0.22861099976301194, "actor_loss": -20.126439208984376, "actor_target_entropy": -6.0, "actor_entropy": 5.715437141418457, "alpha_loss": 0.0004658681717701256, "alpha_value": 0.015604370766803459, "duration": 53.994136333465576, "step": 36000}
{"episode_reward": 126.19547499689142, "episode": 145.0, "batch_reward": 0.32156559884548186, "critic_loss": 1.4642150921821595, "ae_transition_loss": 0.05541242209076881, "ae_encoder_loss": 0.2377639526128769, "actor_loss": -20.23159764099121, "actor_target_entropy": -6.0, "actor_entropy": 5.776028602600098, "alpha_loss": -0.00012797386408783495, "alpha_value": 0.015680737751546228, "duration": 54.26893186569214, "step": 36250}
{"episode_reward": 135.34933421004314, "episode": 146.0, "batch_reward": 0.32235505926609037, "critic_loss": 1.6434476256370545, "ae_transition_loss": 0.05776887917518616, "ae_encoder_loss": 0.23037059473991395, "actor_loss": -20.402673843383788, "actor_target_entropy": -6.0, "actor_entropy": 5.806433811187744, "alpha_loss": 0.00013509881170466542, "alpha_value": 0.015438083238330694, "duration": 53.828261852264404, "step": 36500}
{"episode_reward": 50.566463695758856, "episode": 147.0, "batch_reward": 0.32177435624599454, "critic_loss": 1.0539807438850404, "ae_transition_loss": 0.04341171087324619, "ae_encoder_loss": 0.22445065420866012, "actor_loss": -20.47609912109375, "actor_target_entropy": -6.0, "actor_entropy": 5.805113231658935, "alpha_loss": -0.0021695262850262224, "alpha_value": 0.016027180135181923, "duration": 54.25003218650818, "step": 36750}
{"episode_reward": 83.33065777295755, "episode": 148.0, "batch_reward": 0.3213777174949646, "critic_loss": 1.1709754703044892, "ae_transition_loss": 0.04764235529303551, "ae_encoder_loss": 0.2263004588484764, "actor_loss": -20.592710220336915, "actor_target_entropy": -6.0, "actor_entropy": 5.81655428314209, "alpha_loss": 0.0003966874573379755, "alpha_value": 0.016360321170142293, "duration": 54.20460772514343, "step": 37000}
{"episode_reward": 174.05275140739408, "episode": 149.0, "batch_reward": 0.32349366176128386, "critic_loss": 1.2397869656085967, "ae_transition_loss": 0.04885687038302421, "ae_encoder_loss": 0.22756250435113906, "actor_loss": -20.808797912597655, "actor_target_entropy": -6.0, "actor_entropy": 5.779265594482422, "alpha_loss": 0.00045371137978509067, "alpha_value": 0.01623179473181, "duration": 53.90585899353027, "step": 37250}
{"episode_reward": 64.47077799682317, "episode": 150.0, "batch_reward": 0.3239255197048187, "critic_loss": 1.27266210770607, "ae_transition_loss": 0.04782219925522804, "ae_encoder_loss": 0.2266148796081543, "actor_loss": -20.896322708129883, "actor_target_entropy": -6.0, "actor_entropy": 5.7569033164978025, "alpha_loss": 0.00013932218588888644, "alpha_value": 0.016146175844239753, "duration": 54.08702111244202, "step": 37500}
{"episode_reward": 160.83325385752366, "episode": 151.0, "batch_reward": 0.3244955506324768, "critic_loss": 2.549663648366928, "ae_transition_loss": 0.07123467496037483, "ae_encoder_loss": 0.23744943368434906, "actor_loss": -21.05118469238281, "actor_target_entropy": -6.0, "actor_entropy": 5.864247764587402, "alpha_loss": -1.0816122405230999e-05, "alpha_value": 0.015983301908957442, "duration": 67.84737992286682, "step": 37750}
{"episode_reward": 131.4804450962131, "episode": 152.0, "batch_reward": 0.32632344162464144, "critic_loss": 1.2931223962306977, "ae_transition_loss": 0.052642263010144234, "ae_encoder_loss": 0.22808759212493895, "actor_loss": -21.21311911010742, "actor_target_entropy": -6.0, "actor_entropy": 5.861601734161377, "alpha_loss": -0.00047720011090859773, "alpha_value": 0.01596766173239681, "duration": 54.04875302314758, "step": 38000}
{"episode_reward": 58.08754266297712, "episode": 153.0, "batch_reward": 0.32602452981472013, "critic_loss": 1.2520706977844238, "ae_transition_loss": 0.04886059221625328, "ae_encoder_loss": 0.22546461272239685, "actor_loss": -21.276209869384765, "actor_target_entropy": -6.0, "actor_entropy": 5.824725395202637, "alpha_loss": -0.0007946303649805487, "alpha_value": 0.01628165900118819, "duration": 54.02505159378052, "step": 38250}
{"episode_reward": 147.53050036973474, "episode": 154.0, "batch_reward": 0.32761574518680575, "critic_loss": 1.419213521718979, "ae_transition_loss": 0.05259690172970295, "ae_encoder_loss": 0.2423110328912735, "actor_loss": -21.573493576049806, "actor_target_entropy": -6.0, "actor_entropy": 5.812799140930176, "alpha_loss": -0.0003329983553849161, "alpha_value": 0.016699348749662984, "duration": 54.068702936172485, "step": 38500}
{"episode_reward": 145.37156735804956, "episode": 155.0, "batch_reward": 0.3305821948051453, "critic_loss": 2.5203938970565796, "ae_transition_loss": 0.07024813808500767, "ae_encoder_loss": 0.24121456336975097, "actor_loss": -21.6428458404541, "actor_target_entropy": -6.0, "actor_entropy": 5.9090321922302245, "alpha_loss": 0.0024874552162364124, "alpha_value": 0.016018052074489825, "duration": 54.27887201309204, "step": 38750}
{"episode_reward": 110.2487426106412, "episode": 156.0, "batch_reward": 0.3304563884735107, "critic_loss": 1.2173214960098266, "ae_transition_loss": 0.048720372825860975, "ae_encoder_loss": 0.22987476289272307, "actor_loss": -21.796466079711912, "actor_target_entropy": -6.0, "actor_entropy": 5.755996112823486, "alpha_loss": -0.002423372550867498, "alpha_value": 0.015885869495309107, "duration": 53.82231640815735, "step": 39000}
{"episode_reward": 117.2714530383406, "episode": 157.0, "batch_reward": 0.33422046375274655, "critic_loss": 1.426809722661972, "ae_transition_loss": 0.05376005367934704, "ae_encoder_loss": 0.23903029400110246, "actor_loss": -22.05235046386719, "actor_target_entropy": -6.0, "actor_entropy": 5.829286998748779, "alpha_loss": 0.00014490609942004084, "alpha_value": 0.016411756423154105, "duration": 54.23425006866455, "step": 39250}
{"episode_reward": 144.05542516394323, "episode": 158.0, "batch_reward": 0.3336200671195984, "critic_loss": 2.0148454945087435, "ae_transition_loss": 0.06161049844324589, "ae_encoder_loss": 0.25035808789730074, "actor_loss": -22.09626971435547, "actor_target_entropy": -6.0, "actor_entropy": 5.860759162902832, "alpha_loss": -0.0015835811069700868, "alpha_value": 0.016596728721620504, "duration": 54.24912238121033, "step": 39500}
{"episode_reward": 116.37641702858424, "episode": 159.0, "batch_reward": 0.3365329531431198, "critic_loss": 1.9806971912384033, "ae_transition_loss": 0.061412569761276244, "ae_encoder_loss": 0.24057851433753968, "actor_loss": -22.196521362304686, "actor_target_entropy": -6.0, "actor_entropy": 5.914178985595703, "alpha_loss": 0.000492351668421179, "alpha_value": 0.017013319775663168, "duration": 53.90065097808838, "step": 39750}
{"episode_reward": 155.57595419417345, "episode": 160.0, "batch_reward": 0.33613125371932984, "critic_loss": 1.5903379817008971, "ae_transition_loss": 0.05249413737654686, "ae_encoder_loss": 0.2462333072423935, "actor_loss": -22.358711364746092, "actor_target_entropy": -6.0, "actor_entropy": 5.884088485717774, "alpha_loss": -0.0018945108843035996, "alpha_value": 0.017189996243896093, "duration": 54.25700354576111, "step": 40000}
{"episode_reward": 118.78875723056842, "episode": 161.0, "batch_reward": 0.33673087918758393, "critic_loss": 1.6506515340805055, "ae_transition_loss": 0.055058969512581823, "ae_encoder_loss": 0.25171462881565093, "actor_loss": -22.494618225097657, "actor_target_entropy": -6.0, "actor_entropy": 5.794853260040283, "alpha_loss": 0.00019138287752866744, "alpha_value": 0.017299243729104352, "duration": 74.50490713119507, "step": 40250}
{"episode_reward": 123.16392810421034, "episode": 162.0, "batch_reward": 0.33551887166500094, "critic_loss": 2.2675787613391876, "ae_transition_loss": 0.06403038117289543, "ae_encoder_loss": 0.25872543263435366, "actor_loss": -22.59564976501465, "actor_target_entropy": -6.0, "actor_entropy": 5.908050632476806, "alpha_loss": 0.0033354762215167286, "alpha_value": 0.017412251703644716, "duration": 53.84528565406799, "step": 40500}
{"episode_reward": 45.16457164071435, "episode": 163.0, "batch_reward": 0.33619377970695496, "critic_loss": 1.6333974728584288, "ae_transition_loss": 0.0540141686052084, "ae_encoder_loss": 0.2528250551819801, "actor_loss": -22.779672378540038, "actor_target_entropy": -6.0, "actor_entropy": 5.870989360809326, "alpha_loss": -0.001713239214848727, "alpha_value": 0.01650802133079893, "duration": 54.19756722450256, "step": 40750}
{"episode_reward": 90.09185780201678, "episode": 164.0, "batch_reward": 0.3364954388141632, "critic_loss": 1.3954036555290221, "ae_transition_loss": 0.05272112363576889, "ae_encoder_loss": 0.2539911489486694, "actor_loss": -22.851325759887697, "actor_target_entropy": -6.0, "actor_entropy": 5.799263175964356, "alpha_loss": -0.0011265761225949973, "alpha_value": 0.01712699803948176, "duration": 54.20149302482605, "step": 41000}
{"episode_reward": 132.024947681755, "episode": 165.0, "batch_reward": 0.33865683460235596, "critic_loss": 1.5993652238845826, "ae_transition_loss": 0.055361493170261386, "ae_encoder_loss": 0.2620252156853676, "actor_loss": -23.139940628051757, "actor_target_entropy": -6.0, "actor_entropy": 5.779632194519043, "alpha_loss": -0.00018380603427067398, "alpha_value": 0.01722409299443403, "duration": 53.99593424797058, "step": 41250}
{"episode_reward": 123.15344490668586, "episode": 166.0, "batch_reward": 0.3400781718492508, "critic_loss": 1.8843446023464203, "ae_transition_loss": 0.05699667876958847, "ae_encoder_loss": 0.2582329144477844, "actor_loss": -23.16585006713867, "actor_target_entropy": -6.0, "actor_entropy": 5.861186061859131, "alpha_loss": 0.0028055596137419344, "alpha_value": 0.016775069993837825, "duration": 54.191826581954956, "step": 41500}
{"episode_reward": 85.3361571881994, "episode": 167.0, "batch_reward": 0.33938191962242126, "critic_loss": 2.8122892627716065, "ae_transition_loss": 0.07085940170288085, "ae_encoder_loss": 0.2604660330414772, "actor_loss": -23.130582611083984, "actor_target_entropy": -6.0, "actor_entropy": 5.903150856018066, "alpha_loss": 0.0011118421549908817, "alpha_value": 0.016218709615970064, "duration": 54.07357478141785, "step": 41750}
{"episode_reward": 80.18132678543712, "episode": 168.0, "batch_reward": 0.33745723927021026, "critic_loss": 2.3346208004951476, "ae_transition_loss": 0.06608242107927799, "ae_encoder_loss": 0.25282960319519043, "actor_loss": -23.17835232543945, "actor_target_entropy": -6.0, "actor_entropy": 5.843541324615479, "alpha_loss": -0.0011877835686318577, "alpha_value": 0.01590499001476248, "duration": 54.25420880317688, "step": 42000}
{"episode_reward": 139.45784133481715, "episode": 169.0, "batch_reward": 0.33984748232364653, "critic_loss": 1.853306587934494, "ae_transition_loss": 0.056585951313376424, "ae_encoder_loss": 0.24673523670434952, "actor_loss": -23.336223190307617, "actor_target_entropy": -6.0, "actor_entropy": 5.766345043182373, "alpha_loss": -0.0007338146090041846, "alpha_value": 0.016409131153486824, "duration": 53.99015235900879, "step": 42250}
{"episode_reward": 123.07174887333366, "episode": 170.0, "batch_reward": 0.34060893499851225, "critic_loss": 1.5756023077964783, "ae_transition_loss": 0.051924912095069886, "ae_encoder_loss": 0.24476510936021806, "actor_loss": -23.46194221496582, "actor_target_entropy": -6.0, "actor_entropy": 5.743056552886963, "alpha_loss": -0.0013850420713424683, "alpha_value": 0.01706126399179845, "duration": 54.16768765449524, "step": 42500}
{"episode_reward": 101.89754677898635, "episode": 171.0, "batch_reward": 0.3429946491718292, "critic_loss": 2.01574213886261, "ae_transition_loss": 0.05617828361690044, "ae_encoder_loss": 0.25707030314207074, "actor_loss": -23.695959899902345, "actor_target_entropy": -6.0, "actor_entropy": 5.756377498626709, "alpha_loss": 0.0012813897361047565, "alpha_value": 0.017149185750604368, "duration": 68.08546257019043, "step": 42750}
{"episode_reward": 170.23216708408867, "episode": 172.0, "batch_reward": 0.3440579186677933, "critic_loss": 1.890870327949524, "ae_transition_loss": 0.05660029870271683, "ae_encoder_loss": 0.2512936019897461, "actor_loss": -23.765402801513673, "actor_target_entropy": -6.0, "actor_entropy": 5.762847869873047, "alpha_loss": -0.001134287677705288, "alpha_value": 0.016803320905278512, "duration": 53.963772773742676, "step": 43000}
{"episode_reward": 49.76706288395732, "episode": 173.0, "batch_reward": 0.3436382749080658, "critic_loss": 2.0532375700473784, "ae_transition_loss": 0.05732638467848301, "ae_encoder_loss": 0.249926753282547, "actor_loss": -23.81593309020996, "actor_target_entropy": -6.0, "actor_entropy": 5.807305187225341, "alpha_loss": -0.0012774046105332672, "alpha_value": 0.017367681168006043, "duration": 54.12718367576599, "step": 43250}
{"episode_reward": 101.2891913371651, "episode": 174.0, "batch_reward": 0.34305791699886323, "critic_loss": 2.306836181640625, "ae_transition_loss": 0.06152045665681362, "ae_encoder_loss": 0.24721352702379226, "actor_loss": -23.972774307250976, "actor_target_entropy": -6.0, "actor_entropy": 5.759462501525879, "alpha_loss": 0.0022775921055581422, "alpha_value": 0.017328751092407297, "duration": 54.33037281036377, "step": 43500}
{"episode_reward": 132.88230655133643, "episode": 175.0, "batch_reward": 0.3459013051986694, "critic_loss": 3.0073694944381715, "ae_transition_loss": 0.07186665089428425, "ae_encoder_loss": 0.26017447155714035, "actor_loss": -23.94792887878418, "actor_target_entropy": -6.0, "actor_entropy": 5.8459988098144535, "alpha_loss": 0.0009277471131645143, "alpha_value": 0.016763152312858395, "duration": 53.968096017837524, "step": 43750}
{"episode_reward": 225.35225835191986, "episode": 176.0, "batch_reward": 0.34962655961513517, "critic_loss": 2.8081900782585145, "ae_transition_loss": 0.06877248494327068, "ae_encoder_loss": 0.2554011020064354, "actor_loss": -24.100538681030272, "actor_target_entropy": -6.0, "actor_entropy": 5.782259719848633, "alpha_loss": 0.0007959002200514079, "alpha_value": 0.0162801057907163, "duration": 54.2338593006134, "step": 44000}
{"episode_reward": 207.20508792975525, "episode": 177.0, "batch_reward": 0.3523908942937851, "critic_loss": 2.0725523862838746, "ae_transition_loss": 0.058685116842389105, "ae_encoder_loss": 0.24700253063440322, "actor_loss": -24.331139465332033, "actor_target_entropy": -6.0, "actor_entropy": 5.734657043457031, "alpha_loss": -0.0025677650505676864, "alpha_value": 0.01653370767118345, "duration": 54.378634214401245, "step": 44250}
{"episode_reward": 103.39910674753884, "episode": 178.0, "batch_reward": 0.35058163011074067, "critic_loss": 1.8978311517238617, "ae_transition_loss": 0.05497989322245121, "ae_encoder_loss": 0.24348813968896865, "actor_loss": -24.438801025390624, "actor_target_entropy": -6.0, "actor_entropy": 5.712954135894775, "alpha_loss": -0.002406443509971723, "alpha_value": 0.017367203067553735, "duration": 53.86153173446655, "step": 44500}
{"episode_reward": 137.44530843303568, "episode": 179.0, "batch_reward": 0.3525364155769348, "critic_loss": 2.2563153700828553, "ae_transition_loss": 0.057240010753273965, "ae_encoder_loss": 0.2447586853504181, "actor_loss": -24.487720489501953, "actor_target_entropy": -6.0, "actor_entropy": 5.710921707153321, "alpha_loss": 0.0015122261373326181, "alpha_value": 0.017727608849961822, "duration": 54.33457565307617, "step": 44750}
{"episode_reward": 128.62343377007795, "episode": 180.0, "batch_reward": 0.352800194978714, "critic_loss": 3.461134919166565, "ae_transition_loss": 0.07673272605240344, "ae_encoder_loss": 0.2601074624657631, "actor_loss": -24.490356384277344, "actor_target_entropy": -6.0, "actor_entropy": 5.851655151367187, "alpha_loss": 0.0012284818605985493, "alpha_value": 0.017003189661664836, "duration": 54.29924941062927, "step": 45000}
{"episode_reward": 139.61319942892854, "episode": 181.0, "batch_reward": 0.3556444742679596, "critic_loss": 3.0905211958885195, "ae_transition_loss": 0.06949215751886367, "ae_encoder_loss": 0.26930538946390153, "actor_loss": -24.65026271057129, "actor_target_entropy": -6.0, "actor_entropy": 5.8418808250427245, "alpha_loss": 0.000890234615188092, "alpha_value": 0.01687544238361568, "duration": 67.7404408454895, "step": 45250}
{"episode_reward": 196.38962005432256, "episode": 182.0, "batch_reward": 0.3567525384426117, "critic_loss": 2.1284127955436705, "ae_transition_loss": 0.05748401176929474, "ae_encoder_loss": 0.2551418802142143, "actor_loss": -24.83446545410156, "actor_target_entropy": -6.0, "actor_entropy": 5.75765975189209, "alpha_loss": -0.0004986718774307519, "alpha_value": 0.01657740590909673, "duration": 54.252657890319824, "step": 45500}
{"episode_reward": 178.76145847071473, "episode": 183.0, "batch_reward": 0.3589053682088852, "critic_loss": 2.061916997432709, "ae_transition_loss": 0.056673281013965605, "ae_encoder_loss": 0.2522315013408661, "actor_loss": -24.99684732055664, "actor_target_entropy": -6.0, "actor_entropy": 5.729052375793457, "alpha_loss": 0.00016849626833572985, "alpha_value": 0.016907046477364077, "duration": 54.3476197719574, "step": 45750}
{"episode_reward": 133.14466092194232, "episode": 184.0, "batch_reward": 0.3596891347169876, "critic_loss": 3.9683459877967833, "ae_transition_loss": 0.08107115136086941, "ae_encoder_loss": 0.2780132360458374, "actor_loss": -25.07608613586426, "actor_target_entropy": -6.0, "actor_entropy": 5.806766799926757, "alpha_loss": 0.002187234110198915, "alpha_value": 0.01666021032566389, "duration": 53.94568848609924, "step": 46000}
{"episode_reward": 144.17640100647063, "episode": 185.0, "batch_reward": 0.3595648649930954, "critic_loss": 3.21987771320343, "ae_transition_loss": 0.06994469456374645, "ae_encoder_loss": 0.276517085313797, "actor_loss": -25.131009521484376, "actor_target_entropy": -6.0, "actor_entropy": 5.762595737457276, "alpha_loss": -0.0015101881090085953, "alpha_value": 0.015941909634446638, "duration": 54.30568337440491, "step": 46250}
{"episode_reward": 72.43731054124473, "episode": 186.0, "batch_reward": 0.36049555039405823, "critic_loss": 2.7425643911361695, "ae_transition_loss": 0.06661911895871163, "ae_encoder_loss": 0.27318399101495744, "actor_loss": -25.211950958251954, "actor_target_entropy": -6.0, "actor_entropy": 5.803759254455566, "alpha_loss": -0.0008556524449959398, "alpha_value": 0.016821295785293233, "duration": 54.35402202606201, "step": 46500}
{"episode_reward": 68.3078506916618, "episode": 187.0, "batch_reward": 0.360947544336319, "critic_loss": 1.9828437323570252, "ae_transition_loss": 0.055406907677650455, "ae_encoder_loss": 0.2618378816843033, "actor_loss": -25.271467483520507, "actor_target_entropy": -6.0, "actor_entropy": 5.708288154602051, "alpha_loss": 0.0021421834034845233, "alpha_value": 0.016633775018252358, "duration": 53.88300395011902, "step": 46750}
{"episode_reward": 143.67105131872796, "episode": 188.0, "batch_reward": 0.36085217249393464, "critic_loss": 2.8296183757781983, "ae_transition_loss": 0.06517409127950669, "ae_encoder_loss": 0.2777460895180702, "actor_loss": -25.419827621459962, "actor_target_entropy": -6.0, "actor_entropy": 5.782328308105469, "alpha_loss": 0.0015335672278888523, "alpha_value": 0.01597998487532248, "duration": 54.35306215286255, "step": 47000}
{"episode_reward": 88.32376902664171, "episode": 189.0, "batch_reward": 0.36004581570625305, "critic_loss": 3.9539625010490416, "ae_transition_loss": 0.08034890411794185, "ae_encoder_loss": 0.2886888547539711, "actor_loss": -25.258091415405275, "actor_target_entropy": -6.0, "actor_entropy": 5.866865982055664, "alpha_loss": 0.0004452470596879721, "alpha_value": 0.015635048197254635, "duration": 54.35654425621033, "step": 47250}
{"episode_reward": 120.13174713155264, "episode": 190.0, "batch_reward": 0.3612873681783676, "critic_loss": 5.046653867721558, "ae_transition_loss": 0.08933251813054084, "ae_encoder_loss": 0.2922541361451149, "actor_loss": -25.368460052490235, "actor_target_entropy": -6.0, "actor_entropy": 5.862814331054688, "alpha_loss": -0.001352693879045546, "alpha_value": 0.015567433629752546, "duration": 53.95973753929138, "step": 47500}
{"episode_reward": 173.10193135891214, "episode": 191.0, "batch_reward": 0.3624240027666092, "critic_loss": 3.1309712381362913, "ae_transition_loss": 0.06963806816935539, "ae_encoder_loss": 0.27732424485683443, "actor_loss": -25.447779220581054, "actor_target_entropy": -6.0, "actor_entropy": 5.7842534713745115, "alpha_loss": -0.0011019956760574133, "alpha_value": 0.016316738575238268, "duration": 68.12518334388733, "step": 47750}
{"episode_reward": 100.48647940000747, "episode": 192.0, "batch_reward": 0.36347414588928223, "critic_loss": 2.0776677045822143, "ae_transition_loss": 0.05738067288696766, "ae_encoder_loss": 0.27443654745817186, "actor_loss": -25.629942611694336, "actor_target_entropy": -6.0, "actor_entropy": 5.827556018829346, "alpha_loss": 0.0004965110849589109, "alpha_value": 0.016234769895744468, "duration": 54.37475061416626, "step": 48000}
{"episode_reward": 79.60242797930866, "episode": 193.0, "batch_reward": 0.3636143329143524, "critic_loss": 2.599425422668457, "ae_transition_loss": 0.06042460881173611, "ae_encoder_loss": 0.2828975433111191, "actor_loss": -25.566524047851562, "actor_target_entropy": -6.0, "actor_entropy": 5.791391925811768, "alpha_loss": 0.0007002636943943799, "alpha_value": 0.016160250938859443, "duration": 54.10142493247986, "step": 48250}
{"episode_reward": 119.29259352468634, "episode": 194.0, "batch_reward": 0.3635746523141861, "critic_loss": 3.2499360132217405, "ae_transition_loss": 0.06844446413218976, "ae_encoder_loss": 0.2793055719137192, "actor_loss": -25.676481353759765, "actor_target_entropy": -6.0, "actor_entropy": 5.785556324005127, "alpha_loss": 0.00048412852874025705, "alpha_value": 0.015877527744362407, "duration": 54.280253648757935, "step": 48500}
{"episode_reward": 196.2170918830774, "episode": 195.0, "batch_reward": 0.3650791952610016, "critic_loss": 4.655702778339386, "ae_transition_loss": 0.08129792068898678, "ae_encoder_loss": 0.29941270166635514, "actor_loss": -25.65570570373535, "actor_target_entropy": -6.0, "actor_entropy": 5.780261161804199, "alpha_loss": 0.0016336698397062719, "alpha_value": 0.015520637016677346, "duration": 54.502034187316895, "step": 48750}
{"episode_reward": 167.99511691838902, "episode": 196.0, "batch_reward": 0.36693250012397766, "critic_loss": 3.384888216495514, "ae_transition_loss": 0.07050471824407578, "ae_encoder_loss": 0.28094181513786315, "actor_loss": -25.89498370361328, "actor_target_entropy": -6.0, "actor_entropy": 5.795979274749756, "alpha_loss": -0.0006419038018211723, "alpha_value": 0.015224803931139693, "duration": 54.147361278533936, "step": 49000}
{"episode_reward": 90.96489592665846, "episode": 197.0, "batch_reward": 0.36449009203910826, "critic_loss": 2.69548521900177, "ae_transition_loss": 0.06128982703387737, "ae_encoder_loss": 0.27373973494768145, "actor_loss": -25.777788116455078, "actor_target_entropy": -6.0, "actor_entropy": 5.674051803588867, "alpha_loss": -0.0032227131240069864, "alpha_value": 0.016058828586279366, "duration": 54.225886821746826, "step": 49250}
{"episode_reward": 98.83443956759889, "episode": 198.0, "batch_reward": 0.3660385373830795, "critic_loss": 3.2175026550292967, "ae_transition_loss": 0.0694617673754692, "ae_encoder_loss": 0.2896821014881134, "actor_loss": -25.960016632080077, "actor_target_entropy": -6.0, "actor_entropy": 5.6440417747497555, "alpha_loss": 0.0003359417582396418, "alpha_value": 0.016173231112918813, "duration": 54.36638879776001, "step": 49500}
{"episode_reward": 152.5511889873854, "episode": 199.0, "batch_reward": 0.3694096279144287, "critic_loss": 3.2967122025489806, "ae_transition_loss": 0.07408154766261578, "ae_encoder_loss": 0.2857339047789574, "actor_loss": -26.15747035217285, "actor_target_entropy": -6.0, "actor_entropy": 5.691957099914551, "alpha_loss": 0.00045689055509865286, "alpha_value": 0.016097549694280577, "duration": 54.15214514732361, "step": 49750}
{"episode_reward": 128.50052044946204, "episode": 200.0, "batch_reward": 0.36983577251434324, "critic_loss": 3.649911883354187, "ae_transition_loss": 0.07534953653812408, "ae_encoder_loss": 0.2972427598237991, "actor_loss": -26.1075216217041, "actor_target_entropy": -6.0, "actor_entropy": 5.722846374511719, "alpha_loss": 0.001913337836507708, "alpha_value": 0.015955281123885445, "duration": 54.185534954071045, "step": 50000}
{"episode_reward": 116.49991568835378, "episode": 201.0, "batch_reward": 0.3708752955198288, "critic_loss": 3.94669082069397, "ae_transition_loss": 0.08060937847197056, "ae_encoder_loss": 0.30240150409936906, "actor_loss": -26.140787811279296, "actor_target_entropy": -6.0, "actor_entropy": 5.7595075988769535, "alpha_loss": 0.0030317194256931543, "alpha_value": 0.014914507220551678, "duration": 74.90333223342896, "step": 50250}
{"episode_reward": 185.04891704910398, "episode": 202.0, "batch_reward": 0.3712058398723602, "critic_loss": 3.4931127047538757, "ae_transition_loss": 0.0752254584133625, "ae_encoder_loss": 0.297510903775692, "actor_loss": -26.236261947631835, "actor_target_entropy": -6.0, "actor_entropy": 5.698529800415039, "alpha_loss": -0.0009464544609654695, "alpha_value": 0.014836008106210932, "duration": 54.40490007400513, "step": 50500}
{"episode_reward": 132.50638304362482, "episode": 203.0, "batch_reward": 0.3739415464401245, "critic_loss": 2.769501217842102, "ae_transition_loss": 0.06468529269099235, "ae_encoder_loss": 0.28942863368988037, "actor_loss": -26.517290969848634, "actor_target_entropy": -6.0, "actor_entropy": 5.596693264007568, "alpha_loss": -0.0007826774660497904, "alpha_value": 0.015150214080090353, "duration": 54.37964844703674, "step": 50750}
{"episode_reward": 109.84865784316112, "episode": 204.0, "batch_reward": 0.37256168818473817, "critic_loss": 3.584755302906036, "ae_transition_loss": 0.07531041936576366, "ae_encoder_loss": 0.29729626202583315, "actor_loss": -26.419778015136718, "actor_target_entropy": -6.0, "actor_entropy": 5.590351154327393, "alpha_loss": -5.1412480417639015e-05, "alpha_value": 0.015245428462573466, "duration": 54.02317476272583, "step": 51000}
{"episode_reward": 160.06179519840347, "episode": 205.0, "batch_reward": 0.37596415281295775, "critic_loss": 4.710894031047821, "ae_transition_loss": 0.08758990672230721, "ae_encoder_loss": 0.3158207803964615, "actor_loss": -26.613538665771486, "actor_target_entropy": -6.0, "actor_entropy": 5.73064217376709, "alpha_loss": 0.0003781301658600569, "alpha_value": 0.015258453146678569, "duration": 54.41633582115173, "step": 51250}
{"episode_reward": 159.73495074897795, "episode": 206.0, "batch_reward": 0.3761350005865097, "critic_loss": 3.299455713748932, "ae_transition_loss": 0.07418800275027752, "ae_encoder_loss": 0.2939725685119629, "actor_loss": -26.590341247558595, "actor_target_entropy": -6.0, "actor_entropy": 5.792101303100586, "alpha_loss": 2.1574979182332755e-05, "alpha_value": 0.015052386959725406, "duration": 54.41900086402893, "step": 51500}
{"episode_reward": 168.32442204799284, "episode": 207.0, "batch_reward": 0.3764086360931396, "critic_loss": 3.2077179908752442, "ae_transition_loss": 0.06938071106374263, "ae_encoder_loss": 0.30208830791711805, "actor_loss": -26.74684907531738, "actor_target_entropy": -6.0, "actor_entropy": 5.679159427642822, "alpha_loss": -0.0026072507328353824, "alpha_value": 0.01564002934750785, "duration": 54.030211210250854, "step": 51750}
{"episode_reward": 187.977769176692, "episode": 208.0, "batch_reward": 0.3801091339588165, "critic_loss": 4.596396944999695, "ae_transition_loss": 0.0882314676195383, "ae_encoder_loss": 0.31181799441576, "actor_loss": -26.906101181030273, "actor_target_entropy": -6.0, "actor_entropy": 5.719849460601806, "alpha_loss": 1.5679373871535063e-05, "alpha_value": 0.01604536780155119, "duration": 54.379944801330566, "step": 52000}
{"episode_reward": 141.1239473885867, "episode": 209.0, "batch_reward": 0.3786431860923767, "critic_loss": 5.538700759887695, "ae_transition_loss": 0.09312861493229865, "ae_encoder_loss": 0.309105004966259, "actor_loss": -26.81490980529785, "actor_target_entropy": -6.0, "actor_entropy": 5.9002011756896975, "alpha_loss": 0.0041739745000377295, "alpha_value": 0.015346987081300749, "duration": 54.586355447769165, "step": 52250}
{"episode_reward": 144.51564636713542, "episode": 210.0, "batch_reward": 0.37976012933254244, "critic_loss": 2.982902132511139, "ae_transition_loss": 0.06389765965938568, "ae_encoder_loss": 0.285847472846508, "actor_loss": -27.073260635375977, "actor_target_entropy": -6.0, "actor_entropy": 5.6240735206604, "alpha_loss": -0.0011514929640106858, "alpha_value": 0.014788317599606497, "duration": 54.17630648612976, "step": 52500}
{"episode_reward": 119.07825203161852, "episode": 211.0, "batch_reward": 0.3802717365026474, "critic_loss": 4.807102766990662, "ae_transition_loss": 0.08496288368105888, "ae_encoder_loss": 0.31144175690412523, "actor_loss": -26.99328007507324, "actor_target_entropy": -6.0, "actor_entropy": 5.6925058212280275, "alpha_loss": -0.002225356286857277, "alpha_value": 0.015372566697225415, "duration": 68.28982067108154, "step": 52750}
{"episode_reward": 157.2300365041393, "episode": 212.0, "batch_reward": 0.3828717325925827, "critic_loss": 4.19966900730133, "ae_transition_loss": 0.08025652872025966, "ae_encoder_loss": 0.3155244147777557, "actor_loss": -27.059446228027344, "actor_target_entropy": -6.0, "actor_entropy": 5.717945789337159, "alpha_loss": -0.000799152331892401, "alpha_value": 0.015377321190312597, "duration": 54.256895542144775, "step": 53000}
{"episode_reward": 126.91253028582207, "episode": 213.0, "batch_reward": 0.3811930795907974, "critic_loss": 3.4264606018066406, "ae_transition_loss": 0.06262139289081096, "ae_encoder_loss": 0.3002457681894302, "actor_loss": -27.14427780151367, "actor_target_entropy": -6.0, "actor_entropy": 5.612256866455078, "alpha_loss": -0.0052322401367127895, "alpha_value": 0.01680442121536304, "duration": 54.36578917503357, "step": 53250}
{"episode_reward": 85.54110178772193, "episode": 214.0, "batch_reward": 0.38074318373203275, "critic_loss": 3.7581540927886965, "ae_transition_loss": 0.0651600387841463, "ae_encoder_loss": 0.2982331978082657, "actor_loss": -27.119467544555665, "actor_target_entropy": -6.0, "actor_entropy": 5.741130447387695, "alpha_loss": 0.002303951357724145, "alpha_value": 0.016962772195405786, "duration": 54.42819666862488, "step": 53500}
{"episode_reward": 48.52277178280695, "episode": 215.0, "batch_reward": 0.3806346414089203, "critic_loss": 3.154459674835205, "ae_transition_loss": 0.06077968300879002, "ae_encoder_loss": 0.290040315747261, "actor_loss": -27.309433303833007, "actor_target_entropy": -6.0, "actor_entropy": 5.585759777069092, "alpha_loss": 0.002635617335792631, "alpha_value": 0.01646786400435109, "duration": 54.1112961769104, "step": 53750}
{"episode_reward": 77.63262526891414, "episode": 216.0, "batch_reward": 0.3809400850534439, "critic_loss": 2.908952537536621, "ae_transition_loss": 0.061181048035621646, "ae_encoder_loss": 0.30391363203525545, "actor_loss": -27.264341445922852, "actor_target_entropy": -6.0, "actor_entropy": 5.656792839050293, "alpha_loss": -0.0016712248674593867, "alpha_value": 0.01620887301134634, "duration": 54.55621099472046, "step": 54000}
{"episode_reward": 131.3419063960463, "episode": 217.0, "batch_reward": 0.3813775932788849, "critic_loss": 3.862334658622742, "ae_transition_loss": 0.07504155522584915, "ae_encoder_loss": 0.3203227778673172, "actor_loss": -27.26699702453613, "actor_target_entropy": -6.0, "actor_entropy": 5.643962673187255, "alpha_loss": 0.0016574061689898373, "alpha_value": 0.01656309952297099, "duration": 54.49402618408203, "step": 54250}
{"episode_reward": 127.08424262864345, "episode": 218.0, "batch_reward": 0.3827414717674255, "critic_loss": 10.795516459465027, "ae_transition_loss": 0.1403822503685951, "ae_encoder_loss": 0.34366573733091355, "actor_loss": -27.02870896911621, "actor_target_entropy": -6.0, "actor_entropy": 5.994626605987549, "alpha_loss": 0.006175326303578913, "alpha_value": 0.01573294217779154, "duration": 54.08065629005432, "step": 54500}
{"episode_reward": 87.8402036813407, "episode": 219.0, "batch_reward": 0.3826863729953766, "critic_loss": 6.398179811000824, "ae_transition_loss": 0.09686158600449563, "ae_encoder_loss": 0.31718894350528715, "actor_loss": -26.933871170043947, "actor_target_entropy": -6.0, "actor_entropy": 5.891637428283691, "alpha_loss": 0.0009636214906349779, "alpha_value": 0.014337156929271913, "duration": 54.4203155040741, "step": 54750}
{"episode_reward": 163.59021234001014, "episode": 220.0, "batch_reward": 0.3819484168291092, "critic_loss": 3.2668881154060365, "ae_transition_loss": 0.06356915962696076, "ae_encoder_loss": 0.29200571089982985, "actor_loss": -27.04976412963867, "actor_target_entropy": -6.0, "actor_entropy": 5.7602378997802735, "alpha_loss": -0.0037062602411024274, "alpha_value": 0.014519815005553629, "duration": 54.513423204422, "step": 55000}
{"episode_reward": 64.9624185080241, "episode": 221.0, "batch_reward": 0.38304455423355105, "critic_loss": 2.7302463936805723, "ae_transition_loss": 0.05885034592449665, "ae_encoder_loss": 0.30229282265901564, "actor_loss": -27.31007354736328, "actor_target_entropy": -6.0, "actor_entropy": 5.659567176818848, "alpha_loss": -0.003468776868656278, "alpha_value": 0.015667692378788595, "duration": 68.21776127815247, "step": 55250}
{"episode_reward": 86.9529862190542, "episode": 222.0, "batch_reward": 0.3806305750608444, "critic_loss": 2.7333552141189577, "ae_transition_loss": 0.05650883315503597, "ae_encoder_loss": 0.303817830324173, "actor_loss": -27.194950759887696, "actor_target_entropy": -6.0, "actor_entropy": 5.612570407867431, "alpha_loss": -0.0029937605066224933, "alpha_value": 0.016241735019394923, "duration": 54.44660449028015, "step": 55500}
{"episode_reward": 90.0471439662982, "episode": 223.0, "batch_reward": 0.3825745049715042, "critic_loss": 4.414874268054962, "ae_transition_loss": 0.06935313364863396, "ae_encoder_loss": 0.31505926728248596, "actor_loss": -27.313023391723632, "actor_target_entropy": -6.0, "actor_entropy": 5.726632877349854, "alpha_loss": 0.0016315665193833411, "alpha_value": 0.016481152714561624, "duration": 54.16667079925537, "step": 55750}
{"episode_reward": 113.88136483069941, "episode": 224.0, "batch_reward": 0.38252997159957886, "critic_loss": 5.895552596092224, "ae_transition_loss": 0.09472321881353855, "ae_encoder_loss": 0.32690962409973146, "actor_loss": -27.290014770507813, "actor_target_entropy": -6.0, "actor_entropy": 5.697614669799805, "alpha_loss": 0.0025434293863363564, "alpha_value": 0.01634397628807824, "duration": 54.54484534263611, "step": 56000}
{"episode_reward": 48.75034830398939, "episode": 225.0, "batch_reward": 0.3827019302845001, "critic_loss": 4.3700553612709045, "ae_transition_loss": 0.08111434505879879, "ae_encoder_loss": 0.3116784972548485, "actor_loss": -27.407473663330077, "actor_target_entropy": -6.0, "actor_entropy": 5.614212261199951, "alpha_loss": 0.0002994273027870804, "alpha_value": 0.015518066567171992, "duration": 54.49433755874634, "step": 56250}
{"episode_reward": 215.90702719610022, "episode": 226.0, "batch_reward": 0.3837813611030579, "critic_loss": 2.9874783711433412, "ae_transition_loss": 0.0664677148014307, "ae_encoder_loss": 0.3104757314324379, "actor_loss": -27.534729553222657, "actor_target_entropy": -6.0, "actor_entropy": 5.590116081237793, "alpha_loss": -0.004004355941899121, "alpha_value": 0.016234625302512865, "duration": 54.113440990448, "step": 56500}
{"episode_reward": 184.2017228157868, "episode": 227.0, "batch_reward": 0.3849633240699768, "critic_loss": 3.8955510301589964, "ae_transition_loss": 0.0738088022172451, "ae_encoder_loss": 0.32465467071533205, "actor_loss": -27.57017788696289, "actor_target_entropy": -6.0, "actor_entropy": 5.651966125488281, "alpha_loss": 0.0002998845423571765, "alpha_value": 0.01672353504889018, "duration": 54.42461442947388, "step": 56750}
{"episode_reward": 149.17181313431735, "episode": 228.0, "batch_reward": 0.38600718283653257, "critic_loss": 4.538620129108429, "ae_transition_loss": 0.08650020582973957, "ae_encoder_loss": 0.321169957280159, "actor_loss": -27.701167282104493, "actor_target_entropy": -6.0, "actor_entropy": 5.632181793212891, "alpha_loss": -0.0013432027832604944, "alpha_value": 0.016792265594791408, "duration": 54.50925803184509, "step": 57000}
{"episode_reward": 134.90521414243335, "episode": 229.0, "batch_reward": 0.3883072725534439, "critic_loss": 4.530401375770569, "ae_transition_loss": 0.0807650756239891, "ae_encoder_loss": 0.326563437461853, "actor_loss": -27.786269348144533, "actor_target_entropy": -6.0, "actor_entropy": 5.650439151763916, "alpha_loss": 0.0042652311827987436, "alpha_value": 0.016603134804753082, "duration": 54.359641313552856, "step": 57250}
{"episode_reward": 90.08466481977797, "episode": 230.0, "batch_reward": 0.38551665031909943, "critic_loss": 5.092389566421509, "ae_transition_loss": 0.08641160717606544, "ae_encoder_loss": 0.3405023149251938, "actor_loss": -27.639287292480468, "actor_target_entropy": -6.0, "actor_entropy": 5.6612206687927245, "alpha_loss": 0.0024000286618247628, "alpha_value": 0.015567076572249197, "duration": 54.483782052993774, "step": 57500}
{"episode_reward": 168.6225454884281, "episode": 231.0, "batch_reward": 0.3876945683956146, "critic_loss": 7.917195115089417, "ae_transition_loss": 0.11972798016667366, "ae_encoder_loss": 0.3509813064336777, "actor_loss": -27.65532864379883, "actor_target_entropy": -6.0, "actor_entropy": 5.77995195388794, "alpha_loss": 0.002121898157056421, "alpha_value": 0.015139175031975892, "duration": 68.1496958732605, "step": 57750}
{"episode_reward": 150.48454243143368, "episode": 232.0, "batch_reward": 0.3895802948474884, "critic_loss": 4.24446479177475, "ae_transition_loss": 0.08139325526356697, "ae_encoder_loss": 0.33733193737268446, "actor_loss": -27.88040673828125, "actor_target_entropy": -6.0, "actor_entropy": 5.658680683135986, "alpha_loss": -0.004665408309083432, "alpha_value": 0.015226596354081755, "duration": 54.44018363952637, "step": 58000}
{"episode_reward": 172.04698301771904, "episode": 233.0, "batch_reward": 0.3903056457042694, "critic_loss": 6.813851977348327, "ae_transition_loss": 0.10753339275717735, "ae_encoder_loss": 0.35168594229221345, "actor_loss": -27.838488845825196, "actor_target_entropy": -6.0, "actor_entropy": 5.71522289276123, "alpha_loss": -0.004265259566251189, "alpha_value": 0.016625301852228574, "duration": 54.52606439590454, "step": 58250}
{"episode_reward": 32.33434147086906, "episode": 234.0, "batch_reward": 0.3906191490888596, "critic_loss": 4.109373561382293, "ae_transition_loss": 0.07880792248249054, "ae_encoder_loss": 0.3360244826078415, "actor_loss": -27.850027725219725, "actor_target_entropy": -6.0, "actor_entropy": 5.7459421081542965, "alpha_loss": 0.0014396316902711987, "alpha_value": 0.016771463555467474, "duration": 54.284645557403564, "step": 58500}
{"episode_reward": 74.85062069010374, "episode": 235.0, "batch_reward": 0.3901732338666916, "critic_loss": 3.9323143167495727, "ae_transition_loss": 0.07350437080860138, "ae_encoder_loss": 0.33381016325950624, "actor_loss": -27.97830679321289, "actor_target_entropy": -6.0, "actor_entropy": 5.662268028259278, "alpha_loss": -0.001619092668639496, "alpha_value": 0.016771696702715708, "duration": 54.40431809425354, "step": 58750}
{"episode_reward": 165.41404295347846, "episode": 236.0, "batch_reward": 0.38900944697856904, "critic_loss": 3.8346291284561156, "ae_transition_loss": 0.06708572283387185, "ae_encoder_loss": 0.32292480212450025, "actor_loss": -27.9931893157959, "actor_target_entropy": -6.0, "actor_entropy": 5.664468006134033, "alpha_loss": 0.000609058286761865, "alpha_value": 0.017044370291330775, "duration": 54.388431787490845, "step": 59000}
{"episode_reward": 137.27231801911336, "episode": 237.0, "batch_reward": 0.39213023483753207, "critic_loss": 5.073488926887512, "ae_transition_loss": 0.08058374059200286, "ae_encoder_loss": 0.3518166543245316, "actor_loss": -27.987071212768555, "actor_target_entropy": -6.0, "actor_entropy": 5.785062335968018, "alpha_loss": 0.0014890546230599284, "alpha_value": 0.016775364310568208, "duration": 54.38977336883545, "step": 59250}
{"episode_reward": 148.96587597084778, "episode": 238.0, "batch_reward": 0.3922838649749756, "critic_loss": 5.955723918437958, "ae_transition_loss": 0.08924597452580929, "ae_encoder_loss": 0.3501969989538193, "actor_loss": -28.064664657592772, "actor_target_entropy": -6.0, "actor_entropy": 5.681495784759521, "alpha_loss": -0.0017534280526451766, "alpha_value": 0.016661830905558603, "duration": 54.66194725036621, "step": 59500}
{"episode_reward": 117.2964031780733, "episode": 239.0, "batch_reward": 0.3937453454732895, "critic_loss": 9.769940433502198, "ae_transition_loss": 0.1348640694320202, "ae_encoder_loss": 0.36540088814496996, "actor_loss": -27.754366744995117, "actor_target_entropy": -6.0, "actor_entropy": 5.867610469818115, "alpha_loss": -0.0021846283823251725, "alpha_value": 0.017576456344987147, "duration": 54.17254424095154, "step": 59750}
{"episode_reward": 160.5380691010603, "episode": 240.0, "batch_reward": 0.39239523506164553, "critic_loss": 6.14871516418457, "ae_transition_loss": 0.0938542263507843, "ae_encoder_loss": 0.36526383554935454, "actor_loss": -27.786547576904297, "actor_target_entropy": -6.0, "actor_entropy": 5.880620292663574, "alpha_loss": 0.005457847088575363, "alpha_value": 0.016731077665945202, "duration": 54.471691846847534, "step": 60000}
{"episode_reward": 180.74764319140198, "episode": 241.0, "batch_reward": 0.39366647410392763, "critic_loss": 5.727159673690796, "ae_transition_loss": 0.08523447529971599, "ae_encoder_loss": 0.33340008693933487, "actor_loss": -27.93812796020508, "actor_target_entropy": -6.0, "actor_entropy": 5.8529392471313475, "alpha_loss": -0.0031481134253554047, "alpha_value": 0.016743986080108117, "duration": 74.93005466461182, "step": 60250}
{"episode_reward": 133.4383358743689, "episode": 242.0, "batch_reward": 0.3960380569696426, "critic_loss": 4.315493912696838, "ae_transition_loss": 0.07333222928643227, "ae_encoder_loss": 0.33881787973642347, "actor_loss": -28.118575225830078, "actor_target_entropy": -6.0, "actor_entropy": 5.760468296051025, "alpha_loss": 0.0002126359569374472, "alpha_value": 0.01707454562723493, "duration": 54.55742359161377, "step": 60500}
{"episode_reward": 134.0978420944725, "episode": 243.0, "batch_reward": 0.39516732263565063, "critic_loss": 3.9869808082580565, "ae_transition_loss": 0.06679129661619664, "ae_encoder_loss": 0.3416429640054703, "actor_loss": -27.95815333557129, "actor_target_entropy": -6.0, "actor_entropy": 5.764366333007812, "alpha_loss": -0.0020301029114052653, "alpha_value": 0.01743458656638343, "duration": 54.543434143066406, "step": 60750}
{"episode_reward": 70.1776649688435, "episode": 244.0, "batch_reward": 0.39557007455825804, "critic_loss": 3.5379436593055726, "ae_transition_loss": 0.06472226350009441, "ae_encoder_loss": 0.3414710630774498, "actor_loss": -28.197313735961913, "actor_target_entropy": -6.0, "actor_entropy": 5.670162399291992, "alpha_loss": -0.003014283155091107, "alpha_value": 0.01784988819228455, "duration": 54.24809789657593, "step": 61000}
{"episode_reward": 124.36991848844112, "episode": 245.0, "batch_reward": 0.39478674125671387, "critic_loss": 4.016403211593628, "ae_transition_loss": 0.0694114735275507, "ae_encoder_loss": 0.33497315365076064, "actor_loss": -28.040686782836914, "actor_target_entropy": -6.0, "actor_entropy": 5.803477466583252, "alpha_loss": 0.0054779977505095305, "alpha_value": 0.017637555404546725, "duration": 54.49630880355835, "step": 61250}
{"episode_reward": 159.55072365563166, "episode": 246.0, "batch_reward": 0.3961060824394226, "critic_loss": 6.583666410446167, "ae_transition_loss": 0.09131642131507396, "ae_encoder_loss": 0.36056478303670886, "actor_loss": -28.20118507385254, "actor_target_entropy": -6.0, "actor_entropy": 5.77818404006958, "alpha_loss": 0.0027010110747069122, "alpha_value": 0.016816073709235484, "duration": 54.46920037269592, "step": 61500}
{"episode_reward": 81.62825956004096, "episode": 247.0, "batch_reward": 0.3954901229143143, "critic_loss": 14.646171664237976, "ae_transition_loss": 0.15244478592276572, "ae_encoder_loss": 0.3804249111413956, "actor_loss": -27.872346282958983, "actor_target_entropy": -6.0, "actor_entropy": 5.9666238899230954, "alpha_loss": 0.0060693996991030875, "alpha_value": 0.015919972160554942, "duration": 54.44007182121277, "step": 61750}
{"episode_reward": 123.20919039040199, "episode": 248.0, "batch_reward": 0.39657556760311125, "critic_loss": 8.675762912750244, "ae_transition_loss": 0.10141752101480961, "ae_encoder_loss": 0.3461855090856552, "actor_loss": -27.93593731689453, "actor_target_entropy": -6.0, "actor_entropy": 5.739032932281495, "alpha_loss": -0.001924901149701327, "alpha_value": 0.014703341770831631, "duration": 54.540290117263794, "step": 62000}
{"episode_reward": 147.4524773610365, "episode": 249.0, "batch_reward": 0.39590534508228303, "critic_loss": 4.946880916595459, "ae_transition_loss": 0.07430706407129764, "ae_encoder_loss": 0.3270212895274162, "actor_loss": -27.816667205810546, "actor_target_entropy": -6.0, "actor_entropy": 5.782818283081054, "alpha_loss": -0.0017289144936949014, "alpha_value": 0.015312592463524378, "duration": 54.13567590713501, "step": 62250}
{"episode_reward": 74.08114801640835, "episode": 250.0, "batch_reward": 0.39838607037067414, "critic_loss": 4.354286712646484, "ae_transition_loss": 0.06576060427725315, "ae_encoder_loss": 0.3191482710838318, "actor_loss": -27.929301528930665, "actor_target_entropy": -6.0, "actor_entropy": 5.775338871002197, "alpha_loss": -0.0005061797969974578, "alpha_value": 0.01571540629473932, "duration": 54.567145586013794, "step": 62500}
{"episode_reward": 33.49998580665217, "episode": 251.0, "batch_reward": 0.3961739013195038, "critic_loss": 4.535421514987946, "ae_transition_loss": 0.06457997459173202, "ae_encoder_loss": 0.319477975666523, "actor_loss": -27.987833663940428, "actor_target_entropy": -6.0, "actor_entropy": 5.652138793945313, "alpha_loss": -0.0022293398957699538, "alpha_value": 0.015930401162180894, "duration": 68.51272058486938, "step": 62750}
{"episode_reward": 111.36851985116687, "episode": 252.0, "batch_reward": 0.39634119057655337, "critic_loss": 4.098586890220642, "ae_transition_loss": 0.06674668008089066, "ae_encoder_loss": 0.32461734336614606, "actor_loss": -27.96302131652832, "actor_target_entropy": -6.0, "actor_entropy": 5.660657081604004, "alpha_loss": 0.0009132521520368755, "alpha_value": 0.016447407328496377, "duration": 54.48059844970703, "step": 63000}
{"episode_reward": 168.20764988397156, "episode": 253.0, "batch_reward": 0.39632421350479125, "critic_loss": 4.438291717529297, "ae_transition_loss": 0.07170448043942451, "ae_encoder_loss": 0.33192885595560073, "actor_loss": -28.008178176879884, "actor_target_entropy": -6.0, "actor_entropy": 5.708112258911132, "alpha_loss": -0.0002976653673686087, "alpha_value": 0.01585853057747829, "duration": 54.68924951553345, "step": 63250}
{"episode_reward": 133.28396176359047, "episode": 254.0, "batch_reward": 0.39841765105724336, "critic_loss": 5.584697443008423, "ae_transition_loss": 0.08225981105864048, "ae_encoder_loss": 0.3370423858165741, "actor_loss": -28.13560203552246, "actor_target_entropy": -6.0, "actor_entropy": 5.766004062652588, "alpha_loss": 0.001539695033337921, "alpha_value": 0.015985246986095585, "duration": 54.33591270446777, "step": 63500}
{"episode_reward": 75.09071589198177, "episode": 255.0, "batch_reward": 0.3979339030981064, "critic_loss": 4.18501758480072, "ae_transition_loss": 0.07126484113931655, "ae_encoder_loss": 0.3328986673951149, "actor_loss": -28.17669697570801, "actor_target_entropy": -6.0, "actor_entropy": 5.760885063171386, "alpha_loss": 0.0002961291829124093, "alpha_value": 0.015692916214085802, "duration": 54.500181436538696, "step": 63750}
{"episode_reward": 98.75862657924829, "episode": 256.0, "batch_reward": 0.399689267039299, "critic_loss": 4.111563030719757, "ae_transition_loss": 0.07043483124673366, "ae_encoder_loss": 0.34535255408287047, "actor_loss": -28.36274575805664, "actor_target_entropy": -6.0, "actor_entropy": 5.749371070861816, "alpha_loss": 3.0044975224882365e-05, "alpha_value": 0.015477314747895701, "duration": 54.521239042282104, "step": 64000}
{"episode_reward": 183.87060948279847, "episode": 257.0, "batch_reward": 0.4025583652257919, "critic_loss": 11.324736810684204, "ae_transition_loss": 0.13123726136982442, "ae_encoder_loss": 0.36980489444732667, "actor_loss": -28.348356674194335, "actor_target_entropy": -6.0, "actor_entropy": 5.939382034301758, "alpha_loss": 0.00277535061002709, "alpha_value": 0.015868497654386308, "duration": 54.51027250289917, "step": 64250}
{"episode_reward": 109.04399714329584, "episode": 258.0, "batch_reward": 0.39930104804039, "critic_loss": 10.503666524887086, "ae_transition_loss": 0.12533824506402017, "ae_encoder_loss": 0.3717724506258965, "actor_loss": -27.866286163330077, "actor_target_entropy": -6.0, "actor_entropy": 5.989219905853272, "alpha_loss": 0.0029560274411924185, "alpha_value": 0.014693238203904663, "duration": 54.559388160705566, "step": 64500}
{"episode_reward": 88.6898456287265, "episode": 259.0, "batch_reward": 0.3962411880493164, "critic_loss": 5.066239487171173, "ae_transition_loss": 0.08703340989351273, "ae_encoder_loss": 0.3435896386504173, "actor_loss": -27.955692214965822, "actor_target_entropy": -6.0, "actor_entropy": 5.772980739593506, "alpha_loss": -0.0024097294930834324, "alpha_value": 0.014408675251296924, "duration": 54.238434076309204, "step": 64750}
{"episode_reward": 55.97317791077831, "episode": 260.0, "batch_reward": 0.39789282071590426, "critic_loss": 5.986685435771943, "ae_transition_loss": 0.09347939467430115, "ae_encoder_loss": 0.3469305233955383, "actor_loss": -27.765482315063476, "actor_target_entropy": -6.0, "actor_entropy": 5.920241622924805, "alpha_loss": 0.0012095651724375784, "alpha_value": 0.014807690212404476, "duration": 54.57147216796875, "step": 65000}
{"episode_reward": 152.00516085827604, "episode": 261.0, "batch_reward": 0.3992059777975082, "critic_loss": 5.58933395576477, "ae_transition_loss": 0.0914575860351324, "ae_encoder_loss": 0.3585998291373253, "actor_loss": -27.678755111694336, "actor_target_entropy": -6.0, "actor_entropy": 6.018756980895996, "alpha_loss": 0.001475171105004847, "alpha_value": 0.014166008890546025, "duration": 68.38947296142578, "step": 65250}
{"episode_reward": 116.67372439936838, "episode": 262.0, "batch_reward": 0.39931921696662903, "critic_loss": 4.0994957447052, "ae_transition_loss": 0.07240905769169331, "ae_encoder_loss": 0.3276524208188057, "actor_loss": -27.837903076171877, "actor_target_entropy": -6.0, "actor_entropy": 5.853952537536621, "alpha_loss": -0.0025090530631132423, "alpha_value": 0.014552356030895301, "duration": 54.62456917762756, "step": 65500}
{"episode_reward": 92.59077006880426, "episode": 263.0, "batch_reward": 0.39889061892032623, "critic_loss": 5.208428301811218, "ae_transition_loss": 0.08668723994493485, "ae_encoder_loss": 0.3455395250916481, "actor_loss": -27.80570376586914, "actor_target_entropy": -6.0, "actor_entropy": 5.91036336517334, "alpha_loss": -0.0003616315983235836, "alpha_value": 0.01538075536211154, "duration": 54.68572449684143, "step": 65750}
{"episode_reward": 87.18173472954024, "episode": 264.0, "batch_reward": 0.40018709790706636, "critic_loss": 6.858222580909729, "ae_transition_loss": 0.09109115025401116, "ae_encoder_loss": 0.3474091647863388, "actor_loss": -27.627381881713866, "actor_target_entropy": -6.0, "actor_entropy": 5.906569202423095, "alpha_loss": 0.00013836475694552065, "alpha_value": 0.014741102110944872, "duration": 54.39018964767456, "step": 66000}
{"episode_reward": 60.48540455117401, "episode": 265.0, "batch_reward": 0.3991069495677948, "critic_loss": 8.381862946510315, "ae_transition_loss": 0.09716256277263165, "ae_encoder_loss": 0.3668040226101875, "actor_loss": -27.391225631713866, "actor_target_entropy": -6.0, "actor_entropy": 5.967485740661621, "alpha_loss": 0.0010915476470254363, "alpha_value": 0.014825650287409425, "duration": 54.62677001953125, "step": 66250}
{"episode_reward": 64.22422902347466, "episode": 266.0, "batch_reward": 0.3975987683534622, "critic_loss": 10.591267528533935, "ae_transition_loss": 0.13706212255358696, "ae_encoder_loss": 0.379235809981823, "actor_loss": -27.219847595214844, "actor_target_entropy": -6.0, "actor_entropy": 5.966801116943359, "alpha_loss": 0.0010439626108855009, "alpha_value": 0.014877252491947218, "duration": 54.28468894958496, "step": 66500}
{"episode_reward": 35.052451528732, "episode": 267.0, "batch_reward": 0.3962956210374832, "critic_loss": 5.524493087768555, "ae_transition_loss": 0.08354463943839073, "ae_encoder_loss": 0.34898718529939654, "actor_loss": -27.042008682250977, "actor_target_entropy": -6.0, "actor_entropy": 6.001356811523437, "alpha_loss": 0.0028574835089966656, "alpha_value": 0.014058886791129384, "duration": 54.65767312049866, "step": 66750}
{"episode_reward": 76.90281611203613, "episode": 268.0, "batch_reward": 0.39563305842876434, "critic_loss": 6.010733302116394, "ae_transition_loss": 0.08573627115786076, "ae_encoder_loss": 0.3532843800187111, "actor_loss": -27.215124404907225, "actor_target_entropy": -6.0, "actor_entropy": 5.985822277069092, "alpha_loss": -0.0036025897893123327, "alpha_value": 0.014020280067511721, "duration": 54.65368294715881, "step": 67000}
{"episode_reward": 60.38093362816692, "episode": 269.0, "batch_reward": 0.39658387994766237, "critic_loss": 6.471072684288025, "ae_transition_loss": 0.0797284430116415, "ae_encoder_loss": 0.36625908482074737, "actor_loss": -27.082823547363283, "actor_target_entropy": -6.0, "actor_entropy": 6.006079517364502, "alpha_loss": 0.0009326123287901282, "alpha_value": 0.014586315432946063, "duration": 54.466219425201416, "step": 67250}
{"episode_reward": 111.23910474256935, "episode": 270.0, "batch_reward": 0.3963018534183502, "critic_loss": 5.032084757804871, "ae_transition_loss": 0.07363791690766812, "ae_encoder_loss": 0.3352009326219559, "actor_loss": -27.257891098022462, "actor_target_entropy": -6.0, "actor_entropy": 5.995826259613037, "alpha_loss": -0.000735847849631682, "alpha_value": 0.014389053715549846, "duration": 54.62168025970459, "step": 67500}
{"episode_reward": 82.19334484303623, "episode": 271.0, "batch_reward": 0.3950272490978241, "critic_loss": 6.97632532119751, "ae_transition_loss": 0.08842690958082676, "ae_encoder_loss": 0.3648211570978165, "actor_loss": -26.968599060058594, "actor_target_entropy": -6.0, "actor_entropy": 6.046155563354493, "alpha_loss": 0.0037741682725027205, "alpha_value": 0.014145726973088774, "duration": 68.09354281425476, "step": 67750}
{"episode_reward": 54.21877154694102, "episode": 272.0, "batch_reward": 0.3950982390642166, "critic_loss": 6.529188955307007, "ae_transition_loss": 0.07587817104160785, "ae_encoder_loss": 0.3431418053507805, "actor_loss": -26.96421141052246, "actor_target_entropy": -6.0, "actor_entropy": 5.9385750885009765, "alpha_loss": -0.0006077845697291196, "alpha_value": 0.013649481464707364, "duration": 53.983999252319336, "step": 68000}
{"episode_reward": 86.31155267067496, "episode": 273.0, "batch_reward": 0.3950039737224579, "critic_loss": 7.142766229629516, "ae_transition_loss": 0.08306274889409541, "ae_encoder_loss": 0.3568463319540024, "actor_loss": -26.95997001647949, "actor_target_entropy": -6.0, "actor_entropy": 6.045044807434082, "alpha_loss": -0.001510732527822256, "alpha_value": 0.014220214151959367, "duration": 53.93208575248718, "step": 68250}
{"episode_reward": 118.53144326665438, "episode": 274.0, "batch_reward": 0.39575098633766176, "critic_loss": 6.634052946090698, "ae_transition_loss": 0.08606088180840016, "ae_encoder_loss": 0.36548168540000914, "actor_loss": -27.0105926361084, "actor_target_entropy": -6.0, "actor_entropy": 5.940333408355713, "alpha_loss": -0.00010769082326442004, "alpha_value": 0.014277636008523416, "duration": 53.99176335334778, "step": 68500}
{"episode_reward": 115.23741738299948, "episode": 275.0, "batch_reward": 0.3945788305997848, "critic_loss": 12.95902896785736, "ae_transition_loss": 0.1314791383445263, "ae_encoder_loss": 0.36352140915393827, "actor_loss": -26.533657165527345, "actor_target_entropy": -6.0, "actor_entropy": 6.121716690063477, "alpha_loss": 0.0049846038720570505, "alpha_value": 0.013668552056756463, "duration": 54.010581731796265, "step": 68750}
{"episode_reward": 100.07166209299305, "episode": 276.0, "batch_reward": 0.3962584377527237, "critic_loss": 7.858845557212829, "ae_transition_loss": 0.10679951772093772, "ae_encoder_loss": 0.35706154626607894, "actor_loss": -26.68162512207031, "actor_target_entropy": -6.0, "actor_entropy": 6.135276222229004, "alpha_loss": 0.004078657703474164, "alpha_value": 0.012829406469187052, "duration": 53.73596787452698, "step": 69000}
{"episode_reward": 104.73852053980262, "episode": 277.0, "batch_reward": 0.3947476352453232, "critic_loss": 7.425901082992554, "ae_transition_loss": 0.09069799010455608, "ae_encoder_loss": 0.37851547437906263, "actor_loss": -26.692418563842775, "actor_target_entropy": -6.0, "actor_entropy": 5.945085987091065, "alpha_loss": -0.004729535920079798, "alpha_value": 0.012576057000083442, "duration": 54.086299657821655, "step": 69250}
{"episode_reward": 95.15202737605568, "episode": 278.0, "batch_reward": 0.3966083526611328, "critic_loss": 10.927622700691224, "ae_transition_loss": 0.11309471628069878, "ae_encoder_loss": 0.3825887314081192, "actor_loss": -26.68124705505371, "actor_target_entropy": -6.0, "actor_entropy": 6.014748649597168, "alpha_loss": 0.00038726870226673784, "alpha_value": 0.01299063623796028, "duration": 53.7806510925293, "step": 69500}
{"episode_reward": 58.143146053355856, "episode": 279.0, "batch_reward": 0.3960646574497223, "critic_loss": 5.323341167926788, "ae_transition_loss": 0.07557663060724736, "ae_encoder_loss": 0.35328228455781935, "actor_loss": -26.71862632751465, "actor_target_entropy": -6.0, "actor_entropy": 5.877161354064941, "alpha_loss": -0.0037975515620782972, "alpha_value": 0.013160110748684135, "duration": 53.962162733078, "step": 69750}
{"episode_reward": 59.996928811584745, "episode": 280.0, "batch_reward": 0.3952150214910507, "critic_loss": 6.877462558746338, "ae_transition_loss": 0.07517745123803615, "ae_encoder_loss": 0.35557747930288314, "actor_loss": -26.656974807739257, "actor_target_entropy": -6.0, "actor_entropy": 6.0218127784729, "alpha_loss": -0.0011795247967820615, "alpha_value": 0.014256493031282598, "duration": 54.10481882095337, "step": 70000}
{"episode_reward": 96.76690280540917, "episode": 281.0, "batch_reward": 0.39292126989364623, "critic_loss": 7.417268887519836, "ae_transition_loss": 0.08742315450310707, "ae_encoder_loss": 0.35981481170654295, "actor_loss": -26.656972854614256, "actor_target_entropy": -6.0, "actor_entropy": 6.170434452056885, "alpha_loss": -0.0006965331546962261, "alpha_value": 0.014626485311235908, "duration": 73.46248722076416, "step": 70250}
{"episode_reward": 113.5568209518549, "episode": 282.0, "batch_reward": 0.39511044049263, "critic_loss": 9.514064043998719, "ae_transition_loss": 0.10146045984327794, "ae_encoder_loss": 0.3621105017066002, "actor_loss": -26.658187744140626, "actor_target_entropy": -6.0, "actor_entropy": 6.03756974029541, "alpha_loss": 0.00023820584872737526, "alpha_value": 0.014302897301934262, "duration": 54.000017166137695, "step": 70500}
{"episode_reward": 110.08091210350773, "episode": 283.0, "batch_reward": 0.395777438044548, "critic_loss": 7.5688780355453495, "ae_transition_loss": 0.08319065588712692, "ae_encoder_loss": 0.3613862452507019, "actor_loss": -26.711576278686522, "actor_target_entropy": -6.0, "actor_entropy": 6.001336734771728, "alpha_loss": 0.0019568789526820183, "alpha_value": 0.014323576511225719, "duration": 53.79173827171326, "step": 70750}
{"episode_reward": 111.60635737747829, "episode": 284.0, "batch_reward": 0.39533526957035064, "critic_loss": 5.027843589782715, "ae_transition_loss": 0.07878532871603966, "ae_encoder_loss": 0.376124343752861, "actor_loss": -26.773440521240236, "actor_target_entropy": -6.0, "actor_entropy": 5.8119994812011715, "alpha_loss": -0.004203098728554323, "alpha_value": 0.014291249289849461, "duration": 54.03455185890198, "step": 71000}
{"episode_reward": 54.31370652498644, "episode": 285.0, "batch_reward": 0.39385741436481475, "critic_loss": 5.7221696138381954, "ae_transition_loss": 0.07477449622750282, "ae_encoder_loss": 0.3757155057191849, "actor_loss": -26.73557177734375, "actor_target_entropy": -6.0, "actor_entropy": 5.855898994445801, "alpha_loss": -0.001878706124611199, "alpha_value": 0.01477448302411184, "duration": 53.739994764328, "step": 71250}
{"episode_reward": 66.39688176605695, "episode": 286.0, "batch_reward": 0.3956049696207046, "critic_loss": 6.800397071838379, "ae_transition_loss": 0.08018808878958225, "ae_encoder_loss": 0.37633802342414857, "actor_loss": -26.758922424316406, "actor_target_entropy": -6.0, "actor_entropy": 5.896159687042236, "alpha_loss": 0.0011589916674420238, "alpha_value": 0.015252646377890904, "duration": 53.969382762908936, "step": 71500}
{"episode_reward": 142.109581068957, "episode": 287.0, "batch_reward": 0.39445206117630005, "critic_loss": 6.273744856834411, "ae_transition_loss": 0.08429601918160916, "ae_encoder_loss": 0.37669748973846434, "actor_loss": -26.77649508666992, "actor_target_entropy": -6.0, "actor_entropy": 5.9505751495361325, "alpha_loss": 0.0031233293395489456, "alpha_value": 0.014440891839329645, "duration": 54.134466886520386, "step": 71750}
{"episode_reward": 140.68713958477738, "episode": 288.0, "batch_reward": 0.3961304309368133, "critic_loss": 5.2747920207977295, "ae_transition_loss": 0.07774679264426232, "ae_encoder_loss": 0.37570922082662583, "actor_loss": -26.873176483154296, "actor_target_entropy": -6.0, "actor_entropy": 6.0529989242553714, "alpha_loss": 0.002627599062863737, "alpha_value": 0.014272203986656828, "duration": 53.84507870674133, "step": 72000}
{"episode_reward": 81.04838153518517, "episode": 289.0, "batch_reward": 0.3965527912378311, "critic_loss": 8.113773716926575, "ae_transition_loss": 0.10653484942018986, "ae_encoder_loss": 0.3836628015041351, "actor_loss": -26.771086837768554, "actor_target_entropy": -6.0, "actor_entropy": 5.883713760375977, "alpha_loss": -0.0006458127065561712, "alpha_value": 0.013535129366233438, "duration": 54.16324210166931, "step": 72250}
{"episode_reward": 57.24705289637027, "episode": 290.0, "batch_reward": 0.39443373692035677, "critic_loss": 13.213851699829101, "ae_transition_loss": 0.137750554561615, "ae_encoder_loss": 0.4136727984547615, "actor_loss": -26.398511596679686, "actor_target_entropy": -6.0, "actor_entropy": 6.1556390838623045, "alpha_loss": -0.0012741145803593099, "alpha_value": 0.014261899929335183, "duration": 53.69037675857544, "step": 72500}
{"episode_reward": 67.20569538922591, "episode": 291.0, "batch_reward": 0.3939933301210403, "critic_loss": 7.6728689661026, "ae_transition_loss": 0.09314874233305455, "ae_encoder_loss": 0.3738820026516914, "actor_loss": -26.214651611328126, "actor_target_entropy": -6.0, "actor_entropy": 5.884176536560059, "alpha_loss": -0.00218932174006477, "alpha_value": 0.014077589004858521, "duration": 67.73884057998657, "step": 72750}
{"episode_reward": 145.63233025995743, "episode": 292.0, "batch_reward": 0.3955597032308579, "critic_loss": 6.266834607124329, "ae_transition_loss": 0.08899332192540169, "ae_encoder_loss": 0.3511330043077469, "actor_loss": -26.305029205322267, "actor_target_entropy": -6.0, "actor_entropy": 5.980266445159912, "alpha_loss": 0.0022536273743025957, "alpha_value": 0.01440829758205737, "duration": 53.85338497161865, "step": 73000}
{"episode_reward": 120.08179048013741, "episode": 293.0, "batch_reward": 0.39470444738864896, "critic_loss": 4.756190592765808, "ae_transition_loss": 0.07291629412770272, "ae_encoder_loss": 0.3594579064846039, "actor_loss": -26.242013137817384, "actor_target_entropy": -6.0, "actor_entropy": 5.902526817321777, "alpha_loss": -9.989508241415024e-05, "alpha_value": 0.013939086878457596, "duration": 53.98181486129761, "step": 73250}
{"episode_reward": 94.6553543718384, "episode": 294.0, "batch_reward": 0.394300705075264, "critic_loss": 5.453818762779236, "ae_transition_loss": 0.07462143486738206, "ae_encoder_loss": 0.3571941992044449, "actor_loss": -26.259243606567384, "actor_target_entropy": -6.0, "actor_entropy": 5.887395069122315, "alpha_loss": -0.0009591835178434848, "alpha_value": 0.014075914764919503, "duration": 54.0575168132782, "step": 73500}
{"episode_reward": 102.06779692231024, "episode": 295.0, "batch_reward": 0.39418192505836486, "critic_loss": 5.141808420181275, "ae_transition_loss": 0.07334492439031601, "ae_encoder_loss": 0.35334787917137145, "actor_loss": -26.334384002685546, "actor_target_entropy": -6.0, "actor_entropy": 5.770649215698242, "alpha_loss": 0.0022830557944253085, "alpha_value": 0.014166406903462768, "duration": 53.95134973526001, "step": 73750}
{"episode_reward": 140.28176197905256, "episode": 296.0, "batch_reward": 0.39608760583400726, "critic_loss": 5.221149124145508, "ae_transition_loss": 0.07781596234440803, "ae_encoder_loss": 0.37245509725809095, "actor_loss": -26.534235595703127, "actor_target_entropy": -6.0, "actor_entropy": 5.915205825805664, "alpha_loss": 9.599395468831063e-05, "alpha_value": 0.013940981823700422, "duration": 54.156962871551514, "step": 74000}
{"episode_reward": 138.8826921352687, "episode": 297.0, "batch_reward": 0.3962605890035629, "critic_loss": 6.0266206293106075, "ae_transition_loss": 0.0795092426687479, "ae_encoder_loss": 0.352821826338768, "actor_loss": -26.45340789794922, "actor_target_entropy": -6.0, "actor_entropy": 5.98120027923584, "alpha_loss": -0.0004171812441200018, "alpha_value": 0.01383486993133963, "duration": 53.87954521179199, "step": 74250}
{"episode_reward": 156.33309093553615, "episode": 298.0, "batch_reward": 0.3982829484939575, "critic_loss": 13.116241079330445, "ae_transition_loss": 0.14366199776530267, "ae_encoder_loss": 0.39115009480714796, "actor_loss": -26.310912475585937, "actor_target_entropy": -6.0, "actor_entropy": 5.885166915893555, "alpha_loss": -0.0044179049178492275, "alpha_value": 0.014206616270665925, "duration": 54.20906043052673, "step": 74500}
{"episode_reward": 28.222318151712695, "episode": 299.0, "batch_reward": 0.39626066410541533, "critic_loss": 6.111158445358276, "ae_transition_loss": 0.0909111940562725, "ae_encoder_loss": 0.3558467623591423, "actor_loss": -26.24409111022949, "actor_target_entropy": -6.0, "actor_entropy": 5.948367053985596, "alpha_loss": 0.00376755637396127, "alpha_value": 0.015177676216877515, "duration": 53.92102360725403, "step": 74750}
{"episode_reward": 123.23342675443206, "episode": 300.0, "batch_reward": 0.39657019650936126, "critic_loss": 5.247251040458679, "ae_transition_loss": 0.07436890263855457, "ae_encoder_loss": 0.34831373411417005, "actor_loss": -26.324157730102538, "actor_target_entropy": -6.0, "actor_entropy": 5.76471403503418, "alpha_loss": 0.0019182963268831372, "alpha_value": 0.014116966009705427, "duration": 54.58396816253662, "step": 75000}
{"episode_reward": 129.37362197714225, "episode": 301.0, "batch_reward": 0.39744859433174134, "critic_loss": 5.060494775772095, "ae_transition_loss": 0.0796520253866911, "ae_encoder_loss": 0.35549019503593443, "actor_loss": -26.402526138305664, "actor_target_entropy": -6.0, "actor_entropy": 5.851045860290528, "alpha_loss": 0.003503646832192317, "alpha_value": 0.01325830484643136, "duration": 79.31601691246033, "step": 75250}
{"episode_reward": 131.42352019901006, "episode": 302.0, "batch_reward": 0.39690721571445464, "critic_loss": 5.18431288766861, "ae_transition_loss": 0.07792988455295563, "ae_encoder_loss": 0.34400455439090727, "actor_loss": -26.42089483642578, "actor_target_entropy": -6.0, "actor_entropy": 5.67666711807251, "alpha_loss": -0.0025662696175277233, "alpha_value": 0.013242018985155802, "duration": 54.0996675491333, "step": 75500}
{"episode_reward": 36.24150713885474, "episode": 303.0, "batch_reward": 0.39655698800086975, "critic_loss": 4.456139770030975, "ae_transition_loss": 0.07169333152472973, "ae_encoder_loss": 0.34331716334819795, "actor_loss": -26.341951263427735, "actor_target_entropy": -6.0, "actor_entropy": 5.844571983337402, "alpha_loss": -0.0005846939757466317, "alpha_value": 0.013816866419949189, "duration": 54.755709409713745, "step": 75750}
{"episode_reward": 39.318429257362524, "episode": 304.0, "batch_reward": 0.39626882696151733, "critic_loss": 5.235836584091187, "ae_transition_loss": 0.07023831689357758, "ae_encoder_loss": 0.3505956992506981, "actor_loss": -26.4338780670166, "actor_target_entropy": -6.0, "actor_entropy": 5.8825092697143555, "alpha_loss": 0.00196349535882473, "alpha_value": 0.013418356145746053, "duration": 53.88232374191284, "step": 76000}
{"episode_reward": 60.876510948081986, "episode": 305.0, "batch_reward": 0.3954889485836029, "critic_loss": 5.997325057029724, "ae_transition_loss": 0.07720958632230758, "ae_encoder_loss": 0.3565979013442993, "actor_loss": -26.446436904907227, "actor_target_entropy": -6.0, "actor_entropy": 5.8844096412658695, "alpha_loss": 0.00498599288938567, "alpha_value": 0.012644627914784183, "duration": 54.133235692977905, "step": 76250}
{"episode_reward": 124.25706146022789, "episode": 306.0, "batch_reward": 0.3952161120176315, "critic_loss": 5.289387129783631, "ae_transition_loss": 0.07818172097206116, "ae_encoder_loss": 0.345141011595726, "actor_loss": -26.443725692749023, "actor_target_entropy": -6.0, "actor_entropy": 5.775802768707275, "alpha_loss": -0.0008626846226397902, "alpha_value": 0.012061256724093115, "duration": 54.01626801490784, "step": 76500}
{"episode_reward": 92.92594454700213, "episode": 307.0, "batch_reward": 0.3935128592252731, "critic_loss": 5.133883920669556, "ae_transition_loss": 0.08031795372068883, "ae_encoder_loss": 0.36043808549642564, "actor_loss": -26.433076889038087, "actor_target_entropy": -6.0, "actor_entropy": 5.746145092010498, "alpha_loss": -0.001185618815710768, "alpha_value": 0.012449220561120833, "duration": 54.27288460731506, "step": 76750}
{"episode_reward": 69.26919322376241, "episode": 308.0, "batch_reward": 0.39433643567562104, "critic_loss": 5.277347505569458, "ae_transition_loss": 0.07694229631125928, "ae_encoder_loss": 0.3587825322151184, "actor_loss": -26.559274795532225, "actor_target_entropy": -6.0, "actor_entropy": 5.763225036621094, "alpha_loss": -0.0013685131054371595, "alpha_value": 0.012661761632409325, "duration": 54.318520069122314, "step": 77000}
{"episode_reward": 57.808025948666, "episode": 309.0, "batch_reward": 0.39577700293064116, "critic_loss": 4.302678747177124, "ae_transition_loss": 0.0705948985517025, "ae_encoder_loss": 0.3383250024914741, "actor_loss": -26.45395622253418, "actor_target_entropy": -6.0, "actor_entropy": 5.630143413543701, "alpha_loss": -0.003761216789484024, "alpha_value": 0.013035119456050858, "duration": 53.95013928413391, "step": 77250}
{"episode_reward": 112.99728666347004, "episode": 310.0, "batch_reward": 0.39525850760936737, "critic_loss": 4.316672038078308, "ae_transition_loss": 0.07685039933025838, "ae_encoder_loss": 0.36546652859449386, "actor_loss": -26.655030227661133, "actor_target_entropy": -6.0, "actor_entropy": 5.703841323852539, "alpha_loss": 0.0016380321560427547, "alpha_value": 0.013540977609222614, "duration": 54.202388525009155, "step": 77500}
{"episode_reward": 83.89720124775394, "episode": 311.0, "batch_reward": 0.39332785856723784, "critic_loss": 6.911885823249817, "ae_transition_loss": 0.09892834195494651, "ae_encoder_loss": 0.36647936749458315, "actor_loss": -26.428213958740233, "actor_target_entropy": -6.0, "actor_entropy": 5.788451480865478, "alpha_loss": 0.0016528715253807604, "alpha_value": 0.01323196991472556, "duration": 68.46388936042786, "step": 77750}
{"episode_reward": 129.7199475101217, "episode": 312.0, "batch_reward": 0.39476062715053556, "critic_loss": 10.628696803092957, "ae_transition_loss": 0.1310585464835167, "ae_encoder_loss": 0.35983792597055436, "actor_loss": -26.17519172668457, "actor_target_entropy": -6.0, "actor_entropy": 6.029774784088135, "alpha_loss": 0.0025105141489766536, "alpha_value": 0.012395174879529623, "duration": 54.113792419433594, "step": 78000}
{"episode_reward": 178.30004608572636, "episode": 313.0, "batch_reward": 0.3963575257062912, "critic_loss": 5.012154089927673, "ae_transition_loss": 0.07638301841914653, "ae_encoder_loss": 0.3401913925409317, "actor_loss": -26.35199691772461, "actor_target_entropy": -6.0, "actor_entropy": 5.674545764923096, "alpha_loss": 0.000985636815894395, "alpha_value": 0.012025760053812498, "duration": 54.05373668670654, "step": 78250}
{"episode_reward": 235.4421325526134, "episode": 314.0, "batch_reward": 0.3954401783943176, "critic_loss": 4.132848081588745, "ae_transition_loss": 0.07088938510417939, "ae_encoder_loss": 0.33438930195569994, "actor_loss": -26.340097183227538, "actor_target_entropy": -6.0, "actor_entropy": 5.648555507659912, "alpha_loss": -0.00026557059632614257, "alpha_value": 0.012311073415381187, "duration": 54.128501892089844, "step": 78500}
{"episode_reward": 40.10917491309399, "episode": 315.0, "batch_reward": 0.3984815355539322, "critic_loss": 4.320912121772766, "ae_transition_loss": 0.07110463654994964, "ae_encoder_loss": 0.34086061066389084, "actor_loss": -26.23887042236328, "actor_target_entropy": -6.0, "actor_entropy": 5.9448933601379395, "alpha_loss": 7.039087545126676e-05, "alpha_value": 0.012292634270310299, "duration": 54.258492946624756, "step": 78750}
{"episode_reward": 126.66657952466346, "episode": 316.0, "batch_reward": 0.39568986904621123, "critic_loss": 3.9437950553894043, "ae_transition_loss": 0.06972113516926766, "ae_encoder_loss": 0.35166833823919297, "actor_loss": -26.217067779541015, "actor_target_entropy": -6.0, "actor_entropy": 5.6951447868347165, "alpha_loss": 0.0002864343542605638, "alpha_value": 0.012069997353669475, "duration": 53.93565607070923, "step": 79000}
{"episode_reward": 59.98932904108732, "episode": 317.0, "batch_reward": 0.397863086104393, "critic_loss": 4.257289398193359, "ae_transition_loss": 0.07262717129290104, "ae_encoder_loss": 0.3401845889687538, "actor_loss": -26.470093994140626, "actor_target_entropy": -6.0, "actor_entropy": 5.702361164093017, "alpha_loss": 0.00013308048131875692, "alpha_value": 0.012157712624012794, "duration": 54.242847204208374, "step": 79250}
{"episode_reward": 82.4174260390612, "episode": 318.0, "batch_reward": 0.3956428971290588, "critic_loss": 5.673903505325318, "ae_transition_loss": 0.0834922256320715, "ae_encoder_loss": 0.3645213034152985, "actor_loss": -26.315863037109374, "actor_target_entropy": -6.0, "actor_entropy": 5.74808576965332, "alpha_loss": -0.0018296053325757384, "alpha_value": 0.012361485425632963, "duration": 53.865065813064575, "step": 79500}
{"episode_reward": 101.35494857835313, "episode": 319.0, "batch_reward": 0.39552340865135194, "critic_loss": 6.3384059715270995, "ae_transition_loss": 0.1026787528693676, "ae_encoder_loss": 0.3620963770151138, "actor_loss": -26.18033952331543, "actor_target_entropy": -6.0, "actor_entropy": 5.82046170425415, "alpha_loss": -9.740543086081743e-06, "alpha_value": 0.012464300447738974, "duration": 54.105509757995605, "step": 79750}
{"episode_reward": 199.00011628949727, "episode": 320.0, "batch_reward": 0.3958925684690475, "critic_loss": 4.345945349693299, "ae_transition_loss": 0.07699825981259346, "ae_encoder_loss": 0.3568711469769478, "actor_loss": -26.30313377380371, "actor_target_entropy": -6.0, "actor_entropy": 5.794472827911377, "alpha_loss": 0.0016653900404926389, "alpha_value": 0.012239430301710751, "duration": 54.2812762260437, "step": 80000}
{"episode_reward": 55.4404665551799, "episode": 321.0, "batch_reward": 0.39634871649742126, "critic_loss": 3.700837287902832, "ae_transition_loss": 0.06645266935229302, "ae_encoder_loss": 0.33375429421663283, "actor_loss": -26.22750277709961, "actor_target_entropy": -6.0, "actor_entropy": 5.69635865020752, "alpha_loss": -0.0016401716456748545, "alpha_value": 0.012162150953509527, "duration": 75.79333257675171, "step": 80250}
{"episode_reward": 169.16481076298209, "episode": 322.0, "batch_reward": 0.3982600597143173, "critic_loss": 3.591048454761505, "ae_transition_loss": 0.06831189312040806, "ae_encoder_loss": 0.34578324592113496, "actor_loss": -26.492666168212892, "actor_target_entropy": -6.0, "actor_entropy": 5.569036876678466, "alpha_loss": -0.004999793824274093, "alpha_value": 0.013169252855022946, "duration": 54.11993169784546, "step": 80500}
{"episode_reward": 186.74002601748293, "episode": 323.0, "batch_reward": 0.3992353104352951, "critic_loss": 5.159968615055084, "ae_transition_loss": 0.08919555428624153, "ae_encoder_loss": 0.33973041260242465, "actor_loss": -26.500240631103516, "actor_target_entropy": -6.0, "actor_entropy": 5.503891986846924, "alpha_loss": -5.955210817046463e-05, "alpha_value": 0.013997389897403128, "duration": 53.85137128829956, "step": 80750}
{"episode_reward": 139.6382661865851, "episode": 324.0, "batch_reward": 0.3995412278175354, "critic_loss": 4.322558358192444, "ae_transition_loss": 0.07982231658697128, "ae_encoder_loss": 0.3532620698213577, "actor_loss": -26.628774002075197, "actor_target_entropy": -6.0, "actor_entropy": 5.563735263824463, "alpha_loss": 0.00433471738663502, "alpha_value": 0.013231001897190476, "duration": 54.03770971298218, "step": 81000}
{"episode_reward": 190.92362134928314, "episode": 325.0, "batch_reward": 0.40051208007335665, "critic_loss": 4.946527507781982, "ae_transition_loss": 0.08699966722726822, "ae_encoder_loss": 0.3552199283838272, "actor_loss": -26.674386947631834, "actor_target_entropy": -6.0, "actor_entropy": 5.613733833312988, "alpha_loss": -1.2015711981803178e-05, "alpha_value": 0.012702621984647588, "duration": 53.85980176925659, "step": 81250}
{"episode_reward": 43.40781191804286, "episode": 326.0, "batch_reward": 0.3999993929862976, "critic_loss": 4.328718228340149, "ae_transition_loss": 0.07998787917196751, "ae_encoder_loss": 0.3585899837017059, "actor_loss": -26.76910725402832, "actor_target_entropy": -6.0, "actor_entropy": 5.6709686965942385, "alpha_loss": 0.00012113906256854534, "alpha_value": 0.012770458041067126, "duration": 54.03485727310181, "step": 81500}
{"episode_reward": 164.06584774909436, "episode": 327.0, "batch_reward": 0.40201349663734437, "critic_loss": 4.176021300792694, "ae_transition_loss": 0.07192342479526996, "ae_encoder_loss": 0.32877559572458265, "actor_loss": -26.863655426025392, "actor_target_entropy": -6.0, "actor_entropy": 5.637039234161377, "alpha_loss": 0.0008328296153340489, "alpha_value": 0.012504389126347666, "duration": 54.282280921936035, "step": 81750}
{"episode_reward": 203.2095682182434, "episode": 328.0, "batch_reward": 0.4006823197603226, "critic_loss": 5.224412502288819, "ae_transition_loss": 0.07765043070912361, "ae_encoder_loss": 0.33345656281709674, "actor_loss": -26.888917449951173, "actor_target_entropy": -6.0, "actor_entropy": 5.691319240570069, "alpha_loss": 0.0005743780136108398, "alpha_value": 0.01270512986946304, "duration": 54.093443870544434, "step": 82000}
{"episode_reward": 93.91294481749459, "episode": 329.0, "batch_reward": 0.39981352591514585, "critic_loss": 5.292647869110107, "ae_transition_loss": 0.08211896878480911, "ae_encoder_loss": 0.34651393246650697, "actor_loss": -26.894570693969726, "actor_target_entropy": -6.0, "actor_entropy": 5.602090015411377, "alpha_loss": -0.0016264753094874323, "alpha_value": 0.012770855155617317, "duration": 54.78622055053711, "step": 82250}
{"episode_reward": 89.21726308532506, "episode": 330.0, "batch_reward": 0.40149657928943633, "critic_loss": 4.3156222667694095, "ae_transition_loss": 0.0772215305417776, "ae_encoder_loss": 0.3227482472062111, "actor_loss": -26.99710629272461, "actor_target_entropy": -6.0, "actor_entropy": 5.449263549804687, "alpha_loss": 0.0007072267243638634, "alpha_value": 0.012684837112961712, "duration": 54.49314761161804, "step": 82500}
{"episode_reward": 50.78252026822281, "episode": 331.0, "batch_reward": 0.40076329743862155, "critic_loss": 3.8738493971824646, "ae_transition_loss": 0.07304397052526473, "ae_encoder_loss": 0.3355897445678711, "actor_loss": -26.985557022094728, "actor_target_entropy": -6.0, "actor_entropy": 5.415061073303223, "alpha_loss": -0.0021364921065978705, "alpha_value": 0.012894677543960597, "duration": 69.76712775230408, "step": 82750}
{"episode_reward": 54.71572539742918, "episode": 332.0, "batch_reward": 0.40131863522529604, "critic_loss": 4.129524191856384, "ae_transition_loss": 0.07584277296066284, "ae_encoder_loss": 0.3457448999881744, "actor_loss": -26.94434226989746, "actor_target_entropy": -6.0, "actor_entropy": 5.561596050262451, "alpha_loss": 0.002569689699914306, "alpha_value": 0.01313210782992544, "duration": 54.7503776550293, "step": 83000}
{"episode_reward": 161.6295589687167, "episode": 333.0, "batch_reward": 0.4017980428934097, "critic_loss": 3.8803479690551756, "ae_transition_loss": 0.07500535655021667, "ae_encoder_loss": 0.3477542352080345, "actor_loss": -27.038956451416016, "actor_target_entropy": -6.0, "actor_entropy": 5.347087390899659, "alpha_loss": -0.0015610567359253763, "alpha_value": 0.01273626954440045, "duration": 54.73323202133179, "step": 83250}
{"episode_reward": 152.82060906704564, "episode": 334.0, "batch_reward": 0.402486474275589, "critic_loss": 4.344385615348816, "ae_transition_loss": 0.081755550339818, "ae_encoder_loss": 0.3479371474981308, "actor_loss": -27.25500425720215, "actor_target_entropy": -6.0, "actor_entropy": 5.392282207489013, "alpha_loss": 0.00015912425052374602, "alpha_value": 0.013036417087512681, "duration": 54.7741014957428, "step": 83500}
{"episode_reward": 164.67164193606985, "episode": 335.0, "batch_reward": 0.4027036919593811, "critic_loss": 3.788846779823303, "ae_transition_loss": 0.08389365792274475, "ae_encoder_loss": 0.35463047623634336, "actor_loss": -27.185347259521485, "actor_target_entropy": -6.0, "actor_entropy": 5.389221092224121, "alpha_loss": -0.002300074700266123, "alpha_value": 0.013246740431817446, "duration": 54.43534731864929, "step": 83750}
{"episode_reward": 188.38892316011518, "episode": 336.0, "batch_reward": 0.40456915950775146, "critic_loss": 4.046206883907318, "ae_transition_loss": 0.07999202601611614, "ae_encoder_loss": 0.3521141039729118, "actor_loss": -27.261701950073242, "actor_target_entropy": -6.0, "actor_entropy": 5.5227136840820314, "alpha_loss": -0.0004085935056209564, "alpha_value": 0.013676249958995162, "duration": 54.68906307220459, "step": 84000}
{"episode_reward": 85.23503323496698, "episode": 337.0, "batch_reward": 0.4045663720369339, "critic_loss": 4.188285848140716, "ae_transition_loss": 0.0830431008040905, "ae_encoder_loss": 0.3515773974657059, "actor_loss": -27.58773358154297, "actor_target_entropy": -6.0, "actor_entropy": 5.498864986419678, "alpha_loss": -0.0003501821947284043, "alpha_value": 0.013610555074697219, "duration": 54.71061730384827, "step": 84250}
{"episode_reward": 119.28437978445851, "episode": 338.0, "batch_reward": 0.4041921879053116, "critic_loss": 3.6333597230911256, "ae_transition_loss": 0.07692691516876221, "ae_encoder_loss": 0.36527926301956176, "actor_loss": -27.445292388916016, "actor_target_entropy": -6.0, "actor_entropy": 5.431832984924316, "alpha_loss": -0.0019489061040803791, "alpha_value": 0.013952637366165968, "duration": 54.647754192352295, "step": 84500}
{"episode_reward": 141.09607595847524, "episode": 339.0, "batch_reward": 0.40398458850383756, "critic_loss": 3.574960778236389, "ae_transition_loss": 0.07878901202976704, "ae_encoder_loss": 0.34828457635641097, "actor_loss": -27.625786895751954, "actor_target_entropy": -6.0, "actor_entropy": 5.417271347045898, "alpha_loss": 0.0003067871928215027, "alpha_value": 0.014263771539432535, "duration": 54.81955075263977, "step": 84750}
{"episode_reward": 165.6079209780135, "episode": 340.0, "batch_reward": 0.40517251861095427, "critic_loss": 4.095165253639221, "ae_transition_loss": 0.08738842488825321, "ae_encoder_loss": 0.36016025590896605, "actor_loss": -27.704827423095704, "actor_target_entropy": -6.0, "actor_entropy": 5.424306842803955, "alpha_loss": 0.0001162503776140511, "alpha_value": 0.014006066746275813, "duration": 54.48235058784485, "step": 85000}
{"episode_reward": 100.22907020442524, "episode": 341.0, "batch_reward": 0.40432684898376464, "critic_loss": 3.948407494068146, "ae_transition_loss": 0.08759085446596146, "ae_encoder_loss": 0.3646988589167595, "actor_loss": -27.731121444702147, "actor_target_entropy": -6.0, "actor_entropy": 5.571129962921143, "alpha_loss": -0.0004628114989027381, "alpha_value": 0.014301368295295174, "duration": 69.11235427856445, "step": 85250}
{"episode_reward": 146.6481403319813, "episode": 342.0, "batch_reward": 0.4061856347322464, "critic_loss": 4.176169803619385, "ae_transition_loss": 0.08633475276827812, "ae_encoder_loss": 0.3663261811733246, "actor_loss": -27.922707550048827, "actor_target_entropy": -6.0, "actor_entropy": 5.419287670135498, "alpha_loss": 0.0026464393218047916, "alpha_value": 0.01392732767253701, "duration": 54.41457414627075, "step": 85500}
{"episode_reward": 164.90242391560918, "episode": 343.0, "batch_reward": 0.40702500188350677, "critic_loss": 3.6361271314620973, "ae_transition_loss": 0.07768953321874142, "ae_encoder_loss": 0.359276721060276, "actor_loss": -27.920072174072267, "actor_target_entropy": -6.0, "actor_entropy": 5.365524272918702, "alpha_loss": -0.002101801668293774, "alpha_value": 0.014014583474997046, "duration": 54.71849465370178, "step": 85750}
{"episode_reward": 177.3245864154688, "episode": 344.0, "batch_reward": 0.40652260434627535, "critic_loss": 4.268887955665589, "ae_transition_loss": 0.09299908845126628, "ae_encoder_loss": 0.3612863430380821, "actor_loss": -28.1067470703125, "actor_target_entropy": -6.0, "actor_entropy": 5.492389957427979, "alpha_loss": 0.0008682140801101923, "alpha_value": 0.014093283432133435, "duration": 54.77301836013794, "step": 86000}
{"episode_reward": 121.2459727847242, "episode": 345.0, "batch_reward": 0.4062894244194031, "critic_loss": 3.844532190322876, "ae_transition_loss": 0.08697990839183331, "ae_encoder_loss": 0.3794338486790657, "actor_loss": -28.12715133666992, "actor_target_entropy": -6.0, "actor_entropy": 5.5283825492858885, "alpha_loss": 0.0008741962551139295, "alpha_value": 0.01363132189749443, "duration": 54.64789414405823, "step": 86250}
{"episode_reward": 51.07453204016267, "episode": 346.0, "batch_reward": 0.4074602775573731, "critic_loss": 3.4333130283355713, "ae_transition_loss": 0.07449740177392959, "ae_encoder_loss": 0.35482292699813844, "actor_loss": -28.268269729614257, "actor_target_entropy": -6.0, "actor_entropy": 5.449675457000732, "alpha_loss": 0.0008082906673662364, "alpha_value": 0.013430327517957212, "duration": 54.81147766113281, "step": 86500}
{"episode_reward": 87.2266710835718, "episode": 347.0, "batch_reward": 0.40611806297302244, "critic_loss": 3.675563561916351, "ae_transition_loss": 0.07873965106904507, "ae_encoder_loss": 0.34975298124551774, "actor_loss": -28.108791870117187, "actor_target_entropy": -6.0, "actor_entropy": 5.483029857635498, "alpha_loss": 6.103509245440364e-05, "alpha_value": 0.013690018920412618, "duration": 54.527482748031616, "step": 86750}
{"episode_reward": 144.07774797872963, "episode": 348.0, "batch_reward": 0.40606177723407744, "critic_loss": 3.8637604146003723, "ae_transition_loss": 0.07956558607518673, "ae_encoder_loss": 0.3558545600771904, "actor_loss": -28.244531875610353, "actor_target_entropy": -6.0, "actor_entropy": 5.59806579208374, "alpha_loss": 0.0007980330646969378, "alpha_value": 0.01313191099624571, "duration": 54.6505184173584, "step": 87000}
{"episode_reward": 80.24692230443105, "episode": 349.0, "batch_reward": 0.4076722563505173, "critic_loss": 3.8763430857658387, "ae_transition_loss": 0.08638914370536804, "ae_encoder_loss": 0.36042631417512894, "actor_loss": -28.53085171508789, "actor_target_entropy": -6.0, "actor_entropy": 5.366072620391845, "alpha_loss": -0.00032255123602226377, "alpha_value": 0.013066776738157771, "duration": 54.669179916381836, "step": 87250}
{"episode_reward": 183.12857265994325, "episode": 350.0, "batch_reward": 0.4074976624250412, "critic_loss": 5.332907181739807, "ae_transition_loss": 0.11093841403722764, "ae_encoder_loss": 0.38426173174381256, "actor_loss": -28.445014312744142, "actor_target_entropy": -6.0, "actor_entropy": 5.5964608535766605, "alpha_loss": 9.33502921834588e-05, "alpha_value": 0.013244493853784482, "duration": 54.762070417404175, "step": 87500}
{"episode_reward": 182.76150121820473, "episode": 351.0, "batch_reward": 0.408436181306839, "critic_loss": 4.100111993789673, "ae_transition_loss": 0.08486163899302483, "ae_encoder_loss": 0.3493386665582657, "actor_loss": -28.409254013061524, "actor_target_entropy": -6.0, "actor_entropy": 5.535945827484131, "alpha_loss": 0.0009522089378442615, "alpha_value": 0.01308465443563706, "duration": 69.41309905052185, "step": 87750}
{"episode_reward": 109.04741029726047, "episode": 352.0, "batch_reward": 0.4092026333808899, "critic_loss": 3.1829388093948365, "ae_transition_loss": 0.07352972804009915, "ae_encoder_loss": 0.3389230190515518, "actor_loss": -28.6714493560791, "actor_target_entropy": -6.0, "actor_entropy": 5.418313179016113, "alpha_loss": -0.0028156214905902745, "alpha_value": 0.013415428626728825, "duration": 54.57849907875061, "step": 88000}
{"episode_reward": 85.07046937886369, "episode": 353.0, "batch_reward": 0.4075459189414978, "critic_loss": 2.8982846450805666, "ae_transition_loss": 0.06549540629982949, "ae_encoder_loss": 0.3381112642288208, "actor_loss": -28.71545231628418, "actor_target_entropy": -6.0, "actor_entropy": 5.334802864074707, "alpha_loss": -0.0021758470525965095, "alpha_value": 0.013964536410920419, "duration": 54.843165159225464, "step": 88250}
{"episode_reward": 174.92143621166483, "episode": 354.0, "batch_reward": 0.4087728348970413, "critic_loss": 3.2518609561920164, "ae_transition_loss": 0.08024697852134705, "ae_encoder_loss": 0.3671609113812447, "actor_loss": -28.862712890625, "actor_target_entropy": -6.0, "actor_entropy": 5.446952556610108, "alpha_loss": 0.0022206675983034076, "alpha_value": 0.014164323619424357, "duration": 54.521196126937866, "step": 88500}
{"episode_reward": 70.78341003353516, "episode": 355.0, "batch_reward": 0.40724547338485717, "critic_loss": 3.420730854511261, "ae_transition_loss": 0.0778761287331581, "ae_encoder_loss": 0.3480175337791443, "actor_loss": -28.763323013305666, "actor_target_entropy": -6.0, "actor_entropy": 5.519320625305176, "alpha_loss": -0.0015524152144789697, "alpha_value": 0.013894804548070733, "duration": 54.85868263244629, "step": 88750}
{"episode_reward": 156.4776739214917, "episode": 356.0, "batch_reward": 0.40922311413288115, "critic_loss": 3.925345325946808, "ae_transition_loss": 0.08929584704339505, "ae_encoder_loss": 0.36490772968530655, "actor_loss": -28.958739639282225, "actor_target_entropy": -6.0, "actor_entropy": 5.539849006652832, "alpha_loss": 0.0024814752354286613, "alpha_value": 0.013919370662600579, "duration": 54.91476535797119, "step": 89000}
{"episode_reward": 203.54250524802572, "episode": 357.0, "batch_reward": 0.41076289665699006, "critic_loss": 3.4928694057464598, "ae_transition_loss": 0.07917919500172138, "ae_encoder_loss": 0.3444163221716881, "actor_loss": -29.1576965637207, "actor_target_entropy": -6.0, "actor_entropy": 5.422739379882812, "alpha_loss": -0.00077434018580243, "alpha_value": 0.013782156845656462, "duration": 54.723978996276855, "step": 89250}
{"episode_reward": 160.67726340838362, "episode": 358.0, "batch_reward": 0.41313422334194183, "critic_loss": 3.9481410541534423, "ae_transition_loss": 0.0911563335955143, "ae_encoder_loss": 0.365089349091053, "actor_loss": -29.2458943939209, "actor_target_entropy": -6.0, "actor_entropy": 5.443492237091064, "alpha_loss": -0.00026445185975171624, "alpha_value": 0.01391752930246236, "duration": 54.85891056060791, "step": 89500}
{"episode_reward": 192.0463838635949, "episode": 359.0, "batch_reward": 0.4120336699485779, "critic_loss": 5.044672821044922, "ae_transition_loss": 0.11145688226819038, "ae_encoder_loss": 0.3708919660449028, "actor_loss": -29.225571563720703, "actor_target_entropy": -6.0, "actor_entropy": 5.6041171226501465, "alpha_loss": 0.0002176779741421342, "alpha_value": 0.013716749345277262, "duration": 54.58765482902527, "step": 89750}
{"episode_reward": 119.02249648788121, "episode": 360.0, "batch_reward": 0.41144961643218997, "critic_loss": 3.6479666385650633, "ae_transition_loss": 0.08533314535021783, "ae_encoder_loss": 0.35478258967399595, "actor_loss": -29.312693893432616, "actor_target_entropy": -6.0, "actor_entropy": 5.517048690795899, "alpha_loss": -0.0015239521290641277, "alpha_value": 0.014062757676035837, "duration": 54.83889031410217, "step": 90000}
{"episode_reward": 101.7505647541386, "episode": 361.0, "batch_reward": 0.41329360675811766, "critic_loss": 3.2148129420280456, "ae_transition_loss": 0.07924977363646031, "ae_encoder_loss": 0.3636488614678383, "actor_loss": -29.473371307373046, "actor_target_entropy": -6.0, "actor_entropy": 5.544206619262695, "alpha_loss": 0.0006047391868196427, "alpha_value": 0.014132689209520514, "duration": 77.6983208656311, "step": 90250}
{"episode_reward": 109.69292365019533, "episode": 362.0, "batch_reward": 0.41104686176776883, "critic_loss": 3.322573932170868, "ae_transition_loss": 0.07756458695232868, "ae_encoder_loss": 0.3747922399044037, "actor_loss": -29.52294436645508, "actor_target_entropy": -6.0, "actor_entropy": 5.456094783782959, "alpha_loss": -0.0028472608826123178, "alpha_value": 0.014379781914750506, "duration": 55.00233840942383, "step": 90500}
{"episode_reward": 176.4602820093581, "episode": 363.0, "batch_reward": 0.4139348928928375, "critic_loss": 3.193796371459961, "ae_transition_loss": 0.07625417345762253, "ae_encoder_loss": 0.365833249270916, "actor_loss": -29.59067887878418, "actor_target_entropy": -6.0, "actor_entropy": 5.559387420654297, "alpha_loss": 0.00019594958378002048, "alpha_value": 0.014870897746155102, "duration": 54.8559250831604, "step": 90750}
{"episode_reward": 196.13151505144555, "episode": 364.0, "batch_reward": 0.41410944700241087, "critic_loss": 3.349893151760101, "ae_transition_loss": 0.07936860847473144, "ae_encoder_loss": 0.36289931219816207, "actor_loss": -29.741467468261717, "actor_target_entropy": -6.0, "actor_entropy": 5.634562023162842, "alpha_loss": 0.0011042819251306354, "alpha_value": 0.014641664018660185, "duration": 54.585275650024414, "step": 91000}
{"episode_reward": 83.1869564121455, "episode": 365.0, "batch_reward": 0.4151141591072082, "critic_loss": 3.4508927230834963, "ae_transition_loss": 0.08505758692324161, "ae_encoder_loss": 0.36079874593019484, "actor_loss": -29.844116470336914, "actor_target_entropy": -6.0, "actor_entropy": 5.577611801147461, "alpha_loss": 0.00039976471452973783, "alpha_value": 0.01447927602138897, "duration": 54.77240753173828, "step": 91250}
{"episode_reward": 184.57302780066402, "episode": 366.0, "batch_reward": 0.4158311916589737, "critic_loss": 5.387301886558533, "ae_transition_loss": 0.11681661033630371, "ae_encoder_loss": 0.3715225264430046, "actor_loss": -29.791574203491212, "actor_target_entropy": -6.0, "actor_entropy": 5.65486962890625, "alpha_loss": 0.002615139982663095, "alpha_value": 0.014251087788030267, "duration": 54.50577235221863, "step": 91500}
{"episode_reward": 175.4948278059509, "episode": 367.0, "batch_reward": 0.415435870885849, "critic_loss": 3.899070103645325, "ae_transition_loss": 0.09155268073081971, "ae_encoder_loss": 0.3622387640476227, "actor_loss": -29.959981475830077, "actor_target_entropy": -6.0, "actor_entropy": 5.5356169586181645, "alpha_loss": 0.00033752615726552904, "alpha_value": 0.013118360182146438, "duration": 55.01874756813049, "step": 91750}
{"episode_reward": 166.93066619106185, "episode": 368.0, "batch_reward": 0.4176344941854477, "critic_loss": 3.2432435140609743, "ae_transition_loss": 0.07701859495043754, "ae_encoder_loss": 0.364759360730648, "actor_loss": -30.201936218261718, "actor_target_entropy": -6.0, "actor_entropy": 5.444179405212402, "alpha_loss": -0.0006207920792512595, "alpha_value": 0.013584694090103145, "duration": 54.96420359611511, "step": 92000}
{"episode_reward": 221.82718528960044, "episode": 369.0, "batch_reward": 0.4188064856529236, "critic_loss": 3.066110213279724, "ae_transition_loss": 0.07353440411388874, "ae_encoder_loss": 0.35891465210914614, "actor_loss": -30.226187301635743, "actor_target_entropy": -6.0, "actor_entropy": 5.508998947143555, "alpha_loss": -0.0018277929648756982, "alpha_value": 0.013750353125939556, "duration": 54.67708468437195, "step": 92250}
{"episode_reward": 95.23693119885918, "episode": 370.0, "batch_reward": 0.4166937038898468, "critic_loss": 2.9744509983062746, "ae_transition_loss": 0.07641465279459954, "ae_encoder_loss": 0.34864957171678546, "actor_loss": -30.1789326171875, "actor_target_entropy": -6.0, "actor_entropy": 5.5620979423522945, "alpha_loss": 0.001056429954012856, "alpha_value": 0.014083446531365609, "duration": 55.1503484249115, "step": 92500}
{"episode_reward": 99.55006403492094, "episode": 371.0, "batch_reward": 0.41882634139060976, "critic_loss": 3.0662035059928896, "ae_transition_loss": 0.07442069368064404, "ae_encoder_loss": 0.35287342804670335, "actor_loss": -30.349451934814454, "actor_target_entropy": -6.0, "actor_entropy": 5.49799577331543, "alpha_loss": -0.002151643908582628, "alpha_value": 0.013790855005582, "duration": 69.83937287330627, "step": 92750}
{"episode_reward": 110.99695642027667, "episode": 372.0, "batch_reward": 0.4183309415578842, "critic_loss": 3.0970712447166444, "ae_transition_loss": 0.07897696629166603, "ae_encoder_loss": 0.34476821225881576, "actor_loss": -30.51101254272461, "actor_target_entropy": -6.0, "actor_entropy": 5.518011539459229, "alpha_loss": 0.0018450286285951734, "alpha_value": 0.01445433228191955, "duration": 54.87693548202515, "step": 93000}
{"episode_reward": 153.7922596637053, "episode": 373.0, "batch_reward": 0.41877690207958224, "critic_loss": 3.344302411556244, "ae_transition_loss": 0.0835818188637495, "ae_encoder_loss": 0.3648594724535942, "actor_loss": -30.45678503417969, "actor_target_entropy": -6.0, "actor_entropy": 5.522877941131592, "alpha_loss": -0.0013253575954586267, "alpha_value": 0.014198251687079336, "duration": 54.93588209152222, "step": 93250}
{"episode_reward": 97.9131518040876, "episode": 374.0, "batch_reward": 0.4189015619754791, "critic_loss": 3.79311888217926, "ae_transition_loss": 0.08384148037433624, "ae_encoder_loss": 0.35947848272323607, "actor_loss": -30.500880386352538, "actor_target_entropy": -6.0, "actor_entropy": 5.616942378997803, "alpha_loss": 0.001481282576918602, "alpha_value": 0.014209515309645194, "duration": 54.78082513809204, "step": 93500}
{"episode_reward": 181.42734077975376, "episode": 375.0, "batch_reward": 0.42037036728858945, "critic_loss": 3.465428409576416, "ae_transition_loss": 0.08730415213108063, "ae_encoder_loss": 0.3747521021962166, "actor_loss": -30.672828170776366, "actor_target_entropy": -6.0, "actor_entropy": 5.605290370941162, "alpha_loss": 0.0009409054215066135, "alpha_value": 0.013699391628105824, "duration": 55.464075565338135, "step": 93750}
{"episode_reward": 234.79190153068006, "episode": 376.0, "batch_reward": 0.41963075280189516, "critic_loss": 4.895789347648621, "ae_transition_loss": 0.11306488567590714, "ae_encoder_loss": 0.3725593091845512, "actor_loss": -30.716417846679686, "actor_target_entropy": -6.0, "actor_entropy": 5.5795019874572755, "alpha_loss": 0.0014124451018869876, "alpha_value": 0.013406719088827589, "duration": 54.58377718925476, "step": 94000}
{"episode_reward": 206.88124611507115, "episode": 377.0, "batch_reward": 0.4210322777032852, "critic_loss": 3.668694880962372, "ae_transition_loss": 0.08714464223384857, "ae_encoder_loss": 0.37649833393096926, "actor_loss": -30.931627563476564, "actor_target_entropy": -6.0, "actor_entropy": 5.567806213378907, "alpha_loss": 7.97661622054875e-05, "alpha_value": 0.012992133327091976, "duration": 54.97667407989502, "step": 94250}
{"episode_reward": 176.97230901456732, "episode": 378.0, "batch_reward": 0.4219851777553558, "critic_loss": 3.4229803051948546, "ae_transition_loss": 0.08626250696182251, "ae_encoder_loss": 0.37149461954832075, "actor_loss": -30.972759490966798, "actor_target_entropy": -6.0, "actor_entropy": 5.477135208129883, "alpha_loss": 0.0005154089448042214, "alpha_value": 0.01309981286540646, "duration": 54.84091663360596, "step": 94500}
{"episode_reward": 72.08875814645378, "episode": 379.0, "batch_reward": 0.42043727719783786, "critic_loss": 2.6872224292755127, "ae_transition_loss": 0.07137472411990166, "ae_encoder_loss": 0.35361920404434205, "actor_loss": -31.116777557373048, "actor_target_entropy": -6.0, "actor_entropy": 5.445044960021972, "alpha_loss": -0.004115937399212271, "alpha_value": 0.013488006840465321, "duration": 54.93919920921326, "step": 94750}
{"episode_reward": 95.52001244884116, "episode": 380.0, "batch_reward": 0.4203347412347794, "critic_loss": 2.7808620371818544, "ae_transition_loss": 0.07476292812824249, "ae_encoder_loss": 0.37161480367183686, "actor_loss": -31.14141662597656, "actor_target_entropy": -6.0, "actor_entropy": 5.452728343963623, "alpha_loss": -6.611191388219594e-05, "alpha_value": 0.01432418226284776, "duration": 54.935178995132446, "step": 95000}
{"episode_reward": 163.86473235678935, "episode": 381.0, "batch_reward": 0.4223482064008713, "critic_loss": 3.7562519516944883, "ae_transition_loss": 0.08851842388510704, "ae_encoder_loss": 0.3943969616293907, "actor_loss": -31.13834521484375, "actor_target_entropy": -6.0, "actor_entropy": 5.4812314987182615, "alpha_loss": 0.0004900985197164118, "alpha_value": 0.014096993888187128, "duration": 69.80346345901489, "step": 95250}
{"episode_reward": 230.74929688583651, "episode": 382.0, "batch_reward": 0.42359315884113313, "critic_loss": 3.935904929161072, "ae_transition_loss": 0.09630023956298828, "ae_encoder_loss": 0.38298679363727567, "actor_loss": -31.37099819946289, "actor_target_entropy": -6.0, "actor_entropy": 5.612871917724609, "alpha_loss": 0.002726449752692133, "alpha_value": 0.014098576356643862, "duration": 54.8910653591156, "step": 95500}
{"episode_reward": 197.6171769459336, "episode": 383.0, "batch_reward": 0.4259185130596161, "critic_loss": 3.781467941761017, "ae_transition_loss": 0.0957584472000599, "ae_encoder_loss": 0.3805961230993271, "actor_loss": -31.48604850769043, "actor_target_entropy": -6.0, "actor_entropy": 5.497173385620117, "alpha_loss": -0.0006757125875446945, "alpha_value": 0.013461578316243198, "duration": 54.653335094451904, "step": 95750}
{"episode_reward": 129.42965158790827, "episode": 384.0, "batch_reward": 0.4239050158262253, "critic_loss": 3.441662428379059, "ae_transition_loss": 0.08875852127373218, "ae_encoder_loss": 0.36788229894638064, "actor_loss": -31.400406692504884, "actor_target_entropy": -6.0, "actor_entropy": 5.449827434539795, "alpha_loss": -0.00031745187588967384, "alpha_value": 0.013449444382178845, "duration": 54.92398762702942, "step": 96000}
{"episode_reward": 175.2957664242156, "episode": 385.0, "batch_reward": 0.4257804552316666, "critic_loss": 3.5350171027183532, "ae_transition_loss": 0.0872473457455635, "ae_encoder_loss": 0.37173666346073153, "actor_loss": -31.69934927368164, "actor_target_entropy": -6.0, "actor_entropy": 5.361556140899658, "alpha_loss": -0.0010161483176052571, "alpha_value": 0.013807696866831986, "duration": 55.12934136390686, "step": 96250}
{"episode_reward": 126.92943073818638, "episode": 386.0, "batch_reward": 0.4276990007162094, "critic_loss": 3.498510061740875, "ae_transition_loss": 0.0885180186033249, "ae_encoder_loss": 0.38993524050712586, "actor_loss": -31.842889266967774, "actor_target_entropy": -6.0, "actor_entropy": 5.390423141479492, "alpha_loss": 0.001053977045463398, "alpha_value": 0.013893164297438042, "duration": 54.78251242637634, "step": 96500}
