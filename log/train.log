{"episode_reward": 0.0, "episode": 1.0, "duration": 15.753117084503174, "step": 250}
{"episode_reward": 7.747346039045906, "episode": 2.0, "duration": 0.4079434871673584, "step": 500}
{"episode_reward": 4.427573337125385, "episode": 3.0, "duration": 0.4041907787322998, "step": 750}
{"episode_reward": 5.050386443524035, "episode": 4.0, "duration": 0.40168213844299316, "step": 1000}
{"episode_reward": 17.85499204884596, "episode": 5.0, "batch_reward": 0.03667764478266907, "critic_loss": 0.007112211942336439, "ae_transition_loss": 0.01347498869710006, "ae_encoder_loss": 0.0011477810491587232, "actor_loss": -0.25283544806074154, "actor_target_entropy": -6.0, "actor_entropy": 6.606560141060276, "alpha_loss": 0.055336541903878024, "alpha_value": 0.006473673399626257, "duration": 280.7280662059784, "step": 1250}
{"episode_reward": 36.361718052391886, "episode": 6.0, "batch_reward": 0.057066518515348434, "critic_loss": 0.004506766051985324, "ae_transition_loss": 0.0053713540378957985, "ae_encoder_loss": 0.0038331199088133872, "actor_loss": -0.5988105535507202, "actor_target_entropy": -6.0, "actor_entropy": 5.465816326141358, "alpha_loss": 0.017099654980003834, "alpha_value": 0.004288192398162833, "duration": 53.73260712623596, "step": 1500}
{"episode_reward": 12.103572672449944, "episode": 7.0, "batch_reward": 0.0548511244058609, "critic_loss": 0.007338777365162969, "ae_transition_loss": 0.005092074603773654, "ae_encoder_loss": 0.0037709073345176874, "actor_loss": -0.7499071478843689, "actor_target_entropy": -6.0, "actor_entropy": 5.079712242126464, "alpha_loss": 0.006480793446302414, "alpha_value": 0.004153390845057005, "duration": 53.80183744430542, "step": 1750}
{"episode_reward": 8.049809982603263, "episode": 8.0, "batch_reward": 0.05118308426439762, "critic_loss": 0.0060886133164167406, "ae_transition_loss": 0.00373733495734632, "ae_encoder_loss": 0.003228741426952183, "actor_loss": -0.9025124917030335, "actor_target_entropy": -6.0, "actor_entropy": 4.778775394439697, "alpha_loss": 0.0016377727595972829, "alpha_value": 0.004105517123994209, "duration": 53.63447189331055, "step": 2000}
{"episode_reward": 8.180115699368011, "episode": 9.0, "batch_reward": 0.050052242055535316, "critic_loss": 0.007943728391081095, "ae_transition_loss": 0.0036302119987085464, "ae_encoder_loss": 0.0031492308005690575, "actor_loss": -1.0099390759468079, "actor_target_entropy": -6.0, "actor_entropy": 4.7356962356567385, "alpha_loss": -9.440093470038846e-05, "alpha_value": 0.004099259553197046, "duration": 53.66443681716919, "step": 2250}
{"episode_reward": 13.974420732916272, "episode": 10.0, "batch_reward": 0.051373062148690224, "critic_loss": 0.00818083612807095, "ae_transition_loss": 0.003635290184058249, "ae_encoder_loss": 0.0032768205022439363, "actor_loss": -1.0434193425178528, "actor_target_entropy": -6.0, "actor_entropy": 4.8005157051086425, "alpha_loss": -2.9563425690867008e-05, "alpha_value": 0.0041021359640326435, "duration": 53.658507347106934, "step": 2500}
