{"episode_reward": 0.0, "episode": 1.0, "duration": 17.484803676605225, "step": 250}
{"episode_reward": 7.747346039045906, "episode": 2.0, "duration": 0.39574432373046875, "step": 500}
{"episode_reward": 4.427573337125385, "episode": 3.0, "duration": 0.39548420906066895, "step": 750}
{"episode_reward": 5.050386443524035, "episode": 4.0, "duration": 0.3925132751464844, "step": 1000}
{"episode_reward": 17.85499204884596, "episode": 5.0, "batch_reward": 0.035218364555385705, "critic_loss": 0.0055195010808543315, "ae_transition_loss": 0.01200100388446878, "ae_encoder_loss": 0.001153606450961313, "actor_loss": -0.3034212312566239, "actor_target_entropy": -6.0, "actor_entropy": 6.686850127164155, "alpha_loss": 0.05611677293738622, "alpha_value": 0.006459763811327144, "duration": 281.6975471973419, "step": 1250}
{"episode_reward": 8.790688490998988, "episode": 6.0, "batch_reward": 0.03560465674102306, "critic_loss": 0.0021155956122092903, "ae_transition_loss": 0.0026354046482592822, "ae_encoder_loss": 0.001256257683970034, "actor_loss": -0.5210183901786805, "actor_target_entropy": -6.0, "actor_entropy": 5.987891349792481, "alpha_loss": 0.0230215834826231, "alpha_value": 0.004216196926697524, "duration": 53.99118900299072, "step": 1500}
{"episode_reward": 11.212621557615899, "episode": 7.0, "batch_reward": 0.03769860279560089, "critic_loss": 0.0028113791537471115, "ae_transition_loss": 0.002603119739331305, "ae_encoder_loss": 0.0011515166743192823, "actor_loss": -0.5571295740604401, "actor_target_entropy": -6.0, "actor_entropy": 5.850781478881836, "alpha_loss": 0.02170658603310585, "alpha_value": 0.003986571533414987, "duration": 54.001981258392334, "step": 1750}
{"episode_reward": 12.629649016243528, "episode": 8.0, "batch_reward": 0.040881294697523114, "critic_loss": 0.0034030665778554976, "ae_transition_loss": 0.0024630949012935163, "ae_encoder_loss": 0.0011383692529052497, "actor_loss": -0.6150526552200317, "actor_target_entropy": -6.0, "actor_entropy": 5.788178749084473, "alpha_loss": 0.018841556258499623, "alpha_value": 0.0037759302008624263, "duration": 54.00482201576233, "step": 2000}
{"episode_reward": 18.573057379519735, "episode": 9.0, "batch_reward": 0.044427966102957725, "critic_loss": 0.003928542914800346, "ae_transition_loss": 0.002557619844097644, "ae_encoder_loss": 0.0011206541683059185, "actor_loss": -0.6832367467880249, "actor_target_entropy": -6.0, "actor_entropy": 5.730913051605224, "alpha_loss": 0.015328165538609028, "alpha_value": 0.0035886803541350667, "duration": 54.01069927215576, "step": 2250}
{"episode_reward": 15.558386892360323, "episode": 10.0, "batch_reward": 0.04806071090698242, "critic_loss": 0.003462537864688784, "ae_transition_loss": 0.0021172935366630553, "ae_encoder_loss": 0.0011455509497318417, "actor_loss": -0.7254266204833985, "actor_target_entropy": -6.0, "actor_entropy": 5.423987297058106, "alpha_loss": 0.010786903146654368, "alpha_value": 0.0034494593395896543, "duration": 53.989195823669434, "step": 2500}
{"episode_reward": 25.634214916626167, "episode": 11.0, "batch_reward": 0.05055287316441536, "critic_loss": 0.00332153203105554, "ae_transition_loss": 0.002312013971619308, "ae_encoder_loss": 0.0014231043641921132, "actor_loss": -0.7741705398559571, "actor_target_entropy": -6.0, "actor_entropy": 5.158658710479736, "alpha_loss": 0.007870136726647615, "alpha_value": 0.0033412899454990552, "duration": 70.35381746292114, "step": 2750}
{"episode_reward": 9.401913574135317, "episode": 12.0, "batch_reward": 0.05223227606713772, "critic_loss": 0.005424144067801535, "ae_transition_loss": 0.0028675079410895705, "ae_encoder_loss": 0.0016781640131957828, "actor_loss": -0.8301381363868713, "actor_target_entropy": -6.0, "actor_entropy": 5.1856584548950195, "alpha_loss": 0.005357362083625049, "alpha_value": 0.0032627018192572604, "duration": 54.01132416725159, "step": 3000}
{"episode_reward": 24.98348111575763, "episode": 13.0, "batch_reward": 0.05641949619352817, "critic_loss": 0.007227263229899109, "ae_transition_loss": 0.0027997557707130907, "ae_encoder_loss": 0.0018520798850804568, "actor_loss": -0.9198047652244568, "actor_target_entropy": -6.0, "actor_entropy": 4.7877076148986815, "alpha_loss": 0.0032678881550673397, "alpha_value": 0.003210245806617187, "duration": 54.01214647293091, "step": 3250}
{"episode_reward": 33.6042715701375, "episode": 14.0, "batch_reward": 0.06690858493745327, "critic_loss": 0.007605363309383393, "ae_transition_loss": 0.0034945777766406537, "ae_encoder_loss": 0.0032379162847064437, "actor_loss": -0.9924623160362244, "actor_target_entropy": -6.0, "actor_entropy": 4.675415216445923, "alpha_loss": 0.0011084632235579192, "alpha_value": 0.003178606785293141, "duration": 54.00526142120361, "step": 3500}
{"episode_reward": 48.213626822204, "episode": 15.0, "batch_reward": 0.0702226942628622, "critic_loss": 0.010457372229546309, "ae_transition_loss": 0.00403202778287232, "ae_encoder_loss": 0.0038552783150225876, "actor_loss": -1.0981103043556213, "actor_target_entropy": -6.0, "actor_entropy": 4.5284411277771, "alpha_loss": -0.0005198778494959697, "alpha_value": 0.0031742459026168966, "duration": 53.996530294418335, "step": 3750}
{"episode_reward": 18.53142732744807, "episode": 16.0, "batch_reward": 0.07395179812610149, "critic_loss": 0.010727522145956755, "ae_transition_loss": 0.004333788251504302, "ae_encoder_loss": 0.004510064785368741, "actor_loss": -1.1951063556671142, "actor_target_entropy": -6.0, "actor_entropy": 4.505529077529907, "alpha_loss": -0.0006312624835118185, "alpha_value": 0.003184333490336423, "duration": 54.01176619529724, "step": 4000}
{"episode_reward": 41.94365971810698, "episode": 17.0, "batch_reward": 0.08057763320207596, "critic_loss": 0.012670305030420423, "ae_transition_loss": 0.004969026362523436, "ae_encoder_loss": 0.005575859201140702, "actor_loss": -1.2990057764053344, "actor_target_entropy": -6.0, "actor_entropy": 4.69553653717041, "alpha_loss": -0.00012348345306236296, "alpha_value": 0.00319207736824405, "duration": 53.996265172958374, "step": 4250}
{"episode_reward": 45.70992730057786, "episode": 18.0, "batch_reward": 0.08516232341527939, "critic_loss": 0.01279857267253101, "ae_transition_loss": 0.005308927118778229, "ae_encoder_loss": 0.00631336635351181, "actor_loss": -1.3916044807434083, "actor_target_entropy": -6.0, "actor_entropy": 4.587702960968017, "alpha_loss": -0.00038124702987261114, "alpha_value": 0.003193319173613804, "duration": 54.005706548690796, "step": 4500}
{"episode_reward": 50.398280484218716, "episode": 19.0, "batch_reward": 0.0920332229435444, "critic_loss": 0.015205971682444214, "ae_transition_loss": 0.005281511630862951, "ae_encoder_loss": 0.006724231146275997, "actor_loss": -1.501747184753418, "actor_target_entropy": -6.0, "actor_entropy": 4.507219512939453, "alpha_loss": -0.0011392263905145228, "alpha_value": 0.0032084885724174656, "duration": 54.01348614692688, "step": 4750}
{"episode_reward": 43.126049544485944, "episode": 20.0, "batch_reward": 0.0940156407058239, "critic_loss": 0.014416750606149435, "ae_transition_loss": 0.005211802000179887, "ae_encoder_loss": 0.006889178086072207, "actor_loss": -1.6055636768341064, "actor_target_entropy": -6.0, "actor_entropy": 4.52906205368042, "alpha_loss": -0.00043279492610599844, "alpha_value": 0.003221844979823301, "duration": 54.00915002822876, "step": 5000}
{"episode_reward": 22.95524635046068, "episode": 21.0, "batch_reward": 0.0955980674624443, "critic_loss": 0.01697508927807212, "ae_transition_loss": 0.005505755288526416, "ae_encoder_loss": 0.007195413054898381, "actor_loss": -1.7098281393051147, "actor_target_entropy": -6.0, "actor_entropy": 4.552748727798462, "alpha_loss": -0.0003861553714959882, "alpha_value": 0.0032314187579069492, "duration": 70.26022291183472, "step": 5250}
{"episode_reward": 47.46282718691441, "episode": 22.0, "batch_reward": 0.09899154251813888, "critic_loss": 0.014616847164928913, "ae_transition_loss": 0.005539009727537632, "ae_encoder_loss": 0.007394563388079405, "actor_loss": -1.81714604473114, "actor_target_entropy": -6.0, "actor_entropy": 4.514547443389892, "alpha_loss": -0.0020414398175198586, "alpha_value": 0.0032545699278122447, "duration": 53.98952913284302, "step": 5500}
{"episode_reward": 23.650806228621548, "episode": 23.0, "batch_reward": 0.09689628353714944, "critic_loss": 0.014145902827382088, "ae_transition_loss": 0.005337986044585705, "ae_encoder_loss": 0.007485824590548873, "actor_loss": -1.90936199760437, "actor_target_entropy": -6.0, "actor_entropy": 4.4035980472564695, "alpha_loss": -0.0029911373027134685, "alpha_value": 0.0033163611242599013, "duration": 53.98424410820007, "step": 5750}
{"episode_reward": 26.13518946661038, "episode": 24.0, "batch_reward": 0.09802811896800995, "critic_loss": 0.01793702071160078, "ae_transition_loss": 0.005732748243957758, "ae_encoder_loss": 0.00818073783442378, "actor_loss": -2.016283882141113, "actor_target_entropy": -6.0, "actor_entropy": 4.440733266830445, "alpha_loss": -0.0031108186416095125, "alpha_value": 0.0033980401528129044, "duration": 53.995237588882446, "step": 6000}
{"episode_reward": 19.382558348870518, "episode": 25.0, "batch_reward": 0.09856912431120872, "critic_loss": 0.019327085684984924, "ae_transition_loss": 0.0057333598677068946, "ae_encoder_loss": 0.008445374021306634, "actor_loss": -2.1248840408325194, "actor_target_entropy": -6.0, "actor_entropy": 4.543739189147949, "alpha_loss": -0.003420572740258649, "alpha_value": 0.00349179490507573, "duration": 54.00463676452637, "step": 6250}
{"episode_reward": 45.428457727498056, "episode": 26.0, "batch_reward": 0.10378499755263329, "critic_loss": 0.024527924615889787, "ae_transition_loss": 0.006240217782557011, "ae_encoder_loss": 0.009525180844590067, "actor_loss": -2.240860679626465, "actor_target_entropy": -6.0, "actor_entropy": 4.791157859802246, "alpha_loss": -0.0035544297765009105, "alpha_value": 0.0035994518003780165, "duration": 53.99454402923584, "step": 6500}
{"episode_reward": 61.52012050455558, "episode": 27.0, "batch_reward": 0.10835318776965142, "critic_loss": 0.019003472965210676, "ae_transition_loss": 0.005776837296783924, "ae_encoder_loss": 0.009650046763941645, "actor_loss": -2.335669261932373, "actor_target_entropy": -6.0, "actor_entropy": 4.903733455657959, "alpha_loss": -0.0036491288982797416, "alpha_value": 0.003729116370415686, "duration": 54.004305362701416, "step": 6750}
{"episode_reward": 36.902169929569574, "episode": 28.0, "batch_reward": 0.11002254235744477, "critic_loss": 0.022032118517905475, "ae_transition_loss": 0.00561143740825355, "ae_encoder_loss": 0.00980076152831316, "actor_loss": -2.435233142852783, "actor_target_entropy": -6.0, "actor_entropy": 4.908271125793457, "alpha_loss": -0.0032329048563260587, "alpha_value": 0.0038625339622720195, "duration": 53.991857290267944, "step": 7000}
{"episode_reward": 39.03174015072624, "episode": 29.0, "batch_reward": 0.10928719761967659, "critic_loss": 0.02567528159171343, "ae_transition_loss": 0.005973125355318189, "ae_encoder_loss": 0.010281578212976455, "actor_loss": -2.533732738494873, "actor_target_entropy": -6.0, "actor_entropy": 4.972252635955811, "alpha_loss": -0.0027675395259284413, "alpha_value": 0.003980427425012918, "duration": 53.99436974525452, "step": 7250}
{"episode_reward": 24.22927889526457, "episode": 30.0, "batch_reward": 0.11015327933430671, "critic_loss": 0.026710364304482936, "ae_transition_loss": 0.0058914058785885575, "ae_encoder_loss": 0.010589395880699157, "actor_loss": -2.620553606033325, "actor_target_entropy": -6.0, "actor_entropy": 5.057432601928711, "alpha_loss": -0.0029785987052600832, "alpha_value": 0.004122554156189532, "duration": 53.998252153396606, "step": 7500}
{"episode_reward": 47.588753505402, "episode": 31.0, "batch_reward": 0.11177939903736114, "critic_loss": 0.02596749970316887, "ae_transition_loss": 0.005667032547295094, "ae_encoder_loss": 0.010727718479931354, "actor_loss": -2.707900228500366, "actor_target_entropy": -6.0, "actor_entropy": 5.09827001953125, "alpha_loss": -0.0021429730695672333, "alpha_value": 0.004247303399972245, "duration": 70.27224683761597, "step": 7750}
{"episode_reward": 16.7581128929036, "episode": 32.0, "batch_reward": 0.1106758486032486, "critic_loss": 0.02966999316960573, "ae_transition_loss": 0.005692257346585393, "ae_encoder_loss": 0.010443098809570074, "actor_loss": -2.7718290634155274, "actor_target_entropy": -6.0, "actor_entropy": 5.110700656890869, "alpha_loss": -0.0015690739980200306, "alpha_value": 0.004354744821985942, "duration": 53.9970064163208, "step": 8000}
{"episode_reward": 22.519114728851072, "episode": 33.0, "batch_reward": 0.10879810619354248, "critic_loss": 0.02699199979007244, "ae_transition_loss": 0.005500359436497093, "ae_encoder_loss": 0.010383310258388519, "actor_loss": -2.8591341285705565, "actor_target_entropy": -6.0, "actor_entropy": 5.120122119903565, "alpha_loss": -0.001553703614976257, "alpha_value": 0.004451822222509676, "duration": 53.858590841293335, "step": 8250}
{"episode_reward": 17.922305485353686, "episode": 34.0, "batch_reward": 0.10774572822451592, "critic_loss": 0.03100992350280285, "ae_transition_loss": 0.0053484755419194695, "ae_encoder_loss": 0.010230344165116548, "actor_loss": -2.9119811801910402, "actor_target_entropy": -6.0, "actor_entropy": 5.179406791687012, "alpha_loss": -0.0011083222680026666, "alpha_value": 0.004530998897274166, "duration": 53.50432205200195, "step": 8500}
{"episode_reward": 20.651024261509722, "episode": 35.0, "batch_reward": 0.10842880547046661, "critic_loss": 0.030995502978563308, "ae_transition_loss": 0.005317843014374375, "ae_encoder_loss": 0.010084270123392344, "actor_loss": -3.00067112159729, "actor_target_entropy": -6.0, "actor_entropy": 5.188722484588623, "alpha_loss": -0.001177542628487572, "alpha_value": 0.004621262727615492, "duration": 53.52569651603699, "step": 8750}
{"episode_reward": 25.789105939967232, "episode": 36.0, "batch_reward": 0.10738228625059128, "critic_loss": 0.03699112691730261, "ae_transition_loss": 0.00555626455321908, "ae_encoder_loss": 0.009737931491807104, "actor_loss": -3.066090534210205, "actor_target_entropy": -6.0, "actor_entropy": 5.317077861785888, "alpha_loss": 0.0010093679177807643, "alpha_value": 0.004637830626831214, "duration": 53.52457809448242, "step": 9000}
{"episode_reward": 37.716908294312354, "episode": 37.0, "batch_reward": 0.10828224733471871, "critic_loss": 0.033152262903749945, "ae_transition_loss": 0.005527728889137507, "ae_encoder_loss": 0.009980261623859406, "actor_loss": -3.1533918323516845, "actor_target_entropy": -6.0, "actor_entropy": 5.224196952819824, "alpha_loss": 0.0012708256733603776, "alpha_value": 0.0045369694254119245, "duration": 53.49354648590088, "step": 9250}
{"episode_reward": 15.242533180014455, "episode": 38.0, "batch_reward": 0.10697512394189834, "critic_loss": 0.03559694259613752, "ae_transition_loss": 0.0055410360526293514, "ae_encoder_loss": 0.010262108407914639, "actor_loss": -3.1942599716186524, "actor_target_entropy": -6.0, "actor_entropy": 5.26844856262207, "alpha_loss": 0.0014270880255498922, "alpha_value": 0.004423275357172933, "duration": 53.54789113998413, "step": 9500}
{"episode_reward": 19.49097166615587, "episode": 39.0, "batch_reward": 0.1069861621260643, "critic_loss": 0.035432124748826024, "ae_transition_loss": 0.00529533838108182, "ae_encoder_loss": 0.009867140162736177, "actor_loss": -3.2535357456207277, "actor_target_entropy": -6.0, "actor_entropy": 5.274135082244873, "alpha_loss": 0.000734230792382732, "alpha_value": 0.0043307905454265955, "duration": 53.538355588912964, "step": 9750}
{"episode_reward": 25.82179125145189, "episode": 40.0, "batch_reward": 0.10663701373338699, "critic_loss": 0.04773983736336231, "ae_transition_loss": 0.005608760690316558, "ae_encoder_loss": 0.01019309339299798, "actor_loss": -3.313504634857178, "actor_target_entropy": -6.0, "actor_entropy": 5.288426712036133, "alpha_loss": 6.153851083945484e-05, "alpha_value": 0.004287453627069578, "duration": 53.508188247680664, "step": 10000}
{"episode_reward": 32.13026284175175, "episode": 41.0, "batch_reward": 0.10775714045763016, "critic_loss": 0.045724049381911755, "ae_transition_loss": 0.005683806717395782, "ae_encoder_loss": 0.010229218777269126, "actor_loss": -3.3839039421081543, "actor_target_entropy": -6.0, "actor_entropy": 5.340680679321289, "alpha_loss": -0.0005107366173760966, "alpha_value": 0.0042999892995986035, "duration": 75.94614839553833, "step": 10250}
{"episode_reward": 29.188650884237855, "episode": 42.0, "batch_reward": 0.10851728022098542, "critic_loss": 0.046570008873939514, "ae_transition_loss": 0.005557406108826399, "ae_encoder_loss": 0.010115277890115976, "actor_loss": -3.447958053588867, "actor_target_entropy": -6.0, "actor_entropy": 5.321990173339843, "alpha_loss": -0.0007164221451384946, "alpha_value": 0.004356899989225334, "duration": 53.5570547580719, "step": 10500}
{"episode_reward": 50.90482461067524, "episode": 43.0, "batch_reward": 0.1105675163269043, "critic_loss": 0.04590174428373575, "ae_transition_loss": 0.005362893834710121, "ae_encoder_loss": 0.010242120131850243, "actor_loss": -3.528386558532715, "actor_target_entropy": -6.0, "actor_entropy": 5.450721412658692, "alpha_loss": -0.0007021621065214276, "alpha_value": 0.004452059541665671, "duration": 53.552011251449585, "step": 10750}
{"episode_reward": 38.81850692049933, "episode": 44.0, "batch_reward": 0.11117812865972519, "critic_loss": 0.04161061120778322, "ae_transition_loss": 0.005056370763108134, "ae_encoder_loss": 0.010113302066922188, "actor_loss": -3.5958591632843016, "actor_target_entropy": -6.0, "actor_entropy": 5.425916679382325, "alpha_loss": -0.0012328650036943145, "alpha_value": 0.004556587606580479, "duration": 53.87065768241882, "step": 11000}
{"episode_reward": 38.47662562411682, "episode": 45.0, "batch_reward": 0.11145850729942322, "critic_loss": 0.053377460658550265, "ae_transition_loss": 0.005269106877967715, "ae_encoder_loss": 0.01022630987688899, "actor_loss": -3.682492902755737, "actor_target_entropy": -6.0, "actor_entropy": 5.4474304542541505, "alpha_loss": -0.001081835403572768, "alpha_value": 0.004690912624642079, "duration": 54.027477979660034, "step": 11250}
{"episode_reward": 25.22120816722374, "episode": 46.0, "batch_reward": 0.11319369038939477, "critic_loss": 0.050013455763459204, "ae_transition_loss": 0.004958906373009085, "ae_encoder_loss": 0.01002790080755949, "actor_loss": -3.7866727085113525, "actor_target_entropy": -6.0, "actor_entropy": 5.428348724365234, "alpha_loss": -0.0018783573420951144, "alpha_value": 0.004878537419840818, "duration": 54.008174896240234, "step": 11500}
{"episode_reward": 40.34996506812, "episode": 47.0, "batch_reward": 0.11300964468717575, "critic_loss": 0.04882903699576855, "ae_transition_loss": 0.004703248063102365, "ae_encoder_loss": 0.009809059586375951, "actor_loss": -3.8391724910736085, "actor_target_entropy": -6.0, "actor_entropy": 5.4457454566955565, "alpha_loss": -0.0015323736488353462, "alpha_value": 0.005166930844919973, "duration": 54.01429462432861, "step": 11750}
{"episode_reward": 36.540495910797084, "episode": 48.0, "batch_reward": 0.1138822611272335, "critic_loss": 0.0563914510756731, "ae_transition_loss": 0.00462074119783938, "ae_encoder_loss": 0.00970412151888013, "actor_loss": -3.926385959625244, "actor_target_entropy": -6.0, "actor_entropy": 5.490253002166748, "alpha_loss": -0.001837971407803707, "alpha_value": 0.005417027544650222, "duration": 54.05084490776062, "step": 12000}
{"episode_reward": 50.45444717543455, "episode": 49.0, "batch_reward": 0.11568400835990905, "critic_loss": 0.06879779121279717, "ae_transition_loss": 0.004975715514272451, "ae_encoder_loss": 0.010353515319526196, "actor_loss": -4.039613876342774, "actor_target_entropy": -6.0, "actor_entropy": 5.453867809295654, "alpha_loss": -0.0018449034017976374, "alpha_value": 0.0057403185868431985, "duration": 54.04773473739624, "step": 12250}
{"episode_reward": 29.488046150165946, "episode": 50.0, "batch_reward": 0.11455442401766777, "critic_loss": 0.06181815432012081, "ae_transition_loss": 0.004730678837746382, "ae_encoder_loss": 0.010068174168467522, "actor_loss": -4.117837139129639, "actor_target_entropy": -6.0, "actor_entropy": 5.496367958068848, "alpha_loss": -0.0008662057692417874, "alpha_value": 0.0060211168297271975, "duration": 54.04421281814575, "step": 12500}
{"episode_reward": 28.465699537278752, "episode": 51.0, "batch_reward": 0.1144833032488823, "critic_loss": 0.0670250610858202, "ae_transition_loss": 0.0047425320819020275, "ae_encoder_loss": 0.010113105760887265, "actor_loss": -4.177532157897949, "actor_target_entropy": -6.0, "actor_entropy": 5.538090919494629, "alpha_loss": -0.0006064464926021174, "alpha_value": 0.006146846252774042, "duration": 70.4953076839447, "step": 12750}
{"episode_reward": 17.673070706511435, "episode": 52.0, "batch_reward": 0.11508872410655022, "critic_loss": 0.06967515021562576, "ae_transition_loss": 0.004752503270283342, "ae_encoder_loss": 0.009913776565343141, "actor_loss": -4.283611427307129, "actor_target_entropy": -6.0, "actor_entropy": 5.49738415145874, "alpha_loss": -0.0010695967379724606, "alpha_value": 0.00633456936636656, "duration": 54.042847871780396, "step": 13000}
{"episode_reward": 42.30148395119114, "episode": 53.0, "batch_reward": 0.1163666382431984, "critic_loss": 0.08160332831740379, "ae_transition_loss": 0.004791500730440021, "ae_encoder_loss": 0.009869133183732628, "actor_loss": -4.390614780426025, "actor_target_entropy": -6.0, "actor_entropy": 5.525029560089111, "alpha_loss": -0.0011153002227656543, "alpha_value": 0.006620926555367101, "duration": 54.037073373794556, "step": 13250}
{"episode_reward": 69.42950715413885, "episode": 54.0, "batch_reward": 0.1193031108379364, "critic_loss": 0.07899885541200638, "ae_transition_loss": 0.00482616957090795, "ae_encoder_loss": 0.010414391685277224, "actor_loss": -4.482843124389649, "actor_target_entropy": -6.0, "actor_entropy": 5.57461145401001, "alpha_loss": 0.00041261091153137387, "alpha_value": 0.006686902238442789, "duration": 54.04646301269531, "step": 13500}
{"episode_reward": 38.103546730533544, "episode": 55.0, "batch_reward": 0.12014262229204178, "critic_loss": 0.07534411911666393, "ae_transition_loss": 0.004662727810442448, "ae_encoder_loss": 0.010225296393036843, "actor_loss": -4.562624382019043, "actor_target_entropy": -6.0, "actor_entropy": 5.486137378692627, "alpha_loss": -0.0002666508585680276, "alpha_value": 0.006716277227688767, "duration": 54.02943563461304, "step": 13750}
{"episode_reward": 35.539427875661204, "episode": 56.0, "batch_reward": 0.11963325476646423, "critic_loss": 0.09075662711262703, "ae_transition_loss": 0.004969600684940815, "ae_encoder_loss": 0.010725391916930676, "actor_loss": -4.628928604125977, "actor_target_entropy": -6.0, "actor_entropy": 5.583062061309814, "alpha_loss": 0.00030765548814088106, "alpha_value": 0.006673821082538026, "duration": 54.04724979400635, "step": 14000}
{"episode_reward": 42.586603570269304, "episode": 57.0, "batch_reward": 0.1213085584640503, "critic_loss": 0.08822009138762951, "ae_transition_loss": 0.005034746764227748, "ae_encoder_loss": 0.011237327042967081, "actor_loss": -4.717528415679932, "actor_target_entropy": -6.0, "actor_entropy": 5.599692287445069, "alpha_loss": 0.00019601566810160874, "alpha_value": 0.0066410224385277175, "duration": 54.043503522872925, "step": 14250}
{"episode_reward": 53.70777373121123, "episode": 58.0, "batch_reward": 0.12180227395892143, "critic_loss": 0.09560012811422348, "ae_transition_loss": 0.005344798663631082, "ae_encoder_loss": 0.011508766315877437, "actor_loss": -4.76431364440918, "actor_target_entropy": -6.0, "actor_entropy": 5.637830909729004, "alpha_loss": -7.477778650354594e-05, "alpha_value": 0.006541581906699838, "duration": 54.04381775856018, "step": 14500}
{"episode_reward": 21.94753111407533, "episode": 59.0, "batch_reward": 0.12139373591542243, "critic_loss": 0.09137632235884667, "ae_transition_loss": 0.0053248141221702095, "ae_encoder_loss": 0.011750072706490755, "actor_loss": -4.806692440032959, "actor_target_entropy": -6.0, "actor_entropy": 5.642079765319824, "alpha_loss": 0.0007109004070516675, "alpha_value": 0.006501235982729036, "duration": 54.03973126411438, "step": 14750}
{"episode_reward": 49.01399514658655, "episode": 60.0, "batch_reward": 0.12287722903490067, "critic_loss": 0.11377613282203675, "ae_transition_loss": 0.005646903833374381, "ae_encoder_loss": 0.012168547976762057, "actor_loss": -4.839449203491211, "actor_target_entropy": -6.0, "actor_entropy": 5.6511243553161625, "alpha_loss": 0.0017598398132249713, "alpha_value": 0.0062182114158569534, "duration": 54.04963517189026, "step": 15000}
{"episode_reward": 38.993660699764085, "episode": 61.0, "batch_reward": 0.12364479413628578, "critic_loss": 0.11903245198726654, "ae_transition_loss": 0.005729056894779205, "ae_encoder_loss": 0.012262404412031174, "actor_loss": -4.881678726196289, "actor_target_entropy": -6.0, "actor_entropy": 5.604695831298828, "alpha_loss": 0.0010137696949532255, "alpha_value": 0.005816182612276547, "duration": 70.43179059028625, "step": 15250}
{"episode_reward": 60.88415733954261, "episode": 62.0, "batch_reward": 0.12514671862125396, "critic_loss": 0.11327666953206063, "ae_transition_loss": 0.0056270022671669724, "ae_encoder_loss": 0.012069331258535385, "actor_loss": -4.927790496826172, "actor_target_entropy": -6.0, "actor_entropy": 5.603951583862305, "alpha_loss": -0.0004484922476112843, "alpha_value": 0.005703679003913381, "duration": 54.05326199531555, "step": 15500}
{"episode_reward": 21.380766221286585, "episode": 63.0, "batch_reward": 0.12418877390027046, "critic_loss": 0.12420293000340461, "ae_transition_loss": 0.005869935572147369, "ae_encoder_loss": 0.012194316118955613, "actor_loss": -4.916694923400879, "actor_target_entropy": -6.0, "actor_entropy": 5.6680031013488765, "alpha_loss": 0.0008738967555109411, "alpha_value": 0.005746119690633864, "duration": 54.03740572929382, "step": 15750}
{"episode_reward": 24.607341029716025, "episode": 64.0, "batch_reward": 0.12385095092654229, "critic_loss": 0.13833956590294838, "ae_transition_loss": 0.006054149366915226, "ae_encoder_loss": 0.012400036040693521, "actor_loss": -4.915167434692383, "actor_target_entropy": -6.0, "actor_entropy": 5.643237083435059, "alpha_loss": 0.00029671105043962596, "alpha_value": 0.005511997611474702, "duration": 54.04285287857056, "step": 16000}
{"episode_reward": 35.76340693966627, "episode": 65.0, "batch_reward": 0.12539286518096923, "critic_loss": 0.13857856675982475, "ae_transition_loss": 0.006232060143724084, "ae_encoder_loss": 0.012411385536193848, "actor_loss": -4.942731586456299, "actor_target_entropy": -6.0, "actor_entropy": 5.635281658172607, "alpha_loss": -0.0006916750600794331, "alpha_value": 0.005548482142268017, "duration": 54.04411005973816, "step": 16250}
{"episode_reward": 60.78464728277772, "episode": 66.0, "batch_reward": 0.1272527579367161, "critic_loss": 0.16085427513718606, "ae_transition_loss": 0.0064811260104179385, "ae_encoder_loss": 0.012754812568426132, "actor_loss": -5.0153936080932615, "actor_target_entropy": -6.0, "actor_entropy": 5.667438179016114, "alpha_loss": -0.0009506537276320159, "alpha_value": 0.005861722668675739, "duration": 54.040048122406006, "step": 16500}
{"episode_reward": 37.91442725418225, "episode": 67.0, "batch_reward": 0.12715590065717697, "critic_loss": 0.1718137030005455, "ae_transition_loss": 0.006542454037815332, "ae_encoder_loss": 0.012795806020498277, "actor_loss": -5.063256687164307, "actor_target_entropy": -6.0, "actor_entropy": 5.668344367980957, "alpha_loss": -0.0004738169552292675, "alpha_value": 0.006092140977490402, "duration": 54.06132173538208, "step": 16750}
{"episode_reward": 39.75619688695391, "episode": 68.0, "batch_reward": 0.127068965613842, "critic_loss": 0.15413278633356095, "ae_transition_loss": 0.00646045908331871, "ae_encoder_loss": 0.012923657841980457, "actor_loss": -5.104444751739502, "actor_target_entropy": -6.0, "actor_entropy": 5.6879040718078615, "alpha_loss": -0.00010378265753388405, "alpha_value": 0.0061454312656893, "duration": 54.066609382629395, "step": 17000}
{"episode_reward": 37.36971234244559, "episode": 69.0, "batch_reward": 0.1291493437886238, "critic_loss": 0.19253086900711058, "ae_transition_loss": 0.006919363839551806, "ae_encoder_loss": 0.01401057668030262, "actor_loss": -5.1728464698791505, "actor_target_entropy": -6.0, "actor_entropy": 5.725057609558106, "alpha_loss": -0.000582586188800633, "alpha_value": 0.006248678411765391, "duration": 54.04410743713379, "step": 17250}
{"episode_reward": 77.72858095739498, "episode": 70.0, "batch_reward": 0.1313901645243168, "critic_loss": 0.18669819462299347, "ae_transition_loss": 0.00688307642377913, "ae_encoder_loss": 0.0142234155125916, "actor_loss": -5.18683366394043, "actor_target_entropy": -6.0, "actor_entropy": 5.721721019744873, "alpha_loss": -0.00013327823276631533, "alpha_value": 0.006360681974417622, "duration": 54.03837466239929, "step": 17500}
{"episode_reward": 40.37409811055317, "episode": 71.0, "batch_reward": 0.13186388009786607, "critic_loss": 0.18410332891345024, "ae_transition_loss": 0.006813382955268025, "ae_encoder_loss": 0.014433267336338759, "actor_loss": -5.237270172119141, "actor_target_entropy": -6.0, "actor_entropy": 5.704741630554199, "alpha_loss": -5.557945929467678e-06, "alpha_value": 0.006347292519349981, "duration": 70.32840824127197, "step": 17750}
{"episode_reward": 49.72399842539644, "episode": 72.0, "batch_reward": 0.13110758075118065, "critic_loss": 0.1830606472492218, "ae_transition_loss": 0.0066265673078596595, "ae_encoder_loss": 0.014207236081361771, "actor_loss": -5.282089836120606, "actor_target_entropy": -6.0, "actor_entropy": 5.737858860015869, "alpha_loss": -0.00010197505680844187, "alpha_value": 0.00635511127586195, "duration": 54.04707932472229, "step": 18000}
{"episode_reward": 43.83913172829645, "episode": 73.0, "batch_reward": 0.1325469304919243, "critic_loss": 0.23207688438892365, "ae_transition_loss": 0.0071104458961635825, "ae_encoder_loss": 0.01466807271540165, "actor_loss": -5.331470409393311, "actor_target_entropy": -6.0, "actor_entropy": 5.834474391937256, "alpha_loss": -0.0002451650213915855, "alpha_value": 0.006442424717390154, "duration": 54.04247450828552, "step": 18250}
{"episode_reward": 42.08612487745328, "episode": 74.0, "batch_reward": 0.1339246131181717, "critic_loss": 0.2321120336651802, "ae_transition_loss": 0.0074043857865035536, "ae_encoder_loss": 0.014711111448705197, "actor_loss": -5.363776416778564, "actor_target_entropy": -6.0, "actor_entropy": 5.869165668487549, "alpha_loss": 0.0005383992883143947, "alpha_value": 0.006468794241391553, "duration": 54.06425356864929, "step": 18500}
{"episode_reward": 50.170316704542024, "episode": 75.0, "batch_reward": 0.13395781847834587, "critic_loss": 0.2745874085426331, "ae_transition_loss": 0.007785448405891657, "ae_encoder_loss": 0.01469857493788004, "actor_loss": -5.438625915527344, "actor_target_entropy": -6.0, "actor_entropy": 5.875358787536621, "alpha_loss": -0.001172557830810547, "alpha_value": 0.006469807744358597, "duration": 54.05888056755066, "step": 18750}
{"episode_reward": 33.43352887357052, "episode": 76.0, "batch_reward": 0.13274091231822968, "critic_loss": 0.34239118051528933, "ae_transition_loss": 0.007833550581708551, "ae_encoder_loss": 0.014415306337177754, "actor_loss": -5.502246841430664, "actor_target_entropy": -6.0, "actor_entropy": 5.839123863220215, "alpha_loss": -0.002403635507915169, "alpha_value": 0.0070029504156471955, "duration": 54.05732321739197, "step": 19000}
{"episode_reward": 36.63711262936128, "episode": 77.0, "batch_reward": 0.13523260083794594, "critic_loss": 0.30712946426868437, "ae_transition_loss": 0.007515612185001373, "ae_encoder_loss": 0.01444835351407528, "actor_loss": -5.6137032928466795, "actor_target_entropy": -6.0, "actor_entropy": 5.845334117889404, "alpha_loss": -0.002202183235436678, "alpha_value": 0.0078000382198543435, "duration": 54.05161428451538, "step": 19250}
{"episode_reward": 52.80458280853576, "episode": 78.0, "batch_reward": 0.13356686472892762, "critic_loss": 0.2966280629634857, "ae_transition_loss": 0.007363233435899019, "ae_encoder_loss": 0.014719263583421707, "actor_loss": -5.675940620422363, "actor_target_entropy": -6.0, "actor_entropy": 5.907614555358887, "alpha_loss": 0.0007584977075457573, "alpha_value": 0.008215207474375206, "duration": 54.05982685089111, "step": 19500}
{"episode_reward": 26.742473097753415, "episode": 79.0, "batch_reward": 0.13444481870532035, "critic_loss": 0.3578053569793701, "ae_transition_loss": 0.007504986476153135, "ae_encoder_loss": 0.015105087783187627, "actor_loss": -5.804652614593506, "actor_target_entropy": -6.0, "actor_entropy": 5.878837287902832, "alpha_loss": -0.0006945942335296422, "alpha_value": 0.008132564558453192, "duration": 54.03639888763428, "step": 19750}
{"episode_reward": 31.507431897558817, "episode": 80.0, "batch_reward": 0.13484971702098847, "critic_loss": 0.40878119617700576, "ae_transition_loss": 0.007590500593185424, "ae_encoder_loss": 0.01533543810620904, "actor_loss": -5.981086418151856, "actor_target_entropy": -6.0, "actor_entropy": 5.8486261024475095, "alpha_loss": -0.000285734087927267, "alpha_value": 0.008266349491597724, "duration": 54.03833508491516, "step": 20000}
{"episode_reward": 34.94421525203605, "episode": 81.0, "batch_reward": 0.13472119307518005, "critic_loss": 0.493905987739563, "ae_transition_loss": 0.00825229655764997, "ae_encoder_loss": 0.015874554503709077, "actor_loss": -6.141343868255615, "actor_target_entropy": -6.0, "actor_entropy": 5.9464418258667, "alpha_loss": 0.0015320650411304087, "alpha_value": 0.008101277105826936, "duration": 76.68209886550903, "step": 20250}
{"episode_reward": 37.06053706410994, "episode": 82.0, "batch_reward": 0.1344568829536438, "critic_loss": 0.5983131991624833, "ae_transition_loss": 0.008663826171308757, "ae_encoder_loss": 0.015942575685679913, "actor_loss": -6.298545436859131, "actor_target_entropy": -6.0, "actor_entropy": 5.957786125183105, "alpha_loss": 0.000208293286152184, "alpha_value": 0.007853534772683218, "duration": 54.09905004501343, "step": 20500}
{"episode_reward": 32.288905603996994, "episode": 83.0, "batch_reward": 0.13362649920582773, "critic_loss": 0.7270793762207032, "ae_transition_loss": 0.008591842845082283, "ae_encoder_loss": 0.015039200693368912, "actor_loss": -6.457115306854248, "actor_target_entropy": -6.0, "actor_entropy": 6.01396390914917, "alpha_loss": -0.0002529690242372453, "alpha_value": 0.0077414660649805294, "duration": 54.0393500328064, "step": 20750}
{"episode_reward": 33.270166612683234, "episode": 84.0, "batch_reward": 0.13449066123366357, "critic_loss": 0.8437936296463012, "ae_transition_loss": 0.008442939257249236, "ae_encoder_loss": 0.014399798691272735, "actor_loss": -6.577747097015381, "actor_target_entropy": -6.0, "actor_entropy": 6.174719493865966, "alpha_loss": -0.00012543508945964276, "alpha_value": 0.008051358964626342, "duration": 54.05416536331177, "step": 21000}
{"episode_reward": 35.81243192506094, "episode": 85.0, "batch_reward": 0.13465375342965127, "critic_loss": 1.1296120307445525, "ae_transition_loss": 0.00953439700976014, "ae_encoder_loss": 0.01547102816030383, "actor_loss": -6.722505558013916, "actor_target_entropy": -6.0, "actor_entropy": 6.1681399803161625, "alpha_loss": -0.0011404460680205376, "alpha_value": 0.007966329003506625, "duration": 54.055116176605225, "step": 21250}
{"episode_reward": 38.44600128602088, "episode": 86.0, "batch_reward": 0.13522695773839952, "critic_loss": 1.417367041349411, "ae_transition_loss": 0.009642473787069322, "ae_encoder_loss": 0.015507339157164096, "actor_loss": -7.10395677947998, "actor_target_entropy": -6.0, "actor_entropy": 6.234990242004394, "alpha_loss": -0.0014041340999538078, "alpha_value": 0.008249296997011515, "duration": 54.045928716659546, "step": 21500}
{"episode_reward": 35.07293627310597, "episode": 87.0, "batch_reward": 0.13507760739326477, "critic_loss": 1.690691799879074, "ae_transition_loss": 0.00898852843977511, "ae_encoder_loss": 0.014915434785187245, "actor_loss": -7.616334087371826, "actor_target_entropy": -6.0, "actor_entropy": 6.266297538757324, "alpha_loss": -0.0025002401415258647, "alpha_value": 0.009067678208097405, "duration": 54.06826376914978, "step": 21750}
{"episode_reward": 18.98310456106075, "episode": 88.0, "batch_reward": 0.13363720193505288, "critic_loss": 2.1132779908180237, "ae_transition_loss": 0.009126365561038255, "ae_encoder_loss": 0.014815299827605486, "actor_loss": -7.9189667129516605, "actor_target_entropy": -6.0, "actor_entropy": 6.267895835876465, "alpha_loss": -0.0017499118051491679, "alpha_value": 0.009699387892965622, "duration": 54.056140184402466, "step": 22000}
{"episode_reward": 32.3007553643766, "episode": 89.0, "batch_reward": 0.1351198697388172, "critic_loss": 2.486219573497772, "ae_transition_loss": 0.009265267414972186, "ae_encoder_loss": 0.015327538173645735, "actor_loss": -8.230639144897461, "actor_target_entropy": -6.0, "actor_entropy": 6.220895133972168, "alpha_loss": -0.002651756667532027, "alpha_value": 0.010305033625886008, "duration": 54.05279803276062, "step": 22250}
{"episode_reward": 46.78464400203123, "episode": 90.0, "batch_reward": 0.13433445253968238, "critic_loss": 4.210543624877929, "ae_transition_loss": 0.009974964924156665, "ae_encoder_loss": 0.015377189904451371, "actor_loss": -8.689632026672363, "actor_target_entropy": -6.0, "actor_entropy": 6.2129043807983395, "alpha_loss": -0.003125950939254835, "alpha_value": 0.011370539392145388, "duration": 54.04043912887573, "step": 22500}
{"episode_reward": 27.258324321270717, "episode": 91.0, "batch_reward": 0.1331051145195961, "critic_loss": 5.47117894077301, "ae_transition_loss": 0.010320857658982278, "ae_encoder_loss": 0.015362096082419157, "actor_loss": -9.164225364685059, "actor_target_entropy": -6.0, "actor_entropy": 6.275925491333008, "alpha_loss": -0.004148714853916317, "alpha_value": 0.012471330615293052, "duration": 70.4356997013092, "step": 22750}
{"episode_reward": 25.67366704459322, "episode": 92.0, "batch_reward": 0.13438287556171416, "critic_loss": 7.724490547180176, "ae_transition_loss": 0.010543026886880398, "ae_encoder_loss": 0.015265096813440323, "actor_loss": -9.771672760009766, "actor_target_entropy": -6.0, "actor_entropy": 6.276197540283203, "alpha_loss": -0.004297952209133655, "alpha_value": 0.01359908509625861, "duration": 54.03787112236023, "step": 23000}
{"episode_reward": 43.247035802351746, "episode": 93.0, "batch_reward": 0.13388379526138305, "critic_loss": 12.23399794960022, "ae_transition_loss": 0.011045888081192971, "ae_encoder_loss": 0.015146659102290868, "actor_loss": -10.775188148498534, "actor_target_entropy": -6.0, "actor_entropy": 6.194167953491211, "alpha_loss": -0.005785531948320568, "alpha_value": 0.015195433537061149, "duration": 54.05172610282898, "step": 23250}
{"episode_reward": 29.37606321606781, "episode": 94.0, "batch_reward": 0.13271882450580597, "critic_loss": 11.350396612167359, "ae_transition_loss": 0.009794986113905906, "ae_encoder_loss": 0.014418881304562092, "actor_loss": -10.936191970825195, "actor_target_entropy": -6.0, "actor_entropy": 6.221450309753418, "alpha_loss": -0.002518291865941137, "alpha_value": 0.016795555622895364, "duration": 54.049880266189575, "step": 23500}
{"episode_reward": 8.886928277421271, "episode": 95.0, "batch_reward": 0.13403440633416175, "critic_loss": 19.024187004089356, "ae_transition_loss": 0.010835986882448197, "ae_encoder_loss": 0.015464914865791797, "actor_loss": -11.398848663330078, "actor_target_entropy": -6.0, "actor_entropy": 6.125413925170898, "alpha_loss": -0.0018490372668020427, "alpha_value": 0.01741299204307868, "duration": 54.0559139251709, "step": 23750}
{"episode_reward": 27.180187222103026, "episode": 96.0, "batch_reward": 0.13334852513670922, "critic_loss": 29.954737968444825, "ae_transition_loss": 0.011707226440310478, "ae_encoder_loss": 0.015548967722803354, "actor_loss": -12.024491142272948, "actor_target_entropy": -6.0, "actor_entropy": 6.109394340515137, "alpha_loss": -0.0037748437370173633, "alpha_value": 0.017985160303115123, "duration": 54.087451457977295, "step": 24000}
{"episode_reward": 40.81490681631283, "episode": 97.0, "batch_reward": 0.13350028282403945, "critic_loss": 35.85301268386841, "ae_transition_loss": 0.010998973179608584, "ae_encoder_loss": 0.014473771777004003, "actor_loss": -13.053311454772949, "actor_target_entropy": -6.0, "actor_entropy": 6.166393249511719, "alpha_loss": -0.00804446393251419, "alpha_value": 0.01978155306081427, "duration": 54.03004217147827, "step": 24250}
{"episode_reward": 15.296519181091954, "episode": 98.0, "batch_reward": 0.13185199439525605, "critic_loss": 43.0458250541687, "ae_transition_loss": 0.01070457036793232, "ae_encoder_loss": 0.014465605676174163, "actor_loss": -13.716671844482422, "actor_target_entropy": -6.0, "actor_entropy": 6.186215579986572, "alpha_loss": -0.004525028302334249, "alpha_value": 0.02151455322165257, "duration": 54.04387664794922, "step": 24500}
{"episode_reward": 11.61259858184478, "episode": 99.0, "batch_reward": 0.13121733692288398, "critic_loss": 65.69499546813965, "ae_transition_loss": 0.011370584428310394, "ae_encoder_loss": 0.014918469324707985, "actor_loss": -14.677571884155274, "actor_target_entropy": -6.0, "actor_entropy": 6.146245094299316, "alpha_loss": -0.008043582358397543, "alpha_value": 0.02374019792993728, "duration": 54.0562949180603, "step": 24750}
{"episode_reward": 33.12470532067582, "episode": 100.0, "batch_reward": 0.13202198201417922, "critic_loss": 88.82901860046387, "ae_transition_loss": 0.011224866345524788, "ae_encoder_loss": 0.01457738796621561, "actor_loss": -15.50439688873291, "actor_target_entropy": -6.0, "actor_entropy": 6.23628893661499, "alpha_loss": -0.009739075769670308, "alpha_value": 0.026300153987140536, "duration": 54.02637529373169, "step": 25000}
{"episode_reward": 36.797786823621095, "episode": 101.0, "batch_reward": 0.13143961307406427, "critic_loss": 95.39847355651855, "ae_transition_loss": 0.010400544576346874, "ae_encoder_loss": 0.01407855686917901, "actor_loss": -15.839142578125, "actor_target_entropy": -6.0, "actor_entropy": 6.195728412628174, "alpha_loss": -0.00022773275710642337, "alpha_value": 0.027537707169620524, "duration": 70.47076177597046, "step": 25250}
{"episode_reward": 14.997784050546441, "episode": 102.0, "batch_reward": 0.13097931095957757, "critic_loss": 184.50219857788085, "ae_transition_loss": 0.012005685985088348, "ae_encoder_loss": 0.014966651264578103, "actor_loss": -16.827412322998047, "actor_target_entropy": -6.0, "actor_entropy": 6.39361775970459, "alpha_loss": 0.005523239713162184, "alpha_value": 0.02709504307034962, "duration": 54.04232168197632, "step": 25500}
{"episode_reward": 19.614539850555353, "episode": 103.0, "batch_reward": 0.1294350854754448, "critic_loss": 214.5802494506836, "ae_transition_loss": 0.011294768050312995, "ae_encoder_loss": 0.014768756702542305, "actor_loss": -17.331312782287597, "actor_target_entropy": -6.0, "actor_entropy": 6.397807479858399, "alpha_loss": -0.002531486109830439, "alpha_value": 0.026361608226324777, "duration": 54.04305458068848, "step": 25750}
{"episode_reward": 12.822743464547745, "episode": 104.0, "batch_reward": 0.12998520630598068, "critic_loss": 230.1874942626953, "ae_transition_loss": 0.010920421846210957, "ae_encoder_loss": 0.014042188998311758, "actor_loss": -18.459124114990235, "actor_target_entropy": -6.0, "actor_entropy": 6.200614356994629, "alpha_loss": -0.016212035889737308, "alpha_value": 0.028723273673662567, "duration": 54.050581216812134, "step": 26000}
{"episode_reward": 19.964336306823, "episode": 105.0, "batch_reward": 0.12966126370429992, "critic_loss": 454.33276754760743, "ae_transition_loss": 0.011917464546859264, "ae_encoder_loss": 0.014669409204274416, "actor_loss": -19.515464157104493, "actor_target_entropy": -6.0, "actor_entropy": 6.230924362182617, "alpha_loss": -0.012477192796766758, "alpha_value": 0.03127374567547884, "duration": 54.029356479644775, "step": 26250}
