{"episode_reward": 0.0, "episode": 1.0, "duration": 15.853375911712646, "step": 250}
{"episode_reward": 8.03772363506006, "episode": 2.0, "duration": 0.3510453701019287, "step": 500}
{"episode_reward": 17.16626315104322, "episode": 3.0, "duration": 0.3484365940093994, "step": 750}
{"episode_reward": 12.073072643141685, "episode": 4.0, "duration": 0.35007643699645996, "step": 1000}
{"episode_reward": 11.095187414981499, "episode": 5.0, "batch_reward": 0.048445985442977416, "critic_loss": 0.015009658520756435, "ae_transition_loss": 0.012707332391322615, "ae_encoder_loss": 0.0005281049686263512, "actor_loss": -0.16589658304367333, "actor_target_entropy": -6.0, "actor_entropy": 5.366870821370773, "alpha_loss": 0.033550336250355486, "alpha_value": 0.007090930939406157, "duration": 282.0587840080261, "step": 1250}
{"episode_reward": 13.764420948410834, "episode": 6.0, "batch_reward": 0.05056182199716568, "critic_loss": 0.01193181887641549, "ae_transition_loss": 0.0057810874171555044, "ae_encoder_loss": 0.0007480733456905, "actor_loss": -0.5520212330818176, "actor_target_entropy": -6.0, "actor_entropy": 5.280304634094239, "alpha_loss": 0.019636029027402403, "alpha_value": 0.005061652723178937, "duration": 54.20447564125061, "step": 1500}
{"episode_reward": 14.221399794087606, "episode": 7.0, "batch_reward": 0.05404871390759945, "critic_loss": 0.009408729258924723, "ae_transition_loss": 0.005489908900111914, "ae_encoder_loss": 0.0011574433667119592, "actor_loss": -0.6407781462669373, "actor_target_entropy": -6.0, "actor_entropy": 4.919581829071045, "alpha_loss": 0.009638459924608468, "alpha_value": 0.004758165581098106, "duration": 54.18398189544678, "step": 1750}
{"episode_reward": 22.432453931079774, "episode": 8.0, "batch_reward": 0.06287155935168266, "critic_loss": 0.010472976133227348, "ae_transition_loss": 0.0050925470842048525, "ae_encoder_loss": 0.0013878941987641156, "actor_loss": -0.7316249756813049, "actor_target_entropy": -6.0, "actor_entropy": 4.305032573699951, "alpha_loss": 0.0006070432092528791, "alpha_value": 0.004658059936243495, "duration": 54.21803641319275, "step": 2000}
{"episode_reward": 29.065938421363814, "episode": 9.0, "batch_reward": 0.07030392225086689, "critic_loss": 0.014873088130727411, "ae_transition_loss": 0.005232556998729706, "ae_encoder_loss": 0.0020806060682516544, "actor_loss": -0.7956974778175354, "actor_target_entropy": -6.0, "actor_entropy": 3.9253148288726805, "alpha_loss": 0.001005153312231414, "alpha_value": 0.0046333727264697335, "duration": 54.120243072509766, "step": 2250}
{"episode_reward": 31.8881172415787, "episode": 10.0, "batch_reward": 0.07597487020492553, "critic_loss": 0.016554116260260345, "ae_transition_loss": 0.0056013313140720125, "ae_encoder_loss": 0.0033298340374603866, "actor_loss": -0.8983915829658509, "actor_target_entropy": -6.0, "actor_entropy": 4.132636953353882, "alpha_loss": 7.897160376887768e-05, "alpha_value": 0.0046258095213485995, "duration": 54.08174204826355, "step": 2500}
{"episode_reward": 28.592422362158914, "episode": 11.0, "batch_reward": 0.0742715947329998, "critic_loss": 0.01220558100938797, "ae_transition_loss": 0.005218016099184751, "ae_encoder_loss": 0.004123917722143233, "actor_loss": -1.0910470719337464, "actor_target_entropy": -6.0, "actor_entropy": 3.870399393081665, "alpha_loss": -0.00877675536251627, "alpha_value": 0.0047040550782067245, "duration": 67.96067953109741, "step": 2750}
{"episode_reward": 8.773290855811746, "episode": 12.0, "batch_reward": 0.07005614644289017, "critic_loss": 0.014753352267667651, "ae_transition_loss": 0.005095147646963596, "ae_encoder_loss": 0.0038496296904049813, "actor_loss": -1.275225811958313, "actor_target_entropy": -6.0, "actor_entropy": 3.656917221069336, "alpha_loss": -0.014687957540154457, "alpha_value": 0.005031408801690735, "duration": 54.25412154197693, "step": 3000}
{"episode_reward": 7.340617860304048, "episode": 13.0, "batch_reward": 0.06678660967946053, "critic_loss": 0.013010167572647334, "ae_transition_loss": 0.004640065241605044, "ae_encoder_loss": 0.003680794685613364, "actor_loss": -1.4111095657348633, "actor_target_entropy": -6.0, "actor_entropy": 3.7137297325134275, "alpha_loss": -0.01637613555788994, "alpha_value": 0.005499796449337392, "duration": 54.20994758605957, "step": 3250}
{"episode_reward": 5.964839941967765, "episode": 14.0, "batch_reward": 0.06377026726305485, "critic_loss": 0.014632601410150528, "ae_transition_loss": 0.005075076192617416, "ae_encoder_loss": 0.00361644077161327, "actor_loss": -1.513854076385498, "actor_target_entropy": -6.0, "actor_entropy": 3.86119492149353, "alpha_loss": -0.015309192538261414, "alpha_value": 0.0060426172875088285, "duration": 54.25329661369324, "step": 3500}
{"episode_reward": 5.784715914084874, "episode": 15.0, "batch_reward": 0.0613935546875, "critic_loss": 0.01841720739006996, "ae_transition_loss": 0.005620804604142904, "ae_encoder_loss": 0.003761899155098945, "actor_loss": -1.615624797821045, "actor_target_entropy": -6.0, "actor_entropy": 4.002090660095215, "alpha_loss": -0.014970444679260253, "alpha_value": 0.0066314958418034016, "duration": 54.18757653236389, "step": 3750}
{"episode_reward": 6.214120431851882, "episode": 16.0, "batch_reward": 0.06974547463655471, "critic_loss": 0.03191323718428612, "ae_transition_loss": 0.0070490929912775755, "ae_encoder_loss": 0.007266138153150678, "actor_loss": -1.776041163444519, "actor_target_entropy": -6.0, "actor_entropy": 4.12670943069458, "alpha_loss": -0.0079760782844387, "alpha_value": 0.007215129527221859, "duration": 54.14456057548523, "step": 4000}
{"episode_reward": 92.37131751553096, "episode": 17.0, "batch_reward": 0.08488645875453948, "critic_loss": 0.03841333888471127, "ae_transition_loss": 0.009634391153231264, "ae_encoder_loss": 0.013498465286567807, "actor_loss": -1.9661655626296997, "actor_target_entropy": -6.0, "actor_entropy": 4.185083669662475, "alpha_loss": -0.001625760056776926, "alpha_value": 0.007358982075036067, "duration": 54.217002630233765, "step": 4250}
{"episode_reward": 58.26670771469595, "episode": 18.0, "batch_reward": 0.09203152936697007, "critic_loss": 0.03666062726825476, "ae_transition_loss": 0.01028669000044465, "ae_encoder_loss": 0.01546368957310915, "actor_loss": -2.1804016485214235, "actor_target_entropy": -6.0, "actor_entropy": 3.9524805603027344, "alpha_loss": 0.00037814859440550206, "alpha_value": 0.007438119219927244, "duration": 54.214699268341064, "step": 4500}
{"episode_reward": 37.23141474291488, "episode": 19.0, "batch_reward": 0.09443568316102027, "critic_loss": 0.03995888248831034, "ae_transition_loss": 0.01097594828903675, "ae_encoder_loss": 0.01719116460159421, "actor_loss": -2.4082170181274414, "actor_target_entropy": -6.0, "actor_entropy": 3.6815776710510253, "alpha_loss": 0.0007810029406100512, "alpha_value": 0.007412272594869221, "duration": 54.21210312843323, "step": 4750}
{"episode_reward": 67.96364305114655, "episode": 20.0, "batch_reward": 0.10145829620957375, "critic_loss": 0.03703104139119387, "ae_transition_loss": 0.012099558055400849, "ae_encoder_loss": 0.022596464943140746, "actor_loss": -2.583766691207886, "actor_target_entropy": -6.0, "actor_entropy": 4.19676916885376, "alpha_loss": -0.0004593486570520327, "alpha_value": 0.007369743339334565, "duration": 54.22697901725769, "step": 5000}
{"episode_reward": 29.435186099052665, "episode": 21.0, "batch_reward": 0.10517047062516212, "critic_loss": 0.04165602180361748, "ae_transition_loss": 0.01295072354376316, "ae_encoder_loss": 0.02562347102165222, "actor_loss": -2.7016373043060304, "actor_target_entropy": -6.0, "actor_entropy": 4.454466239929199, "alpha_loss": 0.003495375360827893, "alpha_value": 0.007351331202257324, "duration": 67.84007835388184, "step": 5250}
{"episode_reward": 64.42721236710243, "episode": 22.0, "batch_reward": 0.1118774921298027, "critic_loss": 0.0373433728441596, "ae_transition_loss": 0.013276500314474107, "ae_encoder_loss": 0.02765459331870079, "actor_loss": -2.8718398971557617, "actor_target_entropy": -6.0, "actor_entropy": 4.465510744094849, "alpha_loss": 0.0063913262691348794, "alpha_value": 0.006980843118155563, "duration": 54.20777440071106, "step": 5500}
{"episode_reward": 67.01316170752455, "episode": 23.0, "batch_reward": 0.11798955339193344, "critic_loss": 0.03791657078266144, "ae_transition_loss": 0.013769827853888273, "ae_encoder_loss": 0.029472287841141222, "actor_loss": -3.0115354557037355, "actor_target_entropy": -6.0, "actor_entropy": 4.3013889122009275, "alpha_loss": 0.005938491077162326, "alpha_value": 0.006609654100635084, "duration": 54.28463292121887, "step": 5750}
{"episode_reward": 37.82491278241933, "episode": 24.0, "batch_reward": 0.12344035038352012, "critic_loss": 0.041307309433817864, "ae_transition_loss": 0.014238145280629397, "ae_encoder_loss": 0.031809628680348395, "actor_loss": -3.152983423233032, "actor_target_entropy": -6.0, "actor_entropy": 4.136371322631836, "alpha_loss": 0.00563515697978437, "alpha_value": 0.006256661438923981, "duration": 54.200711727142334, "step": 6000}
{"episode_reward": 78.88840000677978, "episode": 25.0, "batch_reward": 0.1294078089296818, "critic_loss": 0.04161150069534779, "ae_transition_loss": 0.015488151106983422, "ae_encoder_loss": 0.03473695541918278, "actor_loss": -3.2828952846527097, "actor_target_entropy": -6.0, "actor_entropy": 4.376263294219971, "alpha_loss": 0.0053254843127215285, "alpha_value": 0.005888412515328505, "duration": 54.208637952804565, "step": 6250}
{"episode_reward": 81.84363976948478, "episode": 26.0, "batch_reward": 0.13665232703089714, "critic_loss": 0.04046681792289018, "ae_transition_loss": 0.015441885951906443, "ae_encoder_loss": 0.03780918162316084, "actor_loss": -3.4536451988220214, "actor_target_entropy": -6.0, "actor_entropy": 4.605967868804932, "alpha_loss": 0.0019952156259678304, "alpha_value": 0.00564014437762649, "duration": 54.27664089202881, "step": 6500}
{"episode_reward": 71.40629238012124, "episode": 27.0, "batch_reward": 0.14221891659498215, "critic_loss": 0.043515151850879195, "ae_transition_loss": 0.016418553229421377, "ae_encoder_loss": 0.0400002194494009, "actor_loss": -3.592125110626221, "actor_target_entropy": -6.0, "actor_entropy": 4.769633707046509, "alpha_loss": -0.0003435281498823315, "alpha_value": 0.005574811281581859, "duration": 54.20481514930725, "step": 6750}
{"episode_reward": 39.308424424194364, "episode": 28.0, "batch_reward": 0.1430095429122448, "critic_loss": 0.04361664742231369, "ae_transition_loss": 0.016746923040598632, "ae_encoder_loss": 0.04139856544882059, "actor_loss": -3.6854279174804687, "actor_target_entropy": -6.0, "actor_entropy": 4.983266986846924, "alpha_loss": -0.0032047958623152226, "alpha_value": 0.00566965773223662, "duration": 54.20190787315369, "step": 7000}
{"episode_reward": 68.05376830997129, "episode": 29.0, "batch_reward": 0.14796582794189453, "critic_loss": 0.04499809125065803, "ae_transition_loss": 0.017669199712574482, "ae_encoder_loss": 0.04384046192467213, "actor_loss": -3.8042297801971436, "actor_target_entropy": -6.0, "actor_entropy": 5.02989289855957, "alpha_loss": -0.0036368436272023246, "alpha_value": 0.0059347166624747, "duration": 54.30651092529297, "step": 7250}
{"episode_reward": 76.92170216165091, "episode": 30.0, "batch_reward": 0.15294226443767547, "critic_loss": 0.04589970625191927, "ae_transition_loss": 0.01847595642507076, "ae_encoder_loss": 0.04693039263784885, "actor_loss": -3.910696018218994, "actor_target_entropy": -6.0, "actor_entropy": 5.18994282913208, "alpha_loss": -0.0009541952449362725, "alpha_value": 0.006186734395529766, "duration": 54.229252099990845, "step": 7500}
{"episode_reward": 54.62460921919543, "episode": 31.0, "batch_reward": 0.15498457407951355, "critic_loss": 0.04823795707523823, "ae_transition_loss": 0.018848383896052836, "ae_encoder_loss": 0.04676141534745693, "actor_loss": -3.986329376220703, "actor_target_entropy": -6.0, "actor_entropy": 5.5238067893981935, "alpha_loss": 0.0008216563535388559, "alpha_value": 0.006212532314465269, "duration": 67.86337041854858, "step": 7750}
{"episode_reward": 50.133010458814475, "episode": 32.0, "batch_reward": 0.15758590865135194, "critic_loss": 0.04672105636447668, "ae_transition_loss": 0.018423981364816426, "ae_encoder_loss": 0.04628777803480625, "actor_loss": -4.058936807632446, "actor_target_entropy": -6.0, "actor_entropy": 5.36030749130249, "alpha_loss": 0.002020476626348682, "alpha_value": 0.006030477713444153, "duration": 54.339895486831665, "step": 8000}
{"episode_reward": 62.049811702140836, "episode": 33.0, "batch_reward": 0.15856177246570588, "critic_loss": 0.04794461621344089, "ae_transition_loss": 0.01881007357314229, "ae_encoder_loss": 0.046084602028131486, "actor_loss": -4.168951944351196, "actor_target_entropy": -6.0, "actor_entropy": 5.171637050628662, "alpha_loss": -0.006094770259223879, "alpha_value": 0.006182351689529794, "duration": 54.321585178375244, "step": 8250}
{"episode_reward": 27.403269567403274, "episode": 34.0, "batch_reward": 0.1569995192885399, "critic_loss": 0.05119150548428297, "ae_transition_loss": 0.01910804111883044, "ae_encoder_loss": 0.0491087920665741, "actor_loss": -4.237517433166504, "actor_target_entropy": -6.0, "actor_entropy": 5.615722038269043, "alpha_loss": 0.002749913323204964, "alpha_value": 0.006465457938735273, "duration": 54.319918394088745, "step": 8500}
{"episode_reward": 28.951177224607736, "episode": 35.0, "batch_reward": 0.15572526067495346, "critic_loss": 0.04960374055802822, "ae_transition_loss": 0.017809310875833033, "ae_encoder_loss": 0.048926190599799156, "actor_loss": -4.306653621673584, "actor_target_entropy": -6.0, "actor_entropy": 5.610570217132568, "alpha_loss": 0.002853746020118706, "alpha_value": 0.006121778112601866, "duration": 54.32970333099365, "step": 8750}
{"episode_reward": 38.756962102519964, "episode": 36.0, "batch_reward": 0.15497606563568114, "critic_loss": 0.053998664155602456, "ae_transition_loss": 0.017889856819063424, "ae_encoder_loss": 0.05097066195309162, "actor_loss": -4.399390769958496, "actor_target_entropy": -6.0, "actor_entropy": 5.628996398925781, "alpha_loss": 0.0010775291519239546, "alpha_value": 0.00590781899507305, "duration": 54.416895151138306, "step": 9000}
{"episode_reward": 23.905248791285203, "episode": 37.0, "batch_reward": 0.15355066412687302, "critic_loss": 0.05628884311765432, "ae_transition_loss": 0.018238676611334086, "ae_encoder_loss": 0.052954797744750974, "actor_loss": -4.462554069519043, "actor_target_entropy": -6.0, "actor_entropy": 5.693963485717774, "alpha_loss": 0.0017334140727762132, "alpha_value": 0.005735832978790536, "duration": 54.28493094444275, "step": 9250}
{"episode_reward": 37.35048067021057, "episode": 38.0, "batch_reward": 0.1561498365998268, "critic_loss": 0.05695159991085529, "ae_transition_loss": 0.017946968644857408, "ae_encoder_loss": 0.05235062789916992, "actor_loss": -4.560686233520507, "actor_target_entropy": -6.0, "actor_entropy": 5.685810260772705, "alpha_loss": 0.0031974709876812996, "alpha_value": 0.005507373284521494, "duration": 54.19261288642883, "step": 9500}
{"episode_reward": 41.35847626890035, "episode": 39.0, "batch_reward": 0.15414566153287887, "critic_loss": 0.06285295547544956, "ae_transition_loss": 0.020016953743994235, "ae_encoder_loss": 0.053748625472188, "actor_loss": -4.620249946594238, "actor_target_entropy": -6.0, "actor_entropy": 5.73922274017334, "alpha_loss": 0.002514592703199014, "alpha_value": 0.005185559510838825, "duration": 54.273679971694946, "step": 9750}
{"episode_reward": 39.91819999810429, "episode": 40.0, "batch_reward": 0.15594037050008774, "critic_loss": 0.05881377410888672, "ae_transition_loss": 0.017857038374990225, "ae_encoder_loss": 0.053233602046966554, "actor_loss": -4.692215183258057, "actor_target_entropy": -6.0, "actor_entropy": 5.287356327056885, "alpha_loss": -0.0006034178417176009, "alpha_value": 0.005014870428718025, "duration": 54.14480423927307, "step": 10000}
{"episode_reward": 70.51026060741313, "episode": 41.0, "batch_reward": 0.15701795971393584, "critic_loss": 0.05755220906436443, "ae_transition_loss": 0.018165040615946055, "ae_encoder_loss": 0.05404407940804958, "actor_loss": -4.809433422088623, "actor_target_entropy": -6.0, "actor_entropy": 5.164866214752197, "alpha_loss": -0.0020802662672940644, "alpha_value": 0.005206421328317065, "duration": 73.98449659347534, "step": 10250}
{"episode_reward": 41.83447496288627, "episode": 42.0, "batch_reward": 0.1575377965569496, "critic_loss": 0.08252170749008655, "ae_transition_loss": 0.0226831250526011, "ae_encoder_loss": 0.05942929390072822, "actor_loss": -4.888608070373535, "actor_target_entropy": -6.0, "actor_entropy": 5.299778930664062, "alpha_loss": -0.0004777562378440052, "alpha_value": 0.005414666546782686, "duration": 54.267918825149536, "step": 10500}
{"episode_reward": 70.32081138496382, "episode": 43.0, "batch_reward": 0.16245208364725114, "critic_loss": 0.07747903668880463, "ae_transition_loss": 0.02260382105410099, "ae_encoder_loss": 0.06544820024073124, "actor_loss": -5.065591293334961, "actor_target_entropy": -6.0, "actor_entropy": 5.471037147521972, "alpha_loss": -6.289742747321724e-05, "alpha_value": 0.0053633676222100924, "duration": 54.417810678482056, "step": 10750}
{"episode_reward": 72.367642601199, "episode": 44.0, "batch_reward": 0.16450474154949188, "critic_loss": 0.06939870613813401, "ae_transition_loss": 0.019812163170427083, "ae_encoder_loss": 0.06016798409819603, "actor_loss": -5.136629390716553, "actor_target_entropy": -6.0, "actor_entropy": 5.409197452545166, "alpha_loss": -1.9900617888197302e-05, "alpha_value": 0.005400469643699887, "duration": 54.3941490650177, "step": 11000}
{"episode_reward": 71.73110499188147, "episode": 45.0, "batch_reward": 0.16630678635835647, "critic_loss": 0.06721001332998276, "ae_transition_loss": 0.018993428245186805, "ae_encoder_loss": 0.059188276812434194, "actor_loss": -5.233229190826416, "actor_target_entropy": -6.0, "actor_entropy": 5.393804615020752, "alpha_loss": -0.000136208385694772, "alpha_value": 0.005481729348246542, "duration": 54.29826211929321, "step": 11250}
{"episode_reward": 33.94771748710185, "episode": 46.0, "batch_reward": 0.16587401485443115, "critic_loss": 0.09655289620161056, "ae_transition_loss": 0.023056626692414282, "ae_encoder_loss": 0.06518500849604607, "actor_loss": -5.3512591361999515, "actor_target_entropy": -6.0, "actor_entropy": 5.478354415893555, "alpha_loss": -0.0005687703934963793, "alpha_value": 0.005452146239204187, "duration": 54.22601342201233, "step": 11500}
{"episode_reward": 46.03069754106079, "episode": 47.0, "batch_reward": 0.16527769315242768, "critic_loss": 0.08058816194534302, "ae_transition_loss": 0.02123197928071022, "ae_encoder_loss": 0.06748814292252064, "actor_loss": -5.4635746307373045, "actor_target_entropy": -6.0, "actor_entropy": 5.440614406585693, "alpha_loss": -0.0035216954165371134, "alpha_value": 0.00585180769438132, "duration": 54.33720111846924, "step": 11750}
{"episode_reward": 45.34697598064719, "episode": 48.0, "batch_reward": 0.16828545272350312, "critic_loss": 0.0990056305527687, "ae_transition_loss": 0.022816948652267455, "ae_encoder_loss": 0.06942412158846856, "actor_loss": -5.618858417510986, "actor_target_entropy": -6.0, "actor_entropy": 5.513705429077149, "alpha_loss": -0.0014971440147492103, "alpha_value": 0.006267859081984368, "duration": 54.22487688064575, "step": 12000}
{"episode_reward": 81.28098664430878, "episode": 49.0, "batch_reward": 0.1731928486227989, "critic_loss": 0.09896827736496926, "ae_transition_loss": 0.02335644031316042, "ae_encoder_loss": 0.07282679444551468, "actor_loss": -5.786304706573486, "actor_target_entropy": -6.0, "actor_entropy": 5.544847492218017, "alpha_loss": -0.001304278852418065, "alpha_value": 0.00649936011304968, "duration": 54.2931706905365, "step": 12250}
{"episode_reward": 96.43337730579627, "episode": 50.0, "batch_reward": 0.1740745418071747, "critic_loss": 0.0921656329780817, "ae_transition_loss": 0.021753279216587543, "ae_encoder_loss": 0.07014751513302327, "actor_loss": -5.926211585998535, "actor_target_entropy": -6.0, "actor_entropy": 5.612399223327636, "alpha_loss": -0.000526487048715353, "alpha_value": 0.006749207912631465, "duration": 54.342992305755615, "step": 12500}
{"episode_reward": 54.87843612042516, "episode": 51.0, "batch_reward": 0.17809612959623336, "critic_loss": 0.08761238463222981, "ae_transition_loss": 0.020174362756311893, "ae_encoder_loss": 0.06837379990518093, "actor_loss": -6.029316307067871, "actor_target_entropy": -6.0, "actor_entropy": 5.627769660949707, "alpha_loss": 0.0007361196568235755, "alpha_value": 0.006648133120174555, "duration": 67.97686624526978, "step": 12750}
{"episode_reward": 101.17550690572222, "episode": 52.0, "batch_reward": 0.17973316025733949, "critic_loss": 0.09927527919411659, "ae_transition_loss": 0.021431410737335684, "ae_encoder_loss": 0.06933507506549358, "actor_loss": -6.113653011322022, "actor_target_entropy": -6.0, "actor_entropy": 5.538774162292481, "alpha_loss": 0.0010593079265672713, "alpha_value": 0.006490212411768384, "duration": 54.33430242538452, "step": 13000}
{"episode_reward": 55.08277003162294, "episode": 53.0, "batch_reward": 0.18225625324249267, "critic_loss": 0.08802943621575833, "ae_transition_loss": 0.020891926273703575, "ae_encoder_loss": 0.06740589101612568, "actor_loss": -6.2377837371826175, "actor_target_entropy": -6.0, "actor_entropy": 5.546505031585693, "alpha_loss": -0.0012299509805161505, "alpha_value": 0.006509094778409718, "duration": 54.294408321380615, "step": 13250}
{"episode_reward": 87.92593852515813, "episode": 54.0, "batch_reward": 0.18358580493927001, "critic_loss": 0.10434915640950203, "ae_transition_loss": 0.02165222094208002, "ae_encoder_loss": 0.06939902317523956, "actor_loss": -6.335629165649414, "actor_target_entropy": -6.0, "actor_entropy": 5.480936229705811, "alpha_loss": -0.0004700177682098001, "alpha_value": 0.006707525510570834, "duration": 54.28086185455322, "step": 13500}
{"episode_reward": 39.510262016539365, "episode": 55.0, "batch_reward": 0.1852691759467125, "critic_loss": 0.09784960480034352, "ae_transition_loss": 0.021234732776880264, "ae_encoder_loss": 0.06863769519329072, "actor_loss": -6.458294250488281, "actor_target_entropy": -6.0, "actor_entropy": 5.512103694915772, "alpha_loss": 0.0007292463072226383, "alpha_value": 0.006689335589296105, "duration": 54.410290002822876, "step": 13750}
{"episode_reward": 91.68726939475212, "episode": 56.0, "batch_reward": 0.18758445060253143, "critic_loss": 0.12173207128047943, "ae_transition_loss": 0.024559492625296116, "ae_encoder_loss": 0.07311352555453778, "actor_loss": -6.575641536712647, "actor_target_entropy": -6.0, "actor_entropy": 5.48820698928833, "alpha_loss": 4.8502781661227346e-05, "alpha_value": 0.006512627542720493, "duration": 54.39474272727966, "step": 14000}
{"episode_reward": 100.29845320015872, "episode": 57.0, "batch_reward": 0.1899708144068718, "critic_loss": 0.14122022274136542, "ae_transition_loss": 0.026722203969955446, "ae_encoder_loss": 0.08101817409694195, "actor_loss": -6.719444999694824, "actor_target_entropy": -6.0, "actor_entropy": 5.477450527191162, "alpha_loss": -0.00137108143302612, "alpha_value": 0.006725096859471779, "duration": 54.34291052818298, "step": 14250}
{"episode_reward": 99.19856614622024, "episode": 58.0, "batch_reward": 0.19641030061244966, "critic_loss": 0.11427550706267357, "ae_transition_loss": 0.023632904805243014, "ae_encoder_loss": 0.08081152287125587, "actor_loss": -6.921710563659668, "actor_target_entropy": -6.0, "actor_entropy": 5.47623433303833, "alpha_loss": -0.001261003901832737, "alpha_value": 0.007077323366479788, "duration": 54.304930210113525, "step": 14500}
{"episode_reward": 97.49845511777934, "episode": 59.0, "batch_reward": 0.19708107835054398, "critic_loss": 0.13048811829090118, "ae_transition_loss": 0.02454652401804924, "ae_encoder_loss": 0.08289430139958859, "actor_loss": -7.000707904815674, "actor_target_entropy": -6.0, "actor_entropy": 5.507073581695557, "alpha_loss": -7.57847991771996e-05, "alpha_value": 0.007329856907802098, "duration": 54.47765922546387, "step": 14750}
{"episode_reward": 49.08371699023578, "episode": 60.0, "batch_reward": 0.19859724235534668, "critic_loss": 0.14113278618454933, "ae_transition_loss": 0.025308924555778503, "ae_encoder_loss": 0.08264547644555569, "actor_loss": -7.133876106262207, "actor_target_entropy": -6.0, "actor_entropy": 5.554980228424072, "alpha_loss": 0.00016296900017186998, "alpha_value": 0.007192749190245544, "duration": 54.4165256023407, "step": 15000}
{"episode_reward": 93.11766007234667, "episode": 61.0, "batch_reward": 0.2002357736825943, "critic_loss": 0.1430059105157852, "ae_transition_loss": 0.02605503486096859, "ae_encoder_loss": 0.08938095514476299, "actor_loss": -7.3165015182495114, "actor_target_entropy": -6.0, "actor_entropy": 5.5394099311828615, "alpha_loss": 0.0008450236630160361, "alpha_value": 0.007153039074433073, "duration": 68.0197286605835, "step": 15250}
{"episode_reward": 114.69477186015708, "episode": 62.0, "batch_reward": 0.20596543115377425, "critic_loss": 0.14089145305752754, "ae_transition_loss": 0.02668466830998659, "ae_encoder_loss": 0.0894061600714922, "actor_loss": -7.523859127044678, "actor_target_entropy": -6.0, "actor_entropy": 5.4696156044006345, "alpha_loss": -0.001814934004098177, "alpha_value": 0.0071747050982538885, "duration": 54.4164719581604, "step": 15500}
{"episode_reward": 94.62354152736005, "episode": 63.0, "batch_reward": 0.20780696749687194, "critic_loss": 0.16551498478651047, "ae_transition_loss": 0.02805031432956457, "ae_encoder_loss": 0.09537789586186408, "actor_loss": -7.66717004776001, "actor_target_entropy": -6.0, "actor_entropy": 5.475385608673096, "alpha_loss": -0.0019567962950095535, "alpha_value": 0.007652040282569971, "duration": 54.35574555397034, "step": 15750}
{"episode_reward": 80.3876288449348, "episode": 64.0, "batch_reward": 0.20929912334680556, "critic_loss": 0.16619493293762208, "ae_transition_loss": 0.02681159147620201, "ae_encoder_loss": 0.09726756057143211, "actor_loss": -7.860758876800537, "actor_target_entropy": -6.0, "actor_entropy": 5.459832462310791, "alpha_loss": -0.0015069029715377837, "alpha_value": 0.008337835643004103, "duration": 54.495636224746704, "step": 16000}
{"episode_reward": 70.20136443029273, "episode": 65.0, "batch_reward": 0.2107844694852829, "critic_loss": 0.16515659320354462, "ae_transition_loss": 0.02660225209593773, "ae_encoder_loss": 0.09779639810323715, "actor_loss": -8.034740394592285, "actor_target_entropy": -6.0, "actor_entropy": 5.512928504943847, "alpha_loss": 0.00018624945962801575, "alpha_value": 0.00842315502866754, "duration": 54.37945055961609, "step": 16250}
{"episode_reward": 67.3638166347973, "episode": 66.0, "batch_reward": 0.21122638648748399, "critic_loss": 0.15693971779942512, "ae_transition_loss": 0.025290267527103425, "ae_encoder_loss": 0.09486435425281525, "actor_loss": -8.168171215057374, "actor_target_entropy": -6.0, "actor_entropy": 5.49429744720459, "alpha_loss": 0.0009353647468378768, "alpha_value": 0.008383626364953604, "duration": 54.37615656852722, "step": 16500}
{"episode_reward": 77.667099149961, "episode": 67.0, "batch_reward": 0.21242396312952042, "critic_loss": 0.1746574574112892, "ae_transition_loss": 0.027704937145113944, "ae_encoder_loss": 0.0985200731754303, "actor_loss": -8.304915378570557, "actor_target_entropy": -6.0, "actor_entropy": 5.528064781188965, "alpha_loss": 0.001709381795488298, "alpha_value": 0.008057829156685957, "duration": 54.352572202682495, "step": 16750}
{"episode_reward": 47.54020040293153, "episode": 68.0, "batch_reward": 0.21374732983112335, "critic_loss": 0.19394557973742485, "ae_transition_loss": 0.030047245658934116, "ae_encoder_loss": 0.09647826826572418, "actor_loss": -8.452604034423828, "actor_target_entropy": -6.0, "actor_entropy": 5.5057058486938475, "alpha_loss": 0.000521131937392056, "alpha_value": 0.007637546511297583, "duration": 54.51214838027954, "step": 17000}
{"episode_reward": 73.25053565363905, "episode": 69.0, "batch_reward": 0.21584627866744996, "critic_loss": 0.18731203031539917, "ae_transition_loss": 0.027440377064049244, "ae_encoder_loss": 0.09740854641795159, "actor_loss": -8.644634986877442, "actor_target_entropy": -6.0, "actor_entropy": 5.423312068939209, "alpha_loss": -0.0002057852833531797, "alpha_value": 0.007544359303890407, "duration": 54.56847405433655, "step": 17250}
{"episode_reward": 106.50518217370823, "episode": 70.0, "batch_reward": 0.21578859770298003, "critic_loss": 0.20220568042993545, "ae_transition_loss": 0.02941577798128128, "ae_encoder_loss": 0.09879028597474099, "actor_loss": -8.827540367126465, "actor_target_entropy": -6.0, "actor_entropy": 5.474907543182373, "alpha_loss": -0.00023176633636467158, "alpha_value": 0.007653062042070893, "duration": 54.44880819320679, "step": 17500}
{"episode_reward": 70.25739086119323, "episode": 71.0, "batch_reward": 0.21872720104455948, "critic_loss": 0.17898047173023224, "ae_transition_loss": 0.025764007911086084, "ae_encoder_loss": 0.10185524091124534, "actor_loss": -8.963024520874024, "actor_target_entropy": -6.0, "actor_entropy": 5.47003551864624, "alpha_loss": 9.431476111058145e-05, "alpha_value": 0.007592257283119413, "duration": 68.37073516845703, "step": 17750}
{"episode_reward": 71.14395489567397, "episode": 72.0, "batch_reward": 0.22019808548688888, "critic_loss": 0.19459619075059892, "ae_transition_loss": 0.026260932736098766, "ae_encoder_loss": 0.09661301213502883, "actor_loss": -9.087579231262207, "actor_target_entropy": -6.0, "actor_entropy": 5.439772964477539, "alpha_loss": -0.0008439839365892112, "alpha_value": 0.007742156140537542, "duration": 54.52630138397217, "step": 18000}
{"episode_reward": 75.55483998956902, "episode": 73.0, "batch_reward": 0.21916996562480925, "critic_loss": 0.22850237292051315, "ae_transition_loss": 0.028577863454818726, "ae_encoder_loss": 0.09783925670385361, "actor_loss": -9.18933959197998, "actor_target_entropy": -6.0, "actor_entropy": 5.454259284973144, "alpha_loss": -8.251483901403844e-06, "alpha_value": 0.007904198620404623, "duration": 54.479119539260864, "step": 18250}
{"episode_reward": 80.48577707140491, "episode": 74.0, "batch_reward": 0.2211702031493187, "critic_loss": 0.2218533553481102, "ae_transition_loss": 0.02831507844477892, "ae_encoder_loss": 0.10070405852794648, "actor_loss": -9.37152823638916, "actor_target_entropy": -6.0, "actor_entropy": 5.444763656616211, "alpha_loss": -1.6628761077299713e-06, "alpha_value": 0.007906097672839455, "duration": 54.61123442649841, "step": 18500}
{"episode_reward": 36.9983690741349, "episode": 75.0, "batch_reward": 0.22131032621860505, "critic_loss": 0.2559534162580967, "ae_transition_loss": 0.02912994549423456, "ae_encoder_loss": 0.10079162827134132, "actor_loss": -9.543891937255859, "actor_target_entropy": -6.0, "actor_entropy": 5.4029387130737305, "alpha_loss": -0.0008236737023107708, "alpha_value": 0.008102399843475981, "duration": 54.545551776885986, "step": 18750}
{"episode_reward": 106.4222973407228, "episode": 76.0, "batch_reward": 0.22307480645179747, "critic_loss": 0.2417497951388359, "ae_transition_loss": 0.029526924207806587, "ae_encoder_loss": 0.10290216511487961, "actor_loss": -9.721150672912598, "actor_target_entropy": -6.0, "actor_entropy": 5.390448184967041, "alpha_loss": 0.0006451803307281807, "alpha_value": 0.008081265893202481, "duration": 54.49875450134277, "step": 19000}
{"episode_reward": 78.96833175011011, "episode": 77.0, "batch_reward": 0.22398758274316788, "critic_loss": 0.2652582919597626, "ae_transition_loss": 0.02930405116826296, "ae_encoder_loss": 0.10822869917750358, "actor_loss": -9.887179862976074, "actor_target_entropy": -6.0, "actor_entropy": 5.316365333557129, "alpha_loss": 2.700699435081333e-05, "alpha_value": 0.007920275028670492, "duration": 54.566903829574585, "step": 19250}
{"episode_reward": 83.5216007578833, "episode": 78.0, "batch_reward": 0.22566798913478853, "critic_loss": 0.24353427505493164, "ae_transition_loss": 0.02774968262016773, "ae_encoder_loss": 0.10433954128623009, "actor_loss": -10.025682159423829, "actor_target_entropy": -6.0, "actor_entropy": 5.346628353118897, "alpha_loss": -0.000418430169345811, "alpha_value": 0.007989531079132394, "duration": 54.51039958000183, "step": 19500}
{"episode_reward": 94.46681955030063, "episode": 79.0, "batch_reward": 0.22631986433267592, "critic_loss": 0.265678674519062, "ae_transition_loss": 0.02751878608763218, "ae_encoder_loss": 0.10198985624313354, "actor_loss": -10.16423462677002, "actor_target_entropy": -6.0, "actor_entropy": 5.313027214050293, "alpha_loss": -0.0001251974367769435, "alpha_value": 0.007941283304885135, "duration": 54.60537266731262, "step": 19750}
{"episode_reward": 61.2999670755425, "episode": 80.0, "batch_reward": 0.2285507089495659, "critic_loss": 0.24437617993354796, "ae_transition_loss": 0.02600641842931509, "ae_encoder_loss": 0.09951001718640327, "actor_loss": -10.291298904418944, "actor_target_entropy": -6.0, "actor_entropy": 5.392498115539551, "alpha_loss": -0.00047881870646961035, "alpha_value": 0.008350717626025558, "duration": 54.544463872909546, "step": 20000}
